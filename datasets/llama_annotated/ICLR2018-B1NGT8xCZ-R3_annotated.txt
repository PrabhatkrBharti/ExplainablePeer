The authors propose a probabilistic framework for semi-supervised learning and domain adaptation.  By varying the prior distribution, the framework can incorporate both generative and discriminative modeling.   The authors emphasize on one particular form of constraint on the prior distribution, that is weight (parameter) sharing, and come up with a concrete model named Dauto for domain adaptation.  A domain confusion loss is added to learn domain-invariant feature representations.  The authors compared Dauto with several baseline methods on several datasets and showed improvement. \n\nThe paper is well-organized and easy to follow.  The probabilistic framework itself is quite straight-forward.  The paper will be more interesting if the authors are able to extend the discussion on different forms of prior instead of the simple parameter sharing scheme.  \n\nThe proposed DAuto is essentially DANN+autoencoder.   The minimax loss employed in DANN and DAuto is known to be prone to degenerated gradient for the generator.  It would be interesting to see if the additional auto-encoder part help address the issue.  \n\nThe experiments miss some of the more recent baseline in domain adaptation, such as Adversarial Discriminative Domain Adaptation (Tzeng, Eric, et al. 2017).  \n\nIt could be more meaningful to organize the pairs in table by target domain instead of source, for example, grouping 9->9, 8->9, 7->9 and 3->9 in the same block.  DAuto does seem to offer more boost in domain pairs that are less similar. [[CLA-NEG],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]