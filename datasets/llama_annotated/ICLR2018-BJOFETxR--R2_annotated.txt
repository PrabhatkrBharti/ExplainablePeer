The paper introduces an application of Graph Neural Networks (Li's Gated Graph Neural Nets, GGNNs, specifically) for reasoning about programs and programming.  The core idea is to represent a program as a graph that a GGNN can take as input, and train the GGNN to make token-level predictions that depend on the semantic context.  The two experimental tasks were: 1) identifying variable (mis)use, ie. identifying bugs in programs where the wrong variable is used,  and 2) predicting a variable's name by consider its semantic context. \n\nThe paper is generally well written, easy to read and understand, and the results are compelling.  The proposed GGNN approach outperforms (bi-)LSTMs on both tasks.  Because the tasks are not widely explored in the literature, it could be difficult to know how crucial exploiting graphically structured information is, so the authors performed several ablation studies to analyze  this out.  Those results show that as structural information is removed, the GGNN's performance diminishes, as expected.  As a demonstration of the usefulness of their approach, the authors ran their model on an unnamed open-source project and claimed to find several bugs, at least one of which potentially reduced memory performance. \n\nOverall the work is important, original, well-executed, and should open new directions for deep learning in program analysis.  I recommend it be accepted.[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]