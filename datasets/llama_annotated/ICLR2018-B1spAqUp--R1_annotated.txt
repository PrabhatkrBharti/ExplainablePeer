This paper is well written and easy to follow.  The authors propose pixel deconvolutional layers for convolutional neural networks.  The motivation of the proposed method, PixelDCL, is to remove the checkerboard effect of deconvolutoinal layers.  \nThe method consists of adding direct dependencies among the intermediate feature maps generated by the deconv layer.  PixelDCL is applied sequentially, therefore it is slower than the original deconvolutional layer.  The authors evaluate the model in two different problems: semantic segmentation (on PASCAL VOC and MSCOCO datasets) and in image generation VAE (with the CelebA dataset).  \n\nThe authors justify the proposed method as a way to alleviate the checkerboard effect (while introducing more complexity to the model and making it slower).  In the experimental section, however, they do not compare with other approaches to do so For example, the upsampling+conv approach, which has been shown to remove the checkerboard effect while being more efficient than the proposed method (as it does not require any sequential computation).  Moreover, the PixelDCL does not seem to bring substantial improvements on DeepLab (a state-of-the-art semantic segmentation algorithm).  More comments and further exploration on this results should be done.  Why no performance boost?  Is it because of the residual connection?  Or other component of DeepLab?  Is the proposed layer really useful once a powerful model is used? \n\nI also think the experiments on VAE are not conclusive.  The authors simply show set of generated images.  First, it is difficult to see the different of the image generated using deconv and PixelDCL.  Second, a set of 20 qualitative images does not (and cannot) validate any research idea.[[CLA-NEG],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]