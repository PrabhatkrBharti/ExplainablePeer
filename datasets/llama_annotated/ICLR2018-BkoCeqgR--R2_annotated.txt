The authors investigate a modified input layer that results in color invariant networks.  The proposed methods are evaluated on two car datasets.  It is shown that certain color invariant \"input\" layers can improve accuracy for test-images from a different color distribution than the training images. \n\n\nThe proposed assumptions are not well motivated and seem arbitrary.  Why is using a permutation of each pixels' color a good idea? \n\nThe paper is very hard to read.  The message is unclear and the experiments to prove it are of very limited scope,;  i.e. one small dataset with the only experiment purportedly showing generalization to red cars. \n\nSome examples of specific issues:\n- the abstract is almost incomprehensible and it is not clear what the contributions are \n- Some references to Figures are missing the figure number, eg. 3.2 first paragraph,  \n- It is not clear how many input channels the color invariant functions use, eg. p1 does it use only one channel and hence has fewer parameters? \n- are the training and testing sets all disjoint (sec 4.3)?\n- at random points figures are put in the appendix, even though they are described in the paper and seem to show key results (eg \"tested on nored-test\") \n- Sec 4.6: The explanation for why the accuracy drops for all models is not clear.  Is it because the total number of training images drops?  If that's the case the whole experimental setup seems flawed. \n- Sec 4.6: the authors refer to the \"order net\" beating the baseline, however, from Fig 8 (right most) it appears as if all models beat the baseline.  In the conclusion they say that weighted order net beats the baseline on all three test sets w/o red cars in the training set.  Is that Fig 8 @0%?  The baseline seems to be best performing on \"all cars\" and \"non-red cars\"\n\nIn order to be at an appropriate level for any publication the experiments need to be much more general in scope.\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-NEG],[NOV-POS],[ETH-NEG]]