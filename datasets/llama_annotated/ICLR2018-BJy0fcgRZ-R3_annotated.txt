The idea of using MCMCP with GANs is well-motivated and well-presented \nin the paper, and the approach is new as far as I know.   Figures 3 and 5 are\nconvincing evidence that MCMCP compares favorably to direct sampling of\nthe GAN feature space using the classification images approach. \n\nHowever, as discussed in the introduction, the reason an efficient\nsampling method might be interesting would be to provide insight\non the components of perception.   On these insights, the paper felt\nincomplete. \n\nFor example, it was not investigated whether the method identifies\nclassification features that generalize.   The faces experiment is\nsimilar to previous work done by Martin (2011) and Kontsevich\n(2004) but unlike that previous work does not investgiate whether\nclassification features have been identified that can be added to an\narbitrary image to change the attribute \"happy vs sad\" or \"male vs female\". \n\nSimilarly, the second experiment in Table 1 compares classification\naccuracy between different sampling methods, but it does not provide\nany comparison as done in Vondrick (2015) to a classifier trained\nin a conventional way (such as an SVM), so it is difficult to discern\nwhether the learned distributions are informative. \n\nFinally, the effect of choosing GAN features vs a more \"naive\" feature\nspace is not explored in detail.   For example, the GAN is trained\non an image data set with many birds and cars but not many\nfire hydrants.   Is the method giving us a picture of this data set?[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]