The authors propose a defense against attacks on the security of one-class SVM based anonaly detectors.  The core idea is to perform a random projection of the data (which is supposed to decrease the impact from adversarial distortions).  The approach is empirically tested on the following data: MNIST, CIFAR, and SVHN. \n\nThe paper is moderately well written and structured.  Command of related work is ok,  but some relevant refs are missing (e.g., Kloft and Laskov, JMLR 2012).   The empirical results actually confirm that indeed the strategy of reducing the dimensionality using random projections reduces the impact from adversarial distortions.   This is encouraging.  Right now, there is no theoretical justification for the approach, nor even a (in my opinion) convincing movitation/Intuition behind the approach.  Also, the attack model should formally introduced. \n\nIn summary, I d like to encourage the authors to further investigate into their approach, but I am not convinced by the manuscript in the current form.  It lacks both in sound theoretical justification and intuitive motivation of the approach.  The experiments, however, show clearly advantages of the approach  (again, here further experiments are necessary, e.g., varying the dose of adversarial points). [[CLA-NEG],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEU]]