The paper proposes a new method for detecting out of distribution samples.  The core idea is two fold: when passing a new image through the (already trained) classifier, first preprocess the image by adding a small perturbation to the image pushing it closer to the highest softmax output and second, add a temperature to the softmax.  Then, a simple decision is made based on the output of the softmax of the perturbed image - if it is able some threshold then the image is considered in-distribution otherwise out-distribution. \n\nThis paper is well written, easy to understand and presents a simple and apparently effective method of detecting out of distribution samples.  The authors evaluate on cifar-10/100 and several out of distribution datasets and this method outperforms the baseline by significant margins.  They also examine the effects of the temperature and step size of the perturbation.  \n \nMy only concern is that the parameter delta (threshold used to determine in/out distribution) is not discussed much.  They seem to optimize over this parameter, but this requires access to the out of distribution set prior to the final evaluation.  Could the authors comment on how sensitive the method is to this parameter?  How much of the out of distribution dataset is used to determine this value, and what are the effects of this size during tuning?  What happens if you set the threshold using one out of distribution dataset and then evaluate on a different one?  This seems to be the central part missing to this paper  and if the authors are able to address it satisfactorily I will increase my score.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-NEG],[NOV-NEG],[ETH-NEG]]