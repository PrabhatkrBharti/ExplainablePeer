[Main comments]\n\n* I would advice the authors to explain in more details in the intro\nwhat's new compared to Li & Malik (2016) and Andrychowicz et al.  (2016).\nIt took me until section 3.5 to figure it out. \n\n* If I understand correctly, the only new part compared to Li & Malik (2016) is\nsection 3.5, where block-diagonal structure is imposed on the learned matrices. \nIs that correct? \n\n* In the experiments, why not comparing with Li & Malik (2016)? (i.e., without\n  block-diagonal structure) \n\n* Please clarify whether the objective value shown in the plots is wrt the training\n  set or the test set.  Reporting the training objective value makes little\nsense to me, unless the time taken to train on MNIST is taken into account in\nthe comparison.  \n\n* Please clarify what are the hyper-parameters of your meta-training algorithm\n  and how you chose them. \n\nI will adjust my score based on the answer to these questions. \n\n[Other comments]\n\n* \"Given this state of affairs, perhaps it is time for us to start practicing\n  what we preach and learn how to learn\"\n\nThis is in my opinion too casual for a scientific publication... \n\n* \"aim to learn what parameter values of the base-level learner are useful\n  across a family of related tasks\"\n\nIf this is essentially multi-task learning, why not calling it so?  \"Learning\nwhat to learn\" does not mean anything.   I understand that the authors wanted to\nhave \"what\", \"which\" and \"how\" sections but this is not clear at all. \n\nWhat is a \"base-level learner\"? I think it would be useful to define it more\nprecisely early on. \n\n* I don't see the difference between what is described in Section 2.2\n  (\"learning which model to learn\") and usual machine learning (searching for\nthe best hypothesis in a hypothesis class). \n\n* Typo: p captures the how -> p captures how \n\n* The L-BFGS results reported in all Figures looked suspicious to me.   How do you\n  explain that it converges to a an objective value that is so much worse? \nMoreover, the fact that there are huge oscillations makes me think that the\nauthors are measuring the function value during the line search rather than\nthat at the end of each iteration[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-POS]]