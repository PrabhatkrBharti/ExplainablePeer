This paper proposes a simple problem to demonstrate the short-horizon bias of the learning rate meta-optimization. \n\n- The idealized case of quadratic function the analytical solution offers a good way to understand how T-step look ahead can benefit the meta-algorithm. \n- The second part of the paper seems to be a bit disconnected to the quadratic function analysis.  It would be helpful to understand if there is gap between gradient based meta-optimization and the best effort(given by the analytical solution) \n- Unfortunately, no guideline or solution is offered in the paper. \n\nIn summary, the idealized model gives a good demonstration of the problem itself.  I think it might be of interest to some audiences in ICLR[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-NEG],[ENG-POS],[ACC-POS],[CST-NEG],[NOV-POS],[ETH-NEG]]