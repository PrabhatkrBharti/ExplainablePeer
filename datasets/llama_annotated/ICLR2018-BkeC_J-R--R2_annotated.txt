This paper proposes to combine reinforcement learning with supervised learning to speed up learning.  Unlike their claim in the paper, the idea of combining supervised and RL is not new.  A good example of this is a supervised actor-critic by Barto (2004).  I think even alphaGo uses some form of supervision.  However, if I understand correctly, it seems that combining supervision of RL at a later fine-tuning phase by considering supervision as a regularization term is an interesting idea that seems novel. \n\nHaving the luxury of some supervised episodes is of course useful.  The first step of building a supervised initial model looks straight forward.  The next step of the algorithm is less easy to follow, and presentation of the ideas could be much better.  This part of the paper leaves me already with many questions such as why is it essential to consider only a deterministic case and also to consider greedy optimization? Doesn\u2019t this prevent exploration? What are the network parameters (e.g. size of layers) etc.  I am not sure I could redo the work from the provided information.\n\n Overall, it is unclear to me what the advantage of the algorithm is over pure supervised learning, and I don\u2019t think a compelling case has been made.  Since the influence of the supervision is increased by increasing alpha, it can be expected that results should be better for increasing alpha.  The results seem to indicate that an intermediate level of alpha is best, though I would even question the statistical significance by looking at the curves in Figure 3.  Also, what is the epoch number, and why is this 1 for alpha=0?  If the combination of supervised learning with RL is better, than this should be clearly stated.  Some argument is made that pure supervision is overfitting, but would one then not simply add some other regularizer?  \n\nThe presentation could also be improved with some language edits.  Several articles are wrongly placed and even some meaning is unclear.  For example, the phrase \u201ccontinuous input sequence\u201d does not make sense; maybe you mean \u201cinput sequence of real valued quantities\u201d.\n\n In summary, while the paper contains some good ideas, I certainly think it needs more work to make a clear case for this method. \n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-POS]]