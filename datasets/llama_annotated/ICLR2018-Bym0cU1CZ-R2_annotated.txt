The topic discussed in this paper is interesting.  Dialogue acts (DAs; or some other semantic relations between utterances) are informative to increase the diversity of response generation.  It is interesting to see how DAs are used for conversational modeling,;  however this paper is difficult for me to follow.  For example:\n\n1) the caption of section 3.1 is about supervised learning, however the way of describing the model in this section sounds like reinforcement learning.  Not sure whether it is necessary to formulate the problem with a RL framework, since the data have everything that the model needs as for a supervised learning. \n2) the formulation in equation 4 seems to be problematic \n3) \"simplify pr(ri|si,ai) as pr(ri|ai,ui\u22121,ui\u22122) since decoding natural language responses from long conversation history is challenging \" to my understanding, the only difference between the original and simplified model is the encoder part not the decoder part. Did I miss something? \n4) about section 3.2, again I didn't get whether the model needs RL for training. \n5) \"We train m(\u00b7, \u00b7) with the 30 million crawled data through negative sampling.\" not sure I understand the connection between training $m(\\cdot, \\cdot)$ and the entire model. \n6) the experiments are not convincing.  At least, it should show the generation texts were affected about DAs in a systemic way.  Only a single example in table 5 is not enough[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]