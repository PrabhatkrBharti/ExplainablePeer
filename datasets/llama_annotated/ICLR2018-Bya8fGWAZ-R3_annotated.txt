The paper introduces two alternatives to value iteration network (VIN) proposed by Tamar et al. VIN was proposed to tackle the task of learning to plan using as inputs a position and an image of the map of the environment.  The authors propose two new updates value propagation (VProp) and max propagation (MVProp), which are roughly speaking additive and multiplicative versions of the update used in the Bellman-Ford algorithm for shortest path.  The approaches are evaluated in grid worlds with and without other agents. \n\nI had some difficulty to understand the paper because of its presentation and writing (see below). \n\nIn Tamar's work, a mapping from observation to reward is learned.   As a consequence, those two methods need to take as input a new reward function for every new map.  Is that correct? \nI think this could explain the better experimental results\n\nIn the experimental part, the results for VIN are worse than those reported in Tamar et al.'s paper.  Why did you use your own implementation of VIN and not Tamar et al.'s, which is publicly shared as far as I know? \n\nI think the writing needs to be improved on the following points:\n- The abstract doesn't fit well the content of the paper.  For instance, \"its variants\" is confusing because there is only other variant to VProp.  \"Adversarial agents\" is also misleading because those agents act like automata. \n\n- The authors should recall more thoroughly and precisely the work of Tamar et al., on which their work is based to make the paper more self-contained, e.g., (1) is hardly understandable. \n\n- The writing should be careful, e.g., \nvalue iteration is presented as a learning algorithm (which in my opinion is not) \n\\pi^* is defined as a distribution over state-action space and then \\pi is defined as a function;  ...\n\n- The mathematical writing should be more rigorous;  e.g., \np.2:\nT: s \\to a \\to s', \\pi : s \\to a\nA denotes a set and its cardinal\nIn (1), shouldn't it be \\Phi(o)? all the new terms should be explained\np. 3:\ndefinition of T and R \nshouldn't V_{ij}^k depend on Q_{aij}^k?\nT_{::aij} should be defined\nIn the definition of h_{aij}, should \\Phi and b be indexed by a? \n\n- The typos and other issues should be fixed:\np. 3:\nK iteration\nwith capable\np.4:\nclose 0\np.5:\nour our\ns^{t+1} should be defined like the other terms\n\"The state is represented by the coordinates of the agent and 2D environment observation\" should appear much earlier in the paper. \n\"\\pi_\\theta described in the previous sections\", notation \\pi_\\theta appears the first time here...\n3x3 -> 3 \\times 3\nofB\nV_{\\theta^t w^t} \np.6:\nthe the\nFig.2's caption:\nWhat does \"both cases\" refer to? They are three models. \nReferences:\net al.\nYI WU\n[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]