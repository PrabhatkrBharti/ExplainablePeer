Overview\n\nThe authors propose a reinforcement learning approach to learn a general active query policy from multiple heterogeneous datasets.  The reinforcement learning part is based on a policy network, which selects the data instance to be labeled next. They use meta-learning on feature histograms to embed heterogeneous datasets into a fixed dimensional representation.  The authors argue that policy-based reinforcement learning allows learning the criteria of active learning non-myopically.  The experiments show the proposed approach is effective on 14 UCI datasets .\n\nstrength\n\n* The paper is mostly clear and easy to follow .\n* The overall idea is interesting and has many potentials. \n* The experimental results are promising on multiple datasets. \n* There are thorough discussion with related works .\n\nweakness\n\n* The graph in p.3 don't show the architecture of the network clearly. \n* The motivation of using feature histograms as embedding is not clear .\n* The description of the 2-D histogram on p.4 is not clear.  The term \"posterior value\" sounds ambiguous .\n* The experiment sets a fixed budget of only 20 instances, which seems to be rather few in some active learning scenarios, especially for non-linear learners.  Also, the experiments takes a fixed 20K iterations for training, and the convergence status (e.g. whether the accumulated gradient has stabilized the policy) is not clear. \n* Are there particular reasons in using policy learning instead of other reinforcement learning approaches ?\n* The term A(Z) in the objective function can be more clearly described .\n* While many loosely-related works were surveyed, it is not clear why literally none of them were compared.  There is thus no evidence on whether a myopic bandit learner (say, Chu and Lin's work) is really worse than the RL policy.  There is also no evidence on whether adaptive learning on the fly is needed or not. \n* In Equation 2, should there be a balancing parameter for the reconstruction loss? \n* Some typos\n    - page 4: some duplicate words in discriminative embedding session\n    - page 4: auxliary -> auxiliary\n    - page 7: tescting -> testing\n\[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-NEG],[ETH-NEG]]