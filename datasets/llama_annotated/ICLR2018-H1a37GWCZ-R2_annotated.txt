1) This paper proposes a method for learning the sentence representations with sentences dependencies information.  It is more like a dependency-based version skip-thought on the sentence level.  The idea is interesting to me, but I think this paper still needs some improvements.  The introduction and related work part are clear with strong motivations to me.  But section 4 and 6 need a lot of details.  \n\n2) My comments are as follows:\ni) this paper claims that this is a general sentence embedding method, however, from what has been described in section 3, I think this dependency is only defined in HTML format document.  What if I only have pure text document without these HTML structure information?  So I suggest the authors do not claim that this method is a \"general-purpose\" sentence embedding model. \n\nii) The authors do not have any descriptions for Figure 3.  Equation 1 is also very confusing. \n\niii) The experiments are insufficient in terms of details. How is the loss calculated? How is the detection accuracy calculated[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEG],[ETH-NEG]]