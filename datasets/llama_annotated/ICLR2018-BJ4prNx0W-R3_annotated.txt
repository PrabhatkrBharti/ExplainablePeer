Previous work by Cai et al. (2017) shows how to use Neural Programmer-Interpreter (NPI) framework to prove correctness of a learned neural network program by introducing recursion.  It requires generation of a diverse training set consisting of execution traces which describe in detail the role of each function in solving a given input problem.  Moreover, the traces need to be recursive: each function only takes a finite, bounded number of actions.  In this paper, the authors show how training set can be generated automatically satisfying the conditions of Cai et al.'s paper.  They iteratively explore all\npossible behaviors of the oracle in a breadth-first manner, and the bounded nature of the recursive\noracle ensures that the procedure converges.  As a running example, they show how this can be be done for bubblesort.  The training set generated in this Fprocess may have a lot of duplicates, and the authors show how these duplicates can possibly be removed.  It indeeds shows a dramatic reduction in the number of training samples for the three experiments that have been shown in the paper.  \n\nI am not an expert in this area, so it is difficult for me to judge the technical merit of the work.  My feeling from reading the paper is that it is rather incremental over Cai et al.  I am impressed by the results of the three experiments that have been shown here, specifically, the reduction in the training samples once they have been generated is significant.  But these are also the same set of experiments performed by Cai et al.  \n\nGiven the original number of traces generated is huge, I do not understand, why this method is at all practical.  This also explains why the authors have just tested the performance on extremely small sized data. It will not scale.  So, I am hesitant accepting the paper.  I would have been more enthusiastic if the authors had proposed a way to combine the training space exploration as well as removing redundant traces together to make the whole process more scalable and done experiments on reasonably sized data. [[CLA-NEG],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEU],[ETH-NEU]]