The paper proposes a method to train deep multi-task networks using gradient normalization.  The key idea is to enforce the gradients from multi tasks balanced so that no tasks are ignored in the training.  The authors also demonstrated that the technique can improve test errors over single task learning and uncertainty weighting on a large real-world dataset. \n\nIt is an interesting paper with a novel approach to multi-task learning . To improve the paper, it would be helpful to evaluate the method under various settings.  My detailed comments are below.\n\n1. Multi-task learning can have various settings. For example, we may have multiple groups of tasks, where tasks are correlated within groups but tasks in different groups are not much correlated.  Also, tasks may have hierarchical correlation structures.  These patterns often appear in biological datasets.  I am wondering how a variety of multi-task settings can be handled by the proposed approach.  It would be helpful to discuss the conditions where we can benefit from the proposed method. \n\n2. One intuitive approach to task balancing would be to weight each task objective based on the variance of each task.   It would be helpful to add a few simple and intuitive baselines in the experiments.  \n\n3. In Section 4, it would be great to have more in-depth simulations (e.g., multi-task learning in various settings).  Also, in the bottom right panel in Figure 2, GrandNorm and equal weighting decrease test errors effectively even after 15000 steps but uncertainty weighting seems to reach a plateau. Discussions on this would be useful. \n\n4. It would be useful to discuss the implementation of the method as well.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-NEG],[NOV-POS],[ETH-NEG]]