This paper empirically investigates the performance of character-level NMT systems in the face of character-level noise, both synthesized and natural.  The results are not surprising:\n\n* NMT is terrible with noise. \n\n* But it improves on each noise type when it is trained on that noise type. \n\nWhat I like about this paper is that:\n\n1) The experiments are very carefully designed and thorough. \n\n2) This problem might actually matter.  Out of curiosity, I ran the example (Table 4) through Google Translate, and the result was gibberish.  But as the paper shows, it\u2019s easy to make NMT robust to this kind of noise, and Google (and other NMT providers) could do this tomorrow.  So this paper could have real-world impact. \n\n3) Most importantly, it shows that NMT\u2019s handling of natural noise does *not* improve when trained with synthetic noise; that is, the character of natural noise is very different.  So solving the problem of natural noise is not so simple\u2026 it\u2019s a *real* problem.  Speculating, again: commercial MT providers have access to exactly the kind of natural spelling correction data that the researchers use in this paper, but at much larger scale.  So these methods could be applied in the real world.  (It would be excellent if an outcome of this paper was that commercial MT providers answered it\u2019s call to provide more realistic noise by actually providing examples.) \n\nThere are no fancy new methods or state-of-the-art numbers in this paper.  But it\u2019s careful, curiosity-driven empirical research of the type that matters, and it should be in ICLR.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]