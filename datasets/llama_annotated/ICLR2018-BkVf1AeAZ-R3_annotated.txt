The paper proposes a method which jointly learns the label embedding (in the form of class similarity) and a classification model.  While the motivation of the paper makes sense, the model is not properly justified, and I learned very little after reading the paper. \n\nThere are 5 terms in the proposed objective function. There are also several other parameters associated with them: for example, the label temperature of z_2\u2019\u2019 and and parameter alpha in the second last term etc. \n\nFor all the experiments, the same set of parameters are used, and it is claimed that \u201cthe method is robust in our experiment and simply works without fine tuning\u201d.  While I agree that a robust and fine-tuning-free model is ideal 1) this has to be justified by experiment. 2) showing the experiment with different parameters will help us understand the role each component plays.  This is perhaps more important than improving the baseline method by a few point, especially given that the goal of this work is not to beat the state-of-the-art[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]