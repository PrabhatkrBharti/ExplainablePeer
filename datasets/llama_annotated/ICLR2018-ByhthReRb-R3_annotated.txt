Properly capturing named entities for goal oriented dialog is essential, for instance location, time and cuisine for restaurant reservation.  Mots successful approaches have argued for separate mechanism for NE captures, that rely on various hacks and tricks.  This paper attempt to propose a comprehensive approach offers intriguing new ideas, but is too preliminary, both in the descriptions and experiments.  \n\nThe proposed methods and experiments are not understandable in the current way the paper is written: there is not a single equation, pseudo-code algorithm or pointer to real code to enable the reader to get a detailed understanding of the process.  All we have a besides text is a small figure (figure 1).  Then we have to trust the authors that on their modified dataset, the accuracies of the proposed method is around 100% while not using this method yields 0% accuracies? \n\nThe initial description (section 2)  leaves way too many unanswered questions:\n- What embeddings are used for words detected as NE?  Is it the same as the generated representation? \n- What is the exact mechanism of generating a representation for NE EECS545?  (end of page 2)\n- Is it correct that the same representation stored in the NE table is used twice?  (a) To retrieve the key (a vector) given the value (a string)  as the encoder input.  (b) To find the value that best matches a key at the decoder stage? \n- Exact description of the column attention mechanism: some similarity between a key embedding and embeddings representing each column? Multiplicative? Additive? \n- How is the system supervised?  Do we need to give the name of the column the Attention-Column-Query attention should focus on?  Because of this unknown, I could not understand the experiment setup and data formatting! \n\nThe list goes on...\n\nFor such a complex architecture, the authors must try to analyze separate modules as much as possible.  As neither the QA and the Babi tasks use the RNN dialog manager, while not start with something that only works at the sentence level. \n\nThe Q&A task could be used to describe a simpler system with only a decoder accessing the DB table.  Complexity for solving the Babi tasks could be added later[[CLA-NEG],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-NEG],[CST-POS],[NOV-NEG],[ETH-NEG]]