This paper proposes to use a hybrid of convolutional and recurrent networks to predict the DSL specification of a GUI given a screenshot of the GUI.\ n\n\nPros:\n\n\nThe paper is clear and the proposed problem is novel and well-defined. \n\nThe training data is synthetic, allowing for arbitrarily large training sets to be generated.   The authors have made their synthetic dataset publicly available.\ n\nThe method seems to work well based on the samples and ROC curves presented. \n\n\nCons:\n\nThis is mostly an application of an existing method to a new domain - - as stated in the related work section, effectively the same convnet+RNN architecture has been in common use for image captioning and other vision applications. \n\nThe UIs that are represented in the dataset seem quite simple; it\u2019s not clear that this will transfer to arbitrarily complex and multi-page UIs. \n\nThe main motivation for the proposed system seems to be for non-technical designers to be able to implement UIs just by drawing a mockup screenshot .  However, the paper hasn\u2019t shown that this is necessarily possible assuming the hand-designed mockups aren\u2019t pixel-for-pixel matches with a screenshot that could be generated by the \u201cDSL code -> screenshot\u201d mapping that this system learns to invert. \n\nThere exist a number of \u201cdrag and drop\u201d style UI design products (at least for HTML) that would seem to accomplish the same basic goal as the proposed system in a more reliable way.  (Though the proposed system does have the advantage of only requiring a screenshot created using any software, rather than being restricted to a particular piece of software.) \n\n\nOverall, the paper is well-written but the novelty and applicability seems a bit limited[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-NEG],[NOV-NEG],[ETH-NEG]]