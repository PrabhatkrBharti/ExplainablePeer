This paper considers the problem of self-normalizing models. This kind\nof approaches, such as NCE (Noise Contrastive Estimation) is very\npromising and important to provide efficient and large vocabulary\nlanguage models. \n\nBy interpreting the NCE in terms of matrix factorization allows the\nauthors to better explain this learning criterion and more\nspecifically the self-normalizing mechanism. \n\nHowever, the first (theoritical) contribution is to make the link\nbetween matrix decomposition and sampling based objective.  This was\nalready shown for negative sampling in the paper of Melamud et al. in\nEMNLP 2017. Therefore, nothing new here, the difference is slight. \nMoreover, this paper is only cited in the experimental part, while the\ncontribution should be far more emphasized by the authors. \n\nThe second part makes the link with the self-normalization. This is\nnot really surprising. This was already explained in the same way in\npapers from Pihlaja,Gutmann and Hyvarinen published in 2010/12[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-NEG],[ENG-POS],[ACC-POS],[CST-NEG],[NOV-NEG],[ETH-POS]]