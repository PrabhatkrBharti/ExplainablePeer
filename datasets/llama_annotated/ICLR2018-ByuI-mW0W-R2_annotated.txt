The quality of the paper is good, and clarity is mostly good.  The proposed metric is interesting,;  but it is hard to judge the significance without more thorough experiments demonstrating that it works in practice. \n\nPros:\n - clear definitions of terms\n - overall outline of paper is good\n - novel metric. \n\nCons\n - text is a bit over-wordy, and flow/meaning sometimes get lost.  A strict editor would be helpful, because the underlying content is good\n - odd that your definition of generalization in GANs appears immediately preceding the section titled \"Generalisation in GANs\"\n - the paragraph at the end of the \"Generalisation in GANs\" section is confusing.  I think this section and the previous (\"The objective of unsupervised learning\") could be combined, removing some repetition, adding some subtitles to improve clarity.  This would cut down the text a bit to make space for more experiments. \n - why is your definition of generalization that the test set distance is strictly less than training set ?  I would think this should be less-than-or-equal \n - there is a sentence that doesn't end at the top of p.3: \"... the original GAN paper showed that [ends here]. \"\n - should state in the abstract what your \"notion of generalization\" for gans is, instead of being vague about it. \n - more experiments showing a comparison of the proposed metric to others (e.g. inception score, Mturk assessments of sample quality, etc.) would be necessary to find the metric convincing \n - what is a \"pushforward measure\"?  (p.2)\n - the related work section is well-written and interesting, but it's a bit odd to have it at the end.  Earlier in the work (e.g. before experiments and discussion) would allow the comparison with MMD to inform the context of the introduction. \n - there are some errors in figures that I think were all mentioned by previous commentators[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]