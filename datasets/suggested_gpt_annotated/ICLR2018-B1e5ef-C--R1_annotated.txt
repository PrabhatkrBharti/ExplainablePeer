The main insight in this paper is that LSTMs can be viewed as producing a sort of sketch of tensor representations of n-grams.   This allows the authors to design a matrix that maps bag-of-n-gram embeddings into the LSTM embeddings.   They then show that the result matrix satisfies a restricted isometry condition.    Combining these results allows them to argue that the classification performance based on LSTM embeddings is comparable to that based on bag-of-n-gram embeddings.  \n\nI didn't check all the proof details, but based on my knowledge of compressed sensing theory, the results seem plausible.   I think the paper is a nice contribution to the theoretical analysis of LSTM word embeddings.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]