This paper investigates the effect of adversarial training.  Based on experiments using CIFAR10, the authors show that adversarial training is effective in protecting against \"shared\" adversarial perturbation, in particular against universal perturbation.  In contrast, it is less effective to protect against singular perturbations.  Then they show that singular perturbation are less robust to image transformation, meaning after image transformation those perturbations are no longer effective.  Finally, they show that singular perturbations can be easily detected. \n\nI like the message conveyed in this paper.  However, as the statements are mostly backed by experiments, then I think it makes sense to ask how statistically significant the present results are.  Moreover, is CIFAR 10 experiments conclusive enough. [[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEU],[ETH-NEU]]