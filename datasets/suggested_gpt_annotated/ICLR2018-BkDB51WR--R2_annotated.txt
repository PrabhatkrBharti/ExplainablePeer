The papers proposes a recurrent neural network-based model to learn the temporal evolution of a probability density function.  A Monte Carlo method is suggested for approximating the high dimensional integration required for multi-step-ahead prediction. \n\nThe approach is tested on two artificially generated datasets and on two real-world datasets, and compared with standard approaches such as the autoregressive model, the Kalman filter, and a regression LSTM.\ n\nThe paper is quite dense and quite difficult to follow, also due to the complex notation used by the authors.\ n\nThe comparison with other methods is very week, the authors compare their approach with two very simple alternatives, namely a first-order autoregressive mode and the Kalman filter.   More sophisticated should have been employed.[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEU],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEU],[ETH-NEU]]