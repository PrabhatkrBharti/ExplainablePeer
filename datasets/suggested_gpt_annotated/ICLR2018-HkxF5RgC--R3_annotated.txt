The paper proposes improving performance of large RNNs by combing techniques of model pruning and persistent kernels.  The authors further propose model-pruning optimizations which are aware of the persistent implementation. \n\nIt's not clear if the paper is relevant to the ICLR audience due to its emphasize on low-level optimization which has little insight in learning representations.  The exposition in the paper is also not well-suited for people without a systems background, although I'll admit I'm mostly using myself as a proxy for the average machine learning researcher here.  For instance, the authors could do more to explain Lamport Timestamps than a 1974 citation. \n\nModulo problems of relevance and expected audience, the paper is well-written and presents useful improvements in performance of large RNNs, and the work has potential for impact in industrial applications of RNNs.  The work is clearly novel, and the contributions are clear and well-justified using experiments and ablations.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]