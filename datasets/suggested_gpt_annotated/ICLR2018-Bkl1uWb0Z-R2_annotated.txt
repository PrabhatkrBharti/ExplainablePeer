This paper describes a method to induce source-side dependency structures in service to neural machine translation.  The idea of learning soft dependency arcs in tandem with an NMT objective is very similar to recent notions of self-attention (Vaswani et al., 2017, cited) or previous work on latent graph parsing for NMT (Hashimoto and Tsuruoka, 2017, cited).  This paper introduces three innovations: (1) they pass the self-attention scores through a matrix-tree theorem transformation to produce marginals over tree-constrained head probabilities; (2) they explicitly specify how the dependencies are to be used, meaning that rather than simply attending over dependency representations with a separate attention, they select a soft word to attend to through the traditional method, and then attend to that word\u2019s soft head (called Shared Attention in the paper); and (3) they gate when attention is used.  I feel that the first two ideas are particularly interesting.  Unfortunately, the results of the NMT experiments are not particularly compelling, with overall gains over baseline NMT being between 0.6 and 0.8 BLEU.  However, they include a useful ablation study that shows fairly clearly that both ideas (1) and (2) contribute equally to their modest gains, and that without them (FA-NMT Shared=No in Table 2), there would be almost no gains at all.  Interesting side-experiments investigate their accuracy as a dependency parser, with and without a hard constraint on the system\u2019s latent dependency decisions. \n\nThis paper has some very good ideas, and asks questions that are very much worth asking.  In particular, the question of whether a tree constraint is useful in self-attention is very worthwhile.  Unfortunately, this is mostly a negative result, with gains over \u201cflat attention\u201d being relatively small.  I also like the \u201cShared Attention\u201d - it makes a lot of sense to say that if the \u201csemantic\u201d attention mechanism has picked a particular word, one should also attend to that word\u2019s head; it is not something I would have thought of on my own.  The paper is also marred by somewhat weak writing, with a number of disfluencies and awkward phrasings making it somewhat difficult to follow. \n\nIn terms of specific criticisms:\n\nI found the motivation section to be somewhat weak.  We need a better reason than morphology to want to do source-side dependency parsing.  All published error analyses of strong NMT systems (Bentivogli et al, EMNLP 2016; Toral and Sanchez-Cartagena, EACL 2017; Isabelle et al, EMNLP 2017) have shown that morphology is a strength, not a weakness of these systems, and the sorts of head selection problems shown in Figure 1 are, in my experience, handled capably by existing LSTM-based systems. \n\nThe paper mentions \u201csignificant improvements\u201d in only two places: the introduction and the conclusion.  With BLEU score differences being so low, the authors should specify how statistical significance is measured;  ideally using a technique that accounts for the variance of random restarts (i.e.: Clark et al, ACL 2011). \nEquation (3): I couldn\u2019t find the definition for H anywhere. \n\nSentence before Equation (5): I believe there is a typo here, \u201cf takes z_i\u201d should be \u201cf takes u_t\u201d. \n\nFirst section of Section 3: please cite the previous work you are talking about in this sentence. \n\nMy understanding was that the dependency marginals in p(z_{i,j}=1|x,\\phi) in Equation (11) are directly used as \\beta_{i,j}.  If I\u2019m correct, that\u2019s probably worth spelling out explicitly in Equation (11): \\beta_{i,j} = p(z_{i,j}=1|x,\\phi) = \u2026. \n\nI don\u2019t don\u2019t feel like the clause between equations (17) and (18), \u201cwhen sharing attention weights from the decoder with the encoder\u201d is a good description of your clever \u201cshared attention\u201d idea.  In general, I found this region of the paper, including these two equations and the text between them, very difficult to follow. \n\nSection 4.4: It\u2019s very very good that you compared to \u201cflat attention\u201d,  but it\u2019s too bad for everyone cheering for linguistically-informed syntax that the results weren\u2019t better. \n\nTable 5: I had a hard time understanding Table 5 and the corresponding discussion.  What are \u201cproduction percentages\u201d? \n\nFinally, it would have been interesting to include the FA system in the dependency accuracy experiment (Table 4), to see if it made a big difference there[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEU]]