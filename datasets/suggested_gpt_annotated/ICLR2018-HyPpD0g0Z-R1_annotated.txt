The paper discusses ways to guard against adversarial domain shifts with so-called counterfactual regularization.  The main idea is that in several datasets there are many instances of images for the same object/person, and that taking this into account by learning a classifier that is invariant to the superficial changes (or \u201cstyle\u201d features, e.g. hair color, lighting, rotation etc.) can improve the robustness and prediction accuracy.  The authors show the benefit of this approach, as opposed to the naive way of just using all images without any grouping, in several toy experimental settings. \n\nAlthough I really wanted to like the paper, I have several concerns, First and most importantly, the paper is not citing several important related work.  Especially, I have the impression that the paper is focusing on a very similar setting (causally) to the one considered in  [Gong et al. 2016] (http://proceedings.mlr.press/v48/gong16.html), as can be seen from Fig. 1. Although not focusing on classification directly, this paper also tries to a function T(X) such that P(Y|T(X)) is invariant to domain change.  Moreover, in that paper, the authors assume that even the distribution of the class can be changed in the different domains (or interventions in this paper).33.07 \nBesides, there are also other less related papers, e.g. http://proceedings.mlr.press/v28/zhang13d.pdf, https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/10052/0, https://arxiv.org/abs/1707.09724, (or potentially https://arxiv.org/abs/1507.05333 and https://arxiv.org/abs/1707.06422), that I think may be mentioned for a more complete picture.  Since there is some related work, it may be also worth to compare with it, or use the same datasets. \n\nI\u2019m also not very happy with the term \u201ccounterfactual\u201d. As the authors mention in footnote, this is not the correct use of the term, since counterfactual means \u201cagainst the fact\u201d.  For example, a counterfactual query is \u201cwe gave the patient a drug and the patient died, what would have happened if we didn\u2019t give the drug? \u201d In this case, these are just different interventions on possibly the same object.  I\u2019m not sure that in the practical applications one can assure that the noise variables stay the same, which, as the authors correctly mention, would make it a bit closer to counterfactuals.  It may sound pedantic, but I don\u2019t understand why use the wrong and confusing terminology for no specific reason, also because in practice the paper reduces to the simple idea of finding a classifier that doesn\u2019t vary too much in the different images of the single object. \n\n**EDIT**: I was satisfied with the clarifications from the authors and I appreciated the changes that they did with respect to the related work and terminology, so I changed my evaluation from a 5 (marginally below threshold) to a 7 (good paper, accept).[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]