The paper studies catastrophic forgetting, which is an important aspect of deep reinforcement learning (RL).  The problem formulation is connected to safe RL, but the emphasis is on tasks where a DQN is able to learn to avoid catastrophic events as long as it avoids forgetting.  The proposed method is novel, but perhaps the most interesting aspect of this paper is that they demonstrate that \u201cDQNs  are susceptible to periodically repeating mistakes\u201d.  I believe this observation, though not entirely novel, will inspire many researchers to study catastrophic forgetting and propose improved strategies for handling these issues. \n\nThe paper is accurate, very well written (apart from a small number of grammatical mistakes) and contains appealing motivations to its key contributions .In particular, I find the basic of idea of introducing a component that represents fear natural, promising and novel.  \n\nStill, many of the design choices appear quite arbitrary and can most likely be improved upon.  In fact, it is not difficult to design examples for which the proposed algorithm would be far from optimal.  Instead I view the proposed techniques mostly as useful inspiration for future papers to build on.  As a source of inspiration, I believe that this paper will be of considerable importance and I think many people in our community will read it with great interest.  The theoretical results regarding the properties of the proposed algorithm are also relevant, and points out some of its benefits, though I do not view the results as particularly strong.  \n\nTo conclude, the submitted manuscript contains novel observations and results and is likely to draw additional attention to an important aspect of deep reinforcement learning.  A potential weakness with the paper is that the proposed strategies appear to be simple to improve upon and that they have not convinced me that they would yield good performance on a wider set of problems. \n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]