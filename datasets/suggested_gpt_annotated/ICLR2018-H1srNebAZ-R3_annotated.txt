This paper presents an experimental study on the behavior of the units of neural networks.  In particular, authors aim to show that units behave as binary classifiers during training and testing.  \n\nI found the paper unnecessarily longer than the suggested 8 pages.  The focus of the paper is confusing: while the introduction discusses about works on CNN model interpretability, the rest of the paper is focused on showing that each unit behaves consistently as a binary classifier, without analyzing anything in relation to interpretability.   I think some formal formulation and specific examples on the relevance of the partial derivative of the loss with respect to the activation of a unit will help to understand better the main idea of the paper.  Also, quantitative figures would be useful to get the big picture.  For example in Figures 1 and 2 the authors show the behavior of some specific units as examples, but it would be nice to see a graph showing quantitatively the behavior of all the units at each layer.  It would be also useful to see a comparison of different CNNs and see how the observation holds more or less depending on the performance of the network[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEU],[ETH-NEU]]