The authors use deep learning to learn a surrogate model for the motion vector in the advection-diffusion equation that they use to forecast sea surface temperature.  In particular, they use a CNN encoder-decoder to learn a motion field, and a warping function from the last component to provide forecasting.  \n\nI like the idea of using deep learning for physical equations.  I would like to see a description of the algorithm with the pseudo-code in order to understand the flow of the method.  I got confused at several points because it was not clear what was exactly being estimated with the CNN.  Having an algorithmic environment would make the description easier.  I know that authors are going to publish the code, but this is not enough at this point of the revision.  \n\nPhysical processes in Machine learning have been studied from the perspective of Gaussian processes. Just to mention a couple of references \u201cLinear latent force models using Gaussian processes\u201d and \"Numerical Gaussian Processes for Time-dependent and Non-linear Partial Differential Equations \"\n\nIn Theorem 2, do you need to care about boundary conditions for your equation?  I didn\u2019t see any mention to those in the definition for I(x,t). You only mention initial conditions.  How do you estimate the diffusion parameter D?  Are you assuming isotropic diffusion? Is that realistic?  Can you provide more details about how you run the data assimilation model in the experiments? Did you use your own code[[CLA-POS],[JUS-POS],[DEP-NEG],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEU],[ETH-NEU]]