The paper proposed to encode text into a binary matrix by using a compressing code for each word in each matrix row.  The idea is interesting, and overall introduction is clear. \n\nHowever, the work lacks justification for this particular way of encoding, and no comparison for any other encoding mechanism is provided except for the one-hot encoding used in Zhang & LeCun 2015.  The results using this particular encoding are not better than any previous work. \n\nThe network architecture seems to be arbitrary and unusual.  It was designed with 4 convolutional layers stacked together for the first layer, while a common choice is to just make it one convolutional layer with 4 times the output channels.  The depth of the network is only 5, even with many layers listed in table 5. \n\nIt uses 1-D convolution across the word dimension (inferred from the feature size in table 5), which means the convolutional layers learn intra-word features for the entire text but not any character-level features.  This does not seem to be reasonable. \n\nOverall, the lack of comparisons and the questionable choices for the networks render this work lacking significance to be published in ICLR 2018.[[CLA-POS],[JUS-NEG],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]