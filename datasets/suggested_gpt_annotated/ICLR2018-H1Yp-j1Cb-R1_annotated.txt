It is well known that the original GAN (Goodfellow et al.) suffers from instability and mode collapsing . Indeed, existing work has pointed out that the standard GAN training process may not converge if we insist on obtaining pure strategies (for the minmax game).  The present paper proposes to obtain mixed strategy through an online learning approach.  Online learning (no regret) algorithms have been used in finding an equilibrium for zero sum game. However, most theoretical convergence results are known for convex-concave loss.  One interesting theoretical contribution of the paper is to show that convergence result can be proved if one player is a shallow network (and concave in M) .In particular, the concave player plays the FTRL algorithm with standard L2 regularization term.  The regret of concave player can be bounded using existing result for FTRL. The regret for the other player is more interesting: it uses the fact the adversary's strategy doesn't change too drastically.  Then a lemma by Kalai and Vempala can be used.  The theory part of the paper is reasonable and quite well written.  \n\nBased on the theory developed, the paper presents a practical algorithm.  Compared to the standard GAN training, the new algorithm returns mixed strategy and examine several previous models (instead of the latest) in each iteration.  The paper claims that this may help to prevent model collapsing. \n\nHowever, the experimental part is less satisfying.  From figure 2, I don't see much advantage of Checkhov GAN.  In other experiments, I don't see much improvement neither (CIFAR10 and CELEBA). The paper didn't really compare other popular GAN models, especially WGAN and its improved version , which is already quite popular by now and should be compared with. \n\nOverall, I think it is a borderline paper. \n\n-------------------------\nI read the response and the new experimental results regarding WGAN. \nThe experimental results make more sense now. \nIt would be interesting to see whether the idea can be applied to more recent GAN models and still perform better .\nI raised my score to 7[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]