This paper proposes a new method, called VCL, for continual learning.  This method is a combination of the online variational inference for streaming environment with Monte Carlo method.  The authors further propose to maintain a coreset which consists of representative data points from the past tasks.  Such a coreset is used for the main aim of avoiding the catastrophic forgetting problem in continual learning.  Extensive experiments shows that VCL performs very well, compared with some state-of-the-art methods.  \n\nThe authors present two ideas for continual learning in this paper: (1) Combination of online variational inference and sampling method, (2) Use of coreset to deal with the catastrophic forgetting problem.  Both ideas have been investigated in Bayesian literature, while (2) has been recently investigated in continual learning.  Therefore, the authors seems to be the first to investigate the effectiveness of (1) for continual learning.  From extensive experiments, the authors find that the first idea results in VCL which can outperform other state-of-the-art approaches, while the second idea plays little role.  \n\nThe finding of the effectiveness of idea (1) seems to be significant.  The authors did a good job when providing a clear presentation, a detailed analysis about related work, an employment to deep discriminative models and deep generative models, and a thorough investigation of empirical performance. \n\nThere are some concerns the authors should consider:\n- Since the coreset plays little role in the superior performance of VCL, it might be better if the authors rephrase the title of the paper.  When the coreset is empty, VCL turns out to be online variational inference [Broderich et al., 2013; Ghahramani & Attias, 2000].  Their finding of the effectiveness of online variational inference for continual learning should be reflected in the writing of the paper as well. \n- It is unclear about the sensitivity of VCL with respect to the size of the coreset. The authors should investigate this aspect. \n- What is the trade-off when the size of the coreset increases?\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEU]]