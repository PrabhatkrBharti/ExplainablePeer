In this paper, the authors propose a method of compressing network by means of weight ternarization.  The network weights ternatization is formulated in the form of loss-aware quantization, which originally proposed by Hou et al. (2017). \n\nTo this reviewer\u2019s understanding, the proposed method can be regarded as the extension of the previous work of LAB and TWN, which can be the main contribution of the work. \n\nWhile the proposed method achieved promising results compared to the competing methods, it is still necessary to compare their computational complexity, which is one of the main concerns in network compression. \n\nIt would be appreciated to have discussion on the results in Table 2, which tells that the performance of quantized networks is better than the full-precision network[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEU]]