This paper studies the generalization properties of 2-layer neural networks based on Fourier analysis.  Studying the generalization property of neural network is an important problem and Fourier-based analysis is a promising direction, as shown in (Lee et al., 2017).  However, I am not satisfied with the results in the current version. \n\n1) The main theoretical results are on the sin activation functions instead of commonly used ReLU functions.  \n\n2) Even if for sin activation functions, the analysis is NOT complete.  The authors claimed in the abstract that gradient-based methods will converge to generalizable local minima.  However, Corollary 3 is only a concentration bound on the gradient.  There is a gap that how this corollary implies generalization.  The paragraph below this corollary is only a high level intuition.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEG],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEU],[ETH-NEU]]