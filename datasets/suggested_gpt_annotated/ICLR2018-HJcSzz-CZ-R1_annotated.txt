This paper is an extension of the \u201cprototypical network\u201d which will be published in NIPS 2017.  The classical few-shot learning has been limited to using the unlabeled data, while this paper considers employing the unlabeled examples available to help train each episode.  The paper solves a new semi-supervised situation, which is more close to the setting of the real world, with an extension of the prototype network.   Sufficient implementation detail and analysis on results. \n\nHowever, this is definitely not the first work on semi-supervised formed few-shot learning.  There are plenty of works on this topic [R1, R2, R3].  The authors are advised to do a thorough survey of the relevant works in Multimedia and computer vision community.  \n \nAnother concern is that the novelty.  This work is highly incremental since it is an extension of existing prototypical networks by adding the way of leveraging the unlabeled data.  \n\nThe experiments are also not enough. Not only some other works such as [R1, R2, R3]; but also the other na\u00efve baselines should also be compared, such as directly nearest neighbor classifier, logistic regression, and neural network in traditional supervised learning.  Additionally, in the 5-shot non-distractor setting on tiered ImageNet, only the soft kmeans method gets a little bit advantage against the semi-supervised baseline, does it mean that these methods are not always powerful under different dataset? \n\n[R1] \u201cVideostory: A new multimedia embedding for few-example recognition and translation of events,\u201d in ACM MM, 2014\n\n[R2] \u201cTransductive Multi-View Zero-Shot Learning\u201d, IEEE TPAMI 2015\n\n[R3] \u201cVideo2vec embeddings recognize events when examples are scarce,\u201d IEEE TPAMI 2014\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEG],[ETH-NEU]]