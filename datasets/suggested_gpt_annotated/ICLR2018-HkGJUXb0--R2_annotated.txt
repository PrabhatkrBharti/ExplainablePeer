This paper proposes a tensor train decomposition with a ring structure for function approximation and data compression.  Most of the techniques used are well-known in the tensor community (outside of machine learning).  The main contribution of the paper is the introduce such techniques to the ML community and presents experimental results for support. \n\nThe paper is rather preliminary in its examination.  For example, it is claimed that the proposed decomposition provides \"enhanced representation ability\", but this is not justified rigorously either via more comprehensive experimentation or via a theoretical justification.  Furthermore, the paper lacks in novelty aspect, as it is uses mostly well-known techniques[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEG],[ETH-NEU]]