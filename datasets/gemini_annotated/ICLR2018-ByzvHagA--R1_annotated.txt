The authors propose a penalization term that enforces decorrelation between the dimensions of the representation  \nThey show that it can be included as additional term in cost functions to train generic models. \nThe idea is simple and it seems to work for the presented examples. \n\nHowever, they talk about gradient descent using this extra term, but I'd like to see the derivatives of the \nproposed term depending on the parameters of the model (and this depends on the model!).  On the other hand, \ngiven the expression of the proposed regulatization,\nit seems to lead to non-convex optimization problems which are hard to solve. Any comment on that? .\n\nMoreover, its results are not quantitatively compared to other Non-Linear generalizations of PCA/ICA designed for similar goals (e.g. those cited in the \"related work\" section or others which have been proved to be consistent non-linear generalizations of PCA such as: Principal Polynomial Analysis, Dimensionality Reduction via Regression that follow the family introduced in the book of Jolliffe, Principal Component Analysis). \n\nMinor points: Fig.1 conveys not that much information[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]