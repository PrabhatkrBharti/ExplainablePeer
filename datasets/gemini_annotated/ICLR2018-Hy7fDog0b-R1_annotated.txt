Quick summary:\nThis paper shows how to train a GAN in the case where the dataset is corrupted by some measurement noise process.  They propose to introduce the noise process into the generation pipeline such that the GAN generates a clean image, corrupts its own output and feeds that into the discriminator.  The discriminator then needs to decide whether this is a real corrupted measurement or a generated one.   The method is demonstrated to the generate better results than the baseline on a variety of datasets and noise processes. \n\nQuality:\nI found this to be a nice paper - it has an important setting to begin with and the proposed method is clean and elegant albeit a bit simple.  \n\nOriginality:\nI'm pretty sure this is the first paper to tackle this problem directly in general. \n\nSignificance:\nThis is an important research direction as it is not uncommon to get noisy measurements in the real world under different circumstances.  \n\nPros:\n* Important problem \n* elegant and simple solution \n* nice results and decent experiments (but see below) \n\nCons:\n* The assumption that the measurement process *and* parameters are known is quite a strong one.  Though it is quite common in the literature to assume this, it would have been interesting to see if there's a way to handle the case where it is unknown (either the process, parameters or both). \n* The baseline experiments are a bit limited - it's clear that such baselines would never produce samples which are any better than the \"fixed\" version which is fed into them.  I can't however, think of other baselines other than \"ignore\" so I guess that is acceptable. \n* I wish the authors would show that they get a *useful* model eventually - for example, can this be used to denoise other images from the dataset? \n\nSummary:\nThis is a nice paper which deals with an important problem, has some nice results and while not groundbreaking, certainly merits a publication.[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]