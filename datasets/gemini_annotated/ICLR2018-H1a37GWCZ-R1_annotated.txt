This paper presents simple but useful ideas for improving sentence embedding by drawing from more context.  The authors build on the skip thought model where a sentence is predicted conditioned on the previous sentence; they posit that one can obtain more information about a sentence from other \"governing\" sentences in the document such as the title of the document, sentences based on HTML, sentences from table of contents, etc.  The way I understand it, previous sentence like in SkipThought provides more local and discourse context for a sentence whereas other governing sentences provide more semantic and global context. \n\nHere are the pros of this paper:\n1) Useful contribution in terms of using broader context for embedding a sentence. \n2) Novel and simple \"trick\" for generating OOV words by mapping them to \"local\" variables and generating those variables. \n3) Outperforms SkipThought in evals .\n\nCons:\n1) Coreference eval: No details are provided for how the data was annotated for the coreference task.  This is crucial to understanding the reliability of the evaluation as this is a new domain for coreference.  Also, the authors should make this dataset available for replicability.  Also, why have the authors not used this embedding for eval on standard coreference datasets like OntoNotes.  Please clarify.\n2) It is not clear to me how the model learns to generate specific OOV variables.  Can the authors clarify how does the decoder learns to generate these words. \n\nClarifications:\n1) In section 6.1, what is the performance of skip-thought with the same OOV trick as this paper? \n2) What is the exact heuristic in \"Text Styles\" in section 3.1? Should be stated for replicability.[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]