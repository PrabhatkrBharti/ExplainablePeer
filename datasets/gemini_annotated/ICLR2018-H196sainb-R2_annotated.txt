The paper proposes a method to learn bilingual dictionaries without parallel data using an adversarial technique.  The task is interesting and relevant, especially for in low-resource language pair settings.\ n\nThe paper, however, misses comparison against important work from the literature that is very relevant to their task \u2014 decipherment (Ravi, 2013; Nuhn et al., 2012; Ravi & Knight, 2011) and other approaches like CCA. \n\nThe former set of works, while focused on machine translation also learns a translation table in the process . Besides, the authors also claim that their approach is particularly suited for low-resource MT and list this as one of their contributions . Previous works have used non-parallel and comparable corpora to learn MT models and for bilingual lexicon induction.  The authors seem aware of corpora used in previous works (Tiedemann, 2012) yet provide no comparison against any of these methods.  While some of the bilingual lexicon extraction works are cited (Haghighi et al., 2008; Artetxe et al., 2017), they do not demonstrate how their approach performs against these baseline methods.  Such a comparison, even on language pairs which share some similarities (e.g., orthography), is warranted to determine the effectiveness of the proposed approach .\n\nThe proposed methodology is not novel, it rehashes existing adversarial techniques instead of other probabilistic models used in earlier works.  \n\nFor the translation task, it would be useful to see performance of a supervised MT baseline (many tools available in open-source) that was trained on similar amount of parallel training data (60k pairs) and see the gap in performance with the proposed approach. \n\nThe paper mentions that the approach is \u201cunsupervised\u201d.  However, it relies on bootstrapping from word embeddings learned on Wikipedia corpus, which is a comparable corpus even though individual sentences are not aligned across languages . How does the quality degrade if word embeddings had to be learned from scratch or initialized from a different source?[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]