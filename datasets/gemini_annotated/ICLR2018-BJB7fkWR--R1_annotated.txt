In this paper, the authors propose a new approach for learning underlying structure of visually distinct games. \n\nThe proposed approach combines convolutional layers for processing input images, Asynchronous Advantage Actor Critic for deep reinforcement learning task and adversarial approach to force the embedding representation to be independent of the visual representation of games.  \n\nThe network architecture is suitably described and seems reasonable to learn simultaneously similar games, which are visually distinct.  However, the authors do not explain how this architecture can be used to do the domain adaptation.  \nIndeed, if some games have been learnt by the proposed algorithm, the authors do not precise what modules have to be retrained to learn a new game.  This is a critical issue, because the experiments show that there is no gain in terms of performance to learn a shared embedding manifold (see DA-DRL versus baseline in figure 5). \nIf there is a gain to learn a shared embedding manifold, which is plausible, this gain should be evaluated between a baseline, that learns separately the games, and an algorithm, that learns incrementally the games.  \nMoreover, in the experimental setting, the games are not similar but simply the same. \n\nMy opinion is that this paper is not ready for publication.  The interesting issues are referred to future works.\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]