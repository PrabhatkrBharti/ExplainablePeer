* This paper models images with a latent code representation, and then tries to modify the latent code to minimize changes in image space, while changing the classification label.  As the authors indicate, it lies in the space of algorithms looking to modify the image while changing the label (e.g. LIME etc). \n\n* This is quite an interesting paper with a sensible goal.  It seems like the method could be more informative than the other methods.   However, there are quite a number of problems, as explained below.\n\n* The explanation of eqs 1 and 2 is quite poor.  \\alpha in (1) seems to be \\gamma in Alg 1 (line 5). \"L_target is a target objective which can be a negative class probability ..\" this assumes that the example is a positive class.  Could we not also apply this to negative examples? \n\n\"or in the case of heart failure, predicted BNP level\" -- this doesn't make sense to me -- surely it would be necessary to target an adjusted BNP level?  Also specific details should be reserved until a general explanation of the problem has been made. \n\n* The trade-off parameter \\gamma is a \"fiddle factor\" -- how was this set for the lung image and MNIST examples?  Were these values different? \n\n* In typical ICLR style the authors use a deep network to learn the encoder and decoder networks.  It would be v interesting (and provide a good baseline) to use a shallow network (i.e. PCA) instead, and elucidate what advantages the deep network brings. \n\n* The example of 4/9 misclassification seems very specific. Does this method also work on say 2s and 3s?  Why have you not reported results for these kinds of tasks? \n\n* Fig 2: better to show each original and reconstructed image close by (e.g. above below or side-by-side). \n\nThe reconstructions show poor detail relative to the originals.   This loss of detail could be a limitation. \n\n* A serious problem with the method is that we are asked to evaluate it in terms of images like Fig 4 or Fig 8.  A serious study would involve domain experts and ascertain if Fig 4 conforms with what they are looking for. \n\n* The references section is highly inadequate -- no venues of publication are given.  If these are arXiv give the proper ref.  Others are published in conferences etc, e.g. Goodfellow et al is in Advances in Neural Information Processing Systems 27, 2014. \n\n* Overall: the paper contains an interesting idea, but given the deficiencies raised above I judge that it falls below the ICLR threshold. \n\n* Text:\n\nsec 2 para 4. \"reconstruction loss on the validation set was similar to the reconstruction loss on the validation set.\" ?? \n\n* p 3 bottom -- give size of dataset\n\n* p 5 AUC curve -> ROC curve\n\n* p 6 Fig 4 use text over each image to better specify the details given in the caption.\n\n\n\n[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]