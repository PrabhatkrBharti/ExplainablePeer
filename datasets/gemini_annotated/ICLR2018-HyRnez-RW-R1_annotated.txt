The authors present a scalable model for questioning answering that is able to train on long documents.  On the TriviaQA dataset, the proposed model achieves state of the art results on both domains (wikipedia and web).  The formulation of the model is straight-forward,  however I am skeptical about whether the results prove the premise of the paper (e.g. multi-mention reasoning is necessary).  Furthermore, I am slightly unconvinced about the authors' claim of efficiency.  Nevertheless, I think this work is important given its performance on the task. \n\n1. Why is this model successful?  Multi-mention reasoning or more document context? \nI am not convinced of the necessity of multi-mention reasoning, which the authors use as motivation, as shown in the examples in the paper.  For example, in Figure 1, the answer is solely obtained using the second last passage.  The other mentions provide signal, but does not provide conclusive evidence.  Perhaps I am mistaken, but it seems to me that the proposed model cannot seem to handle negation, can the authors confirm/deny this?  I am also skeptical about the computation efficiency of a model that scores all spans in a document (which is O(N^2), where N is the document length).  Can you show some analysis of your model results that confirm/deny this hypothesis? \n\n2. Why is the computational complexity not a function of the number of spans? \nIt seems like the derivations presents several equations that score a given span.  Perhaps I am mistaken, but there seems to be n^2 spans in the document that one has to score.  Shouldn't the computational complexity then be at least O(n^2), which makes it actually much slower than, say, SQuAD models that do greedy decoding O(2n + nm)? \n\nSome minor notes\n- 3.3.1 seems like an attention computation in which the attention context over the question and span is computed using the question.  Explicitly mentioning this may help the reading grasp the formulation. \n- Same for 3.4, which seems like the biattention (Seo 2017) or coattention (Xiong 2017) from previous squad work. \n- The sentence \"We define ... to be the embeddings of the l words of the sentence that contains s.\" is not very clear.  Do you mean that the sentence contains l words?  It could be interpreted that the span has l words. \n- There is a typo in your 3.7 \"level 1 complexity\": there is an extra O inside the big O notation.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-NEG],[NOV-POS],[ETH-NEG]]