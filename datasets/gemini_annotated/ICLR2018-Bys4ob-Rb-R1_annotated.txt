This paper develops a new differentiable upper bound on the performance of classifier when the adversarial input in l_infinity is assumed to be applied. \nWhile the attack model is quite general, the current bound is only valid for linear and NN with one hidden layer model, so the result is quite restrictive. \n\nHowever the new bound is an \"upper\" bound of the worst-case performance which is very different from the conventional sampling based \"lower\" bounds.  Therefore minimizing this upper bound together with a classification loss makes perfect sense and provides a theoretically sound approach to train a robust classifier. \nThis paper provides a gradient of this new upper bound with respect to model parameters so we can apply the usual first order optimization scheme to this joint optimization (loss + upper bound). \nIn conclusion, I recommend this paper to be accepted, since it presents a new and feasible direction of a principled approach to train a robust classifier,  and the paper is clearly written and easy to follow. \n \nThere are possible future directions to be developed. \n\n1. Apply the sum-of-squares (SOS) method.\nThe paper's SDP relaxation is the straightforward relaxation of Quadratic Program (QP), and in terms of SOS relaxation hierarchy, it is the first hierarchy.  One can increase the complexity going beyond the first hierarchy, and this should provides a computationally more challenging but tighter upper bound. \nThe paper already mentions about this direction and it would be interesting to see the experimental results. \n\n2. Develop a similar relaxation for deep neural networks.\nThe author already mentioned that they are pursuing this direction.  While developing the result to the general deep neural networks might be hard, residual networks maybe fine thanks to its structure.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]