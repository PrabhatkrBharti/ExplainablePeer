Summary: This paper studies a series of reinforcement learning (RL) techniques in combination with recurrent neural networks (RNNs) to model and synthesise molecules.  The experiments seem extensive, using many recently proposed RL methods,  and show that most sophisticated RL methods are less effective than the simple hill-climbing technique, with PPO is perhaps the only exception .  \n\nOriginality and significance:  \n\nThe conclusion from the experiments could be valuable to the broader sequence generation/synthesis field, showing that many current RL techniques can fail dramatically.  \n\nThe paper does not provide any theoretical contribution but nevertheless is a good application paper combining and comparing different techniques .\n\nClarity: The paper is generally well-written. However, I'm not an expert in molecule design, so might not have caught any trivial errors in the experimental set-up[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]