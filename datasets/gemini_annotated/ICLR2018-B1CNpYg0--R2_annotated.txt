\nThis paper illustrates a method to compute produce word embeddings on the fly for rare words, using a pragmatic combination of existing ideas: \n\n* Backing off to a separate decoder for rare words a la Luong and Manning (https://arxiv.org/pdf/1604.00788.pdf, should be cited, though the idea might be older). \n\n* Using character-level models a la Ling et al. \n\n* Using dictionary embeddings a la Hill et al. \n\nNone of these ideas are new before but I haven\u2019t seen them combined in this way before.  This is a very practical idea, well-explained with a thorough set of experiments across three different tasks.  The paper is not surprising  but this seems like an effective technique for people who want to build effective systems with whatever data they\u2019ve got. \n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-POS]]