This paper proposes a new reading comprehension model for multi-choice questions and the main motivation is that some options should be eliminated first to infer better passage/question representations. \n\nIt is a well-written paper,  however, I am not very convinced by its motivation, the proposed model and the experimental results.  \n\nFirst of all, the improvement is rather limited.  It is only 0.4 improvement overall on the RACE dataset;  although it outperforms GAR on 7 out of 13 categories;  but why is it worse on the other 6 categories?  I don\u2019t see any convincing explanations here. \n\nSecondly, in terms of the development of reading comprehension models, I don\u2019t see why we need to care about eliminating the irrelevant options.  It is hard to generalize to any other RC/QA tasks.  If the point is that the options can add useful information to induce better representations for passage/question, there should be some simple baselines in the middle that this paper should compare to.  The two baselines SAR and GAR both only induce a representation from paragraph/question, and finally compare to the representation of each option.  Maybe a simple baseline is to merge the question and all the options and see if a better document representation can be defined.  \n\nSome visualizations/motivational examples could be also useful to understand how some options are eliminated and how the document representation has been changed based on that.\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]