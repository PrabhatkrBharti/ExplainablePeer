In this work, the authors propose a sequence-to-sequence architecture that learns a mapping from a normalized sentence to a grammatically correct sentence.  The proposed technique is a simple modification to the standard encoder-decoder paradigm which makes it more efficient and better suited to this task.  The authors evaluate their technique using three morphologically rich languages French, Polish and Russian and obtain promising results. \n\nThe morphological agreement task would be an interesting contribution of the paper, with wider potential.  But one concern that I have is regarding the evaluation metrics used for it.  Firstly, word accuracy rate doesn't seem appropriate, as it does not measure morphological agreement.  Secondly, sentence accuracy (w.r.t. the sentences from which the normalized sentences are derived) is not indicative of morphological agreement: even \"wrong\" sentences in the output could be perfectly valid in terms of agreement.  A grammatical error rate (fraction of grammatically wrong sentences produced) would probably be a better measure. \n\nAnother concern I have is regarding the quality of the baseline: Additional variants of the baseline models should be considered and the best one reported.  Specifically, in the conversation task, have the authors considered switching the order of normalized answer and context in the input?  Also, the word order of the normalized answer and/or context could be reversed (as is done in sequence-to-sequence translation models). \n\nAlso, many experimental details are missing from the draft: \n-- What are the sizes of the train/test sets derived from the OpenSubtitles database? \n-- Details of the validation sets used to tune the models. \n-- In Section 5.4, no details of the question-answer corpus are provided.  How many pairs were extracted?  How many were used for training and testing? \n-- In Section 5.4.1, how many assessors participated in the evaluation and how many questions were evaluated? \n-- In some of the tables (e.g. 6, 7, 8) which show example sentences from Polish, Russian and French, please provide some more information in the accompanying text on how to interpret these examples (since most readers may not be familiar with these languages). \n\nPros:\n-- Efficient model \n-- Proposed architecture is general enough to be useful for other sequence-to-sequence problems \n\nCons:\n-- Evaluation metrics for the morphological agreement task are unsatisfactory \n-- It would appear that the baselines could be improved further using standard techniques[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]