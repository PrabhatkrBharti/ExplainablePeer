Summary:\n\nThis paper proposes generative models for point clouds.  First, they train an auto-encoder for 3D point clouds,  somewhat similar to PointNet (by Qi et al.).  Then, they train generative models over the auto-encoder's latent space, both using a \"latent-space GAN\" (l-GAN) that outputs latent codes, and a Gaussian Mixture Model.  To generate point clouds, they sample a latent code and pass it to the decoder.  They also introduce a \"raw point cloud GAN\" (r-GAN) that, instead of generating a latent code, directly produces a point cloud.\ n\nThey evaluate the methods on several metrics.  First, they show that the autoencoder's latent space is a good representation for classification problems, using the ModelNet dataset.  Second, they evaluate the generative model on several metrics (such as Jensen-Shannon Divergence) and study the benefits and drawbacks of these metrics, and suggest that one-to-one mapping metrics such as earth mover's distance are desirable over Chamfer distance.  Methods such as the r-GAN score well on the latter by over-representing parts of an object that are likely to be filled. \n\nPros:\n\n- It is interesting that the latent space models are most successful, including the relatively simple GMM-based model.  Is there a reason that these models have not been as successful in other domains?\ n\n- The comparison of the evaluation metrics could be useful for future work on evaluating point cloud GANs.  Due to the simplicity of the method, this paper could be a useful baseline for future work. \n\n- The part-editing and shape analogies results are interesting, and it would be nice to see these expanded in the main paper. \n\nCons:\n\n- How does a model that simply memorizes (and randomly samples) the training set compare to the auto-encoder-based models on the proposed metrics? How does the diversity of these two models differ? \n\n- The paper simultaneously proposes methods for generating point clouds, and for evaluating them.  The paper could therefore be improved by expanding the section comparing to prior, voxel-based 3D methods, particularly in terms of the diversity of the outputs.  Although the performance on automated metrics is encouraging,  it is hard to conclude much about under what circumstances one representation or model is better than another. \n\n- The technical approach is not particularly novel.  The auto-encoder performs fairly well,  but it is just a series of MLP layers that output a Nx3 matrix representing the point cloud, trained to optimize EMD or Chamfer distance.  The most successful generative models are based on sampling values in the auto-encoder's latent space using simple models (a two-layer MLP or a GMM). \n\n- While it is interesting that the latent space models seem to outperform the r-GAN, this may be due to the relatively poor performance of r-GAN than to good performance of the latent space models, and directly training a GAN on point clouds remains an important problem.\ n\n- The paper could possibly be clearer by integrating more of the \"background\" section into later sections.  Some of the GAN figures could also benefit from having captions. \n\nOverall, I think that this paper could serve as a useful baseline for generating point clouds,  but I am not sure that the contribution is significant enough for acceptance.\n[[CLA-NEG],[JUS-NEG],[DEP-NEG],[FAI-NEG],[CON-NEG],[ENG-NEG],[ACC-NEG],[CST-NEG],[NOV-NEG],[ETH-NEG]]