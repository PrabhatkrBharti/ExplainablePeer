This work proposes a multi task learning framework for the modeling of clinical data in neurodegenerative diseases.  \nDifferently from previous applications of machine learning in neurodegeneration modeling, the proposed approach models the clinical data accounting for the bounded nature of cognitive tests scores.  The framework is represented by a feed-forward deep architecture analogous to a residual network.  At each layer a low-rank constraint is enforced on the linear transformation, while the cost function is specified in order to differentially account for the bounds of the predicted variables. \n\nThe idea of explicitly accounting for the boundedness of clinical scores is interesting,  although the assumption of the proposed model is still incorrect: clinical scores are defined on discrete scales.  For this reason the Gaussian assumption for the cost function used in the method is still not appropriate for the proposed application.  \nFurthermore, while being the main methodological drive of this work, the paper does not show evidence about improved predictive performance and generalisation when accounting for the boundedness of the regression targets.  \nThe proposed algorithm is also generally compared with respect to linear methods, and the authors could have provided a more rigorous benchmark including standard non-linear prediction approaches (e.g. random forests, NN, GP, \u2026).  \n\nOverall, the proposed methods seems to provide little added value to the large amount of predictive methods proposed so far for prediction in neurodegenerative disorders.  Moreover, the proposed experimental paradigm appears flawed.  What is the interest of predicting baseline (or 6 months at best) cognitive scores (relatively low-cost and part of any routine clinical assessment) from brain imaging data (high-cost and not routine)? \n\nOther remarks. \n\n- In section 2.2 and 4 there is some confusion between iteration indices and samples indices \u201ci\u201d.  \n\n- Contrarily to what is stated in the introduction, the loss functions proposed in page 3 (first two formulas) only accounts for the lower bound of the predicted variables.   \n\n-  Figure 2, synthetic data.  The scale of the improvement of the subspace difference is quite tiny, in the order of 1e-2 when compared to U, and of 1e-5 across iterations.  The loss function of Figure 2. b also does not show a strong improvement across iterations, while indicating a rather large instability of the optimisation procedure.  These aspects may be a sign of convergence issues.  \n\n- The dimensionality of the subspace representation importantly depends on the choice of the rank R of U and V.  This is a crucial parameters that is however not discussed nor analysed in the paper.  \n\n- The synthetic example of page 7 is quite misleading and potentially biased towards the proposed model.  The authors are generating the synthetic data according to the model, and it is thus not surprising that they managed to obtain the best performance.   In particular, due to the nonlinear nature of (1), all the competing linear models are expected to perform poorly in this kind of setting. \n\n- The computation time for the linear model shown in Table 3 is quite surprising (~20 minutes for linear regression of 5k observations).  Is there anything that I am missing?\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]