The paper proposed a copula-based modification to an existing deep variational information bottleneck model, such that the marginals of the variables of interest (x, y) are decoupled from the DVIB latent variable model, allowing the latent space to be more compact when compared to the non-modified version.  The experiments verified the relative compactness of the latent space, and also qualitatively shows that the learned latent features are more 'disentangled'.  However, I wonder how sensitive are the learned latent features to the hyper-parameters and optimizations? \n\nQuality: Ok. The claims appear to be sufficiently verified in the experiments.  However, it would have been great to have an experiment that actually makes use of the learned features to make predictions.  I struggle a little to see the relevance of the proposed method without a good motivating example. \n\nClarity: Below average.  Section 3 is a little hard to understand.  Is q(t|x) in Fig 1 a typo?  How about t_j in equation (5)?  There is a reference that appeared twice in the bibliography (1st and 2nd). \n\nOriginality and Significance: Average. The paper (if I understood it correctly) appears to be mainly about borrowing the key ideas from Rey et. al. 2014 and applying it to the existing DVIB model.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]