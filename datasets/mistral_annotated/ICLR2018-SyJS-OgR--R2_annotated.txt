I enjoyed reading the paper.  This is a very well written paper, the authors propose a method for speeding up the training time of Residual Networks based on the dynamical system view interpretation of ResNets.  In general I have a positive opinion about the paper, however, I\u2019d like to ask for some clarifications. \n\nI\u2019m not fully convinced by the interpretation of Eq. 5: \u201c\u2026 d is inversely proportional to the norm of the residual modules G(Yj)\u201d.  Since F(Yj) is not a constant, I think that d is inversely proportional to ||G(Yj)||/||F(Yj)||, however, in the interpretation the dependence on ||F(Yj)|| is ignored.  Could the authors comment on that? \n\nSection 4. 1 \u201c Each cycle itself can be regarded as a training process, thus we need to reset the learning rate value at the beginning of each training cycle and anneal the learning rate during that cycle. \u201d Is there any empirical evidence for this?  What would happen if the learning rate is not reset at the beginning of each cycle?  \n\nQuestions with respect to dynamical systems point of view: Eq. 4 assumes small value of h.  However, for ResNet there is no guarantee that the h would be small (e. g. in Appendix C the values between 0.25 and 1 are used).  Would the authors be willing to comment on the importance of the value of h?  In figure 1, pooling (strided convolutions) are not depicted between network stages.  I have one question w.r.t. feature maps dimensionality changes inside a CNN: how does pooling (or strided convolution) fit into dynamical systems view? \n\nTable 3 and 4. I assume that the training time unit is a minute, I couldn\u2019t find this information in the paper.  Is the batch size the same for all models (100 for CIFAR and 32 for STL-10)?  I understand that the models with different #Blocks have different capacity, for clarity, would it be possible to add # of parameters to each model?  For multilevel method, would it be possible to show intermediate results in Table 3 and 4, e. g. at the end of cycle 1 and 2?   I see these results in Figure 6, however, the plots are condensed and it is difficult to see the exact number at the end of each cycle.  \n\nThe citation (E, 2017) seems to be wrong, could the authors check it?\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-POS],[ETH-POS]]