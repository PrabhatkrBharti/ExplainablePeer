This paper describes an approach to decode non-autoregressively for neural machine translation (and other tasks that can be solved via seq2seq models).  The advantage is the possibility of more parallel decoding which can result in a significant speed-up (up to a factor of 16 in the experiments described).  The disadvantage is that it is more complicated than a standard beam search as auto-regressive teacher models are needed for training and the results do not reach (yet) the same BLEU scores as standard beam search.  \n\nOverall, this is an interesting paper.  It would have been good to see a speed-accuracy curve which plots decoding speed for different sized models versus the achieved BLUE score on one of the standard benchmarks (like WMT14 en-fr or en-de) to understand better the pros and cons of the proposed approach and to be able to compare models at the same speed or the same BLEU scores.   While the Ro->En results are goodG this particular language pair has not been used much by others; it would have been more interesting to stay with a single well-used language pair and benchmark and analyze why WMT14 en->de and de->en are not improving more.  Finally it would have been good to address total computation in the comparison as well -- it seems while total decoding time is smaller total computation for NAT + NPD is actually higher depending on the choice of s.\n [[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]