In this work, the objective is to analyze the robustness of a neural network to any sort of attack. \n\nThis is measured by naturally linking the robustness of the network to the local Lipschitz properties of the network function.  This approach is quite standard in learning theory, I am not aware of how original this point of view is within the deep learning community. \n\nThis is estimated by obtaining values of the norm of the gradient (also naturally linked to the Lipschitz properties of the function) by backpropagation. This is again a natural idea[[CLA-POS],[JUS-POS],[DEP-NEG],[FAI-POS],[CON-NEG],[ENG-NEG],[ACC-POS],[CST-NEG],[NOV-POS],[ETH-NEG]]