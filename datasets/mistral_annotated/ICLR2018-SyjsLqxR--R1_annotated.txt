Summary:\n\nThis paper empirically studies adversarial perturbations dx and what the effects are of adversarial training (AT) with respect to shared (dx fools for many x) and singular (only for a single x) perturbations.  Experiments use a (previously published) iterative fast-gradient-sign-method and use a Resnet on CIFAR. \n\nThe authors conclude that in this experimental setting:\n- AT seems to defend models against shared dx's. \n- This is visible on universal perturbations, which become less effective as more AT is applied. \n- AT decreases the effectiveness of adversarial perturbations, e.g. AT decreases the number of adversarial perturbations that fool both an input x and x with e.g. a contrast change. \n- Singular perturbations are easily detected by a detector model, as such perturbations don't change much when applying AT. \n\nPro:\n- Paper addresses an important problem: qualitative / quantitative understanding of the behavior of adversarial perturbations is still lacking. \n- The visualizations of universal perturbations as they change during AT are nice. \n- The basic observation wrt the behavior of AT is clearly communicated. \n\nCon:\n- The experiments performed are interesting directions, although unfocused and rather limited in scope.  For instance, does the same phenomenon happen for different datasets?  Different models? \n- What happens when we use adversarial attacks different from FGSM?  Do we get similar results? \n- The papers lacks a more in-depth theoretical analysis.  Is there a principled reason AT+FGSM defends against universal perturbations? \n\nOverall:\n- As is, it seems to me the paper lacks a significant central message (due to limited and unfocused experiments) or significant new theoretical insight into the effect of AT.  A number of questions addressed are interesting starting points towards a deeper understanding of *how* the observations can be explained and more rigorous empirical investigations.\n\nDetailed:\n-\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]