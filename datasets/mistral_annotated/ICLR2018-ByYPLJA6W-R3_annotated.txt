This is an intriguing paper on running regressions on probability distributions: i.e. a target distribution is expressed as a function of input distributions.  A well-written manuscript,;  though the introduction could have motivated the problem a little better (i.e. why would we want to do this).  The novelty in the paper is implementing such a regression in a layered network.  The paper shows how the densities at each nodes are computed (and normalised).  Optimisation by back propagation and discretization of the densities to carry out numerical integration are well explained and easy to follow.  The paper uses three problems to illustrate the idea -- a synthetic dataset, a mean reverting stochastic process and a prediction problem on stock indices.   \nMy only two reservations of this paper is the illustration on the stock index data -- it seems to me, returns on individual constituent stocks of an index are used as samples of the return on the index itself.   But this cannot be true when the index is a weighted sum of the constituent assets.   Secondly, it is not clear to me why one would force a kernel density estimate on the asset returns and then bin the density into 100 bins for numerical reasons;  -- does the smoothing that results from this give any advantage over a histogram of the returns in 100 bins[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]