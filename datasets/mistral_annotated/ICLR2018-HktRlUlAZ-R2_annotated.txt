This paper proposes a method to learn networks invariant to translation and equivariant to rotation and scale of arbitrary precision.  The idea is to jointly train \n- a network predicting a polar origin, \n- a module transforming the image into a log-polar representation according to the predicted origin, \n- a final classifier performing the desired classification task. \nRotation and scale from the polar origin result in translation of the log-polar representation.  Rotation and scale can have arbitrary precision, which is novel to the best of my knowledge. \n\n(+) In my opinion, this is a simple, attractive approach to rotation and scale equivariant CNNs. \n\n(-) The evaluation, however, is quite limited.  The approach is evaluated on:\n 1) several variants of MNIST.  The authors introduce a new variant (SIM2MNIST), which is created by applying random similitudes to the images from MNIST.  This variant is of course very well suited to the proposed method, and a bit artificial.  \n 2) 3d voxel occupancy grids with a small resolution.   The objects can be rotated around the z-axis, and the method is used to be equivariant to this rotation.   \n\n(-) Since the method starts by predicting the polar origin, wouldn't it be possible to also predict rotation and scale?    Then the input image could be rectified to a canonical orientation and scale, without needing equivariance.    My intuition is that this simpler approach would work better[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]