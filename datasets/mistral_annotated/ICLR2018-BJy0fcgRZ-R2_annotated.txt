This paper presents a method based on GANs for visualizing how humans represent visual categories.  Authors perform experiments on two datasets: Asian Faces Dataset and ImageNet Large Scale Recognition Challenge dataset. \n\nPositive aspects:\n+ The idea of using GANs for this goal is smart and interesting \n+ The results seem interesting too \n\nWeaknesses:\n- Some aspects of the paper are not clear and presentation needs improvement. \n- I miss a clearer results comparison with previous methods, like Vondrick et al. 2015. \n\nSpecific comments and questions:\n\n-  Figure 1 is not clear.  Authors should clarify how they use the inference network and what the two arrows from this inference network represent. \n- Figure 2 is also not clear.  Just the FLD projections of the MCMCP chains are difficult to interpret.  The legend of the figure is too tiny.  The right part of the figure should be better described in the text or in the caption, I don't understand well what this illustrates. \n- Regarding to the human experiments with AMT: how do the authors deal with noise on the workers performance?  Is any qualification task used?  What are the instructions given to the workers? \n- In section 4.2. the authors state \"We also simultaneously learn a corresponding inference network, .... granular human biases captured\".  This seems interesting  but I didn't find any result on that in the paper.  Can you give more details or refer to where in the paper it is discussed/tested? \n- Figure 4 shows \"most interpretable mixture components\".   How this \"most interpretable\" were selected? \n- In second paragraph Section 4.3, it should be Table 1 instead of Figure 1.  \n- It would be interesting to see a discussion on why MCMCP Density is better for group 1 and MCMCP Mean is better for group 2.  To see the confusion matrixes could be useful. \n\nI like this paper.  The addressed problem is challenging and the proposed idea seems interesting.   However, the aspects mentioned make me think the paper needs some improvements to be published.\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]