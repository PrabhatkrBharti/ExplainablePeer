In this very good paper, the objective is to perform robust learning: to minimize not only the risk under some distribution P_0, but also against the worst case distribution in a ball around P_0.\ n\nSince the min-max problem is intractable in general,  what is actually studied here is a relaxation of the problem: it is possible to give a non-convex dual formulation of the problem.  If the duality parameter is large enough, the functions become convex given that the initial losses are smooth.  \n\nWhat follows are certifiable bounds for the risk for robust  learning and stochastic optimization over a ball of distributions.  Experiments show that this performs as expected, and gives a good intuition for the reasons why this occurs: separation lines are 'pushed away' from samples, and a margin seems to be increased with this procedure.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-NEG],[ENG-NEG],[ACC-POS],[CST-NEG],[NOV-POS],[ETH-NEG]]