The authors address two important issues: semi-supervised learning from relatively few labelled training examples in the presence of many unlabelled examples, and visual rationale generation: explaining the outputs of the classifiier by overlaing a visual rationale on the original image.  This focus is mainly on medical image classification but the approach could potentially be useful in many more areas.  The main idea is to train a GAN on the unlabeled examples to create a mapping from a lower-dimensional space in which the input features are approximately Gaussian, to the space of images, and then to train an encoder to map the original images into this space minimizing reconstruction error with the GAN weights fixed.  The encoder is then used as a feature extractor for classification and regression of targets (e.g. heard disease).  The visual rationales are generated by optimizing the encoded representation to simultaneously reconstruct an image close to the original and to minimize the probability of the target class.  This gives an image that is similar to the original but with features that caused the classification of the disease removed.  The resulting image can be subtracted from the original encoding to highlight problematic areas.  The approach is evaluated on an in-house dataset and a public NIH dataset, demonstrating good performance, and illustrative visual rationales are also given for MNIST. \n\nThe idea in the paper is, to my knowledge, novel, and represents a good step toward the important task of generating interpretable visual rationales.  There are a few limitations, e.g. the difficulty of evaluating the rationales, and the fact that the resolution is fixed to 128x128 (which means discarding many pixels collected via ionizing radiation), but these are readily acknowledged by the authors in the conclusion. \n\nComments:\n1) There are a few details missing, like the batch sizes used for training (it is difficult to relate epochs to iterations without this).  Also, the number of hidden units in the 2 layer MLP from para 5 in Sec 2. \n2) It would be good to include PSNR/MSE figures for the reconstruction task (fig 2) to have an objective measure of error. \n3) Sec 2 para 4: \"the reconstruction loss on the validation set was similar to the reconstruction loss on the validation set\" -- perhaps you could be a little more precise here.  E.g. learning curves would be useful.\n4) Sec 2 para 5: \"paired with a BNP blood test that is correlated with heart failure\" I suspect many readers of ICLR, like myself, will not be well versed in this test, correlation with HF, diagnostic capacity, etc., so a little further explanation would be helpful here.  The term \"correlated\" is a bit too broad, and it is difficult for a non-expert to know exactly how correlated this is.  It is also a little confusing that you begin this paragraph saying that you are doing a classification task, but then it seems like a regression task which may be postprocessed to give a classification.  Anyway, a clearer explanation would be helpful.  Also, if this test is diagnostic, why use X-rays for diagnosis in the first place? \n5) I would have liked to have seen some indicative times on how long the optimization takes to generate a visual rationale, as this would have practical implications.. \n6) Sec 2 para 7: \"L_target is a target objective which can be a negative class probability or in the case of heart failure, predicted BNP level\" -- for predicted BNP level, are you treating this as a probability and using cross entropy here, or \nmean squared error?. \n7) As always, it would be illustrative if you could include some examples of failure cases, which would be helpful both in suggesting ways of improving the proposed technique, and in providing insight into where it may fail in practical situations.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-POS],[CON-POS],[ENG-NEG],[ACC-POS],[CST-POS],[NOV-POS],[ETH-NEG]]