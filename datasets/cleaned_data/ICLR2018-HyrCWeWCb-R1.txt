 "Clarity \nThe paper is well-written and clear.  \n\nOriginality\nThe paper proposes a path consistency learning method with a new combination of entropy regularization and relative entropy.  The paper leverages a novel method in determining the coefficient of relative entropy.   \n\nSignificance\n- Trust-PCL achieves overall competitive with state-of-the-art external implementations. \n- Trust-PCL (off-policy) significantly outperform TRPO in terms of data efficiency and final performance.   \n- Even though the paper claims Trust-PCL (on-policy) is close to TRPO, the initial performance of TRPO looks better in HalfCheetah, Hopper, Walker2d and Ant.   \n- Some ablation studies (e.g., on entropy regularization and relative entropy) and sensitivity analysis on parameters (e.g. \\alpha and update frequency on \\phi) would be helpful.  \n\nPros:\n- The paper is well-written and clear.   \n- Competitive with state-of-the-art external implementations  \n- Significant empirical advantage over TRPO.  \n-  Open source codes.  \n\nCons:\n- No ablation studies. \n"