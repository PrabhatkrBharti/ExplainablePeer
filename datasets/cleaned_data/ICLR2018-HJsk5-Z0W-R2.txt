 "The authors introduce a novel novel for collaborative filtering.  The proposed model combines some of the strengths of factorization machines and of polynomial regression.  Another way to understand this model is that it's a feed forward neural network with a specific connection structure (i.e., not fully connected). \n\nThe paper is well written overall and relatively easy to understand.  The study seems fairly thorough (both vanilla and cold-start experiments are reported). \n\nOverall the paper feels a little bit incomplete .  This is particularly apparent in the empirical study.  Given the somewhat limited novelty of the model the potential impact of this work relies on more convincing experimental results.  Here are some suggestions about how to achieve that: \n\n1) Methodically report results for MF, FM, CTR (when meaningful), other strong baselines (maybe SLIM?) and all your methods for all datasets. \n\n2) Report results on well-known CF datasets.  Movielens comes to mind. \n\n3) Shed some light on some of the poor CTR results (last paragraph of Section 4.2.2)\n\n4) Explore the models and shed some lights on where the gains are coming from. \n\n\nMinor: \n\n- How do you deal with unobserved preferences in the implicit case?\ n\n- I found the idea of Figure 1 very good but in its current form I didn't find it particularly insightful (these \"clouds\" are hard to interpret). \n\n- It may also be worth adding this reference when discussing neural factorization:\nhttp://www.cs.toronto.edu/~mvolkovs/nips2017_deepcf.pdf\n"