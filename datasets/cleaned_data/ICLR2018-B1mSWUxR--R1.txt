 "This paper dives deeper into understand reward augmented maximum likelihood training.  Overall, I feel that the paper is hard to understand and that it would benefit from more clarity, e.g., section 3.3 states that decoding from the softmax q-distribution is similar to the Bayes decision rule.  Please elaborate on this. \n\nDid you compare to minimum bayes risk decoding which chooses the output with the lowest expected risk amongst a set of candidates? \n\nSection 4.2.2 says that Ranzato et al. and Bahdanau et al. require sampling from the model distribution.  However, the methods analyzed in this paper also require sampling (cf. Appendix D.2.4 where you mention a sample size of 10),  Please explain the difference."