 "The idea of using GANs for outlier detection is interesting and the problem is relevant.  However, I have the following concerns about the quality and the significance:\n- The proposed formulation in Equation (2) is questionable.  The authors say that this is used to generate outliers, and since it will generate inliers when convergence, the authors propose the technique of early stopping in Section 4.1 to avoid convergence.  However, then what is learned though the proposed formulation?  Since this approach is not straightforward, more theoretical analysis of the proposed method is desirable. \n- In addition to the above point, I guess the expectation is needed as the original formulation of GAN.  Otherwise the proposed formulation does not make sense as it receives only specific data points and how to accumulate objective values across data points is not defined. \n- In experiments, although the authors say \"lots of datasets are used\", only two datasets are used, which is not enough to examine the performance of outlier detection methods.  Moreover, outliers are artificially generated in these datasets, hence there is no evaluation on pure real-world datasets.  To achieve the better quality of the paper, I recommend to add more real-world datasets in experiments. \n- As discussed in Section 2, there are already many outlier detection methods, such as distance-based outlier detection methods, but they are not compared in experiments. \n  Although the authors argue that distance-based outlier detection methods do not work well for high-dimensional data, this is not always correct .\n  Please see the paper:\n  -- Zimek, A., Schubert, E., Kriegel, H.-P., A survey on unsupervised outlier detection in high-dimensional numerical data, Statistical Analysis and Data Mining (2012)\n  This paper shows that the performance gets even better for higher dimensional data if each feature is relevant. \n  I recommend to add some distance-based outlier detection methods as baselines in experiments.   \n- Since parameter tuning by cross validation cannot be used due to missing information of outliers, it is important to examine the sensitivity of the proposed method with respect to changes in its parameters (a_new, lambda, and others).  Otherwise in practice how to set these parameters to get better results is not obvious. \n\n* The clarity of this paper is not high as the proposed method is not well explained.  In particular, please mathematically formulate each proposed technique in Section 4. \n\n* Since the proposed formulation is not convincing due to the above reasons and experimental evaluation is not thorough, the originality is not high. \n\nMinor comments:\n- P.1, L.5 in the third paragraph: architexture -> architecture \n- What does \"Cor\" of CorGAN mean? \n\nAFTER REVISION\nThank you to the authors for their response and revision.  Although the paper has been improved, I keep my rating due to the insufficient experimental evaluation.