 "This paper proposes a device placement algorithm to place operations of tensorflow on devices.  \n\nPros:\n\n1. It is a novel approach which trains the placement end to end .\n2. The experiments are solid to demonstrate this method works very well .\n3. The writing is easy to follow. \n4. This would be a very useful tool for the community if open sourced. \n\nCons:\n\n1. It is not very clear in the paper whether the training happens for each model yielding separate agents, or a shared agent is trained and used for all kinds of models . The latter would be more exciting.  The adjacency matrix varies size for different graphs, so I guess a separate agent is trained for each graph?  However, if the agent is not shared, why not just use integer to represent each operation in the graph, since overfitting would be more desirable in this case. \n2. Averaging the embedding is hard to understand especially for the output sizes and number of outputs.\ n3. It is not clear how the adjacency information is used.\n"