 "The paper extends softmax consistency by adding in a relative entropy term to the entropy regularization and applying trust region policy optimization instead of gradient descent.   I am not an expert in this area.  It is hard to judge the significance of this extension. \n\nThe paper largely follows the work of Nachum et al 2017.  The differences (i.e., the claimed novelty) from that work are the relative entropy and trust region method for training.  However, the relative entropy term added seems like a marginal modification.