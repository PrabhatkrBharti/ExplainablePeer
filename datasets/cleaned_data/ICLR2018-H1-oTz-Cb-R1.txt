 "The paper proposes an approach to learning a distribution over filters of a CNN.  The method is based on a adversarial training: the generator produces filters, and the discriminator aims to distinguish the activation maps produced by real filters from those produced by the generated ones.  \n\nPros:\n1) The general task of learning distributions over network weights is interesting \n2) To my knowledge, the proposed approach is new \n\nCons:\n1) Experimental evaluation is very substandard. The experiments on invariances seem to be the highlight of the paper, but they basically do not tell me anything.  \n - Figures 3 and 4 take 2 pages, but what should one see there? \n - There are no quantitative results.  Could there be a way to measure the invariances? \n - Can the results be applied to some practical task? Why are the results interesting and/or useful? \n2) The experiments are restricted to a single dataset - MNIST.  The authors mention that \u201cthe test accuracy obtained by following the above procedure is of 0.982, against a test accuracy of 0.971 for the real CNN\u201d - these are very poor accuracies for MNIST. So even the MNIST results do not seem convincing. \n3) Presentation is suboptimal, and many details are missing. For instance, architectures of networks are not provided. \n \nTo conclude, while the general direction is interesting and the proposed method might work, the experimental evaluation is very poor, and the paper absolutely cannot be accepted for publication."