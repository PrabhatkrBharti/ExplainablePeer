 "This paper applies recently developed ideas in the literature of robust optimization, in particular distributionally robust optimization with Wasserstein metric,  and showed that under this framework for smooth loss functions when not too much robustness is requested,  then the resulting optimization problem is of the same difficulty level as the original one (where the adversarial attack is not concerned).  I think the idea is intuitive and reasonable, the result is nice.  Although it only holds when light robustness are imposed,  but in practice, this seems to be more of the case than say large deviation/adversary exists.  As adversarial training is an important topic for deep learning, I feel this work may lead to promising principled ways for adversarial training. "