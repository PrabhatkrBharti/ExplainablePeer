 "Summary:\n\nThis paper proposes an adversarial learning framework for machine comprehension task.  Specifically, authors consider a reader network which learns to answer the question by reading the passage and a narrator network which learns to obfuscate the passage so that the reader can fail in its task.  Authors report results in 3 different reading comprehension datasets and the proposed learning framework results in improving the performance of GMemN2N. \n\n\nMy Comments:\n\nThis paper is a direct application of adversarial learning to the task of reading comprehension.  It is a reasonable idea and authors indeed show that it works. \n\n1. The paper needs a lot of editing.  Please check the minor comments. \n\n2. Why is the adversary called narrator network?  It is bit confusing because the job of that network is to obfuscate the passage. \n\n3. Why do you motivate the learning method using self-play?  This is just using the idea of adversarial learning (like GAN) and it is not related to self-play. \n\n4 In section 2, first paragraph, authors mention that the narrator prevents catastrophic forgetting.  How is this happening?  Can you elaborate more? \n\n5. The learning framework is not explained in a precise way.  What do you mean by re-initializing and retraining the narrator? Isn\u2019t it costly to reinitialize the network and retrain it for every turn?  How many such epochs are done?  You say that test set also contains obfuscated documents.  Is it only for the validation set?  Can you please explain if you use obfuscation when you report the final test performance too?  It would be more clear if you can provide a complete pseudo-code of the learning procedure. \n\n6. How does the narrator choose which word to obfuscate?  Do you run the narrator model with all possible obfuscations and pick the best choice? \n\n7. Why don\u2019t you treat number of hops as a hyper-parameter and choose it based on validation set?  I would like to see the results in Table 1 where you choose number of hops for each of the three models based on validation set. \n\n8. In figure 2, how are rounds constructed?  Does the model sees the same document again and again for 100 times or each time it sees a random document and you sample documents with replacement?  This will be clear if you provide the pseudo-code for learning. \n\n9. I do not understand author's\u2019 justification for figure-3.  Is it the case that the model learns to attend to last sentences for all the questions?  Or where it attends varies across examples?\n\n10. Are you willing to release the code for reproducing the results?\n\nMinor comments:\n\nPage 1, \u201cexploit his own decision\u201d should be \u201cexploit its own decision \u201d\nIn page 2, section 2.1, sentence starting with \u201cIndeed, a too low percentage \u2026\u201d needs to be fixed. \nPage 3, \u201cforgetting is compensate\u201d should be \u201cforgetting is compensated\u201d. \nPage 4, \u201cfor one sentences\u201d needs to be fixed. \nPage 4, \u201cunknow\u201d should be \u201cunknown\u201d.\nPage 4, \u201c?? \u201d needs to be fixed. \nPage 5, \u201cfor the two first datasets\u201d needs to be fixed. \nTable 1, \u201cGMenN2N\u201d should be \u201cGMemN2N\u201d.  In caption, is it mean accuracy or maximum accuracy? \nPage 6, \u201cdataset was achieves\u201d needs to be fixed. \nPage 7, \u201cdocument by obfuscated this word\u201d needs to be fixed.\ nPage 7, \u201coverall aspect of the two first readers\u201d needs to be fixed. \nPage 8, last para, references needs to be fixed. \nPage 9, first sentence, please check grammar. \nSection 6.2, last sentence is irrelevant.\n"