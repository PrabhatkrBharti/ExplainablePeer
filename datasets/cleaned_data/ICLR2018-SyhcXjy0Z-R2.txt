 "\nAs one can see by the title, the originality (application of DCNN) and significance (limited to ATM domain) is very limited.  If this is still enough for ICLR, the paper could be okay.  However, even so one can clearly see that the architecture, the depth, the regularization techniques, and the evaluation are clearly behind the state of the art.  Especially for this problem domain, drop-out and data augmentation should be investigated. \n\nOnly one dataset is used for the evaluation and it seems to be very limited and small.  Moreover, it seems that the same subjects (even if it is other pictures) may appear in the training set and test set as they were randomly selected.  Looking into the referece (to get the details of the dataset -  from a workshop of the IEEE International Conference on Computer Vision Workshops (ICCVW) 2017) reveals, that it has only 25 subjects and 10 disguises . This makes it even likely that the same subject with the same disguise appears in the training and test set. \n\nA very bad manner, which unfortunately is often performed by deep learning researchers with limited pattern recognition background, is that the accuracy on the test set is measured for every timestamp and finally the highest accuracy is reported.  As such you perform an optimization of the paramerter #iterations on the test set, making it a validation set and not an independent test set.  \n\nMinor issues:\nmake sure that the capitalization in the references is correct (ATM should be capital, e.g., by putting {ATM} - and many more things)."