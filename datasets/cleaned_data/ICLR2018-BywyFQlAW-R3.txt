 "The main strength of this paper, I think, is the theoretical result in Theorem 1 . This result is quite nice.  I wish the authors actually concluded with the following minor improvement to the proof that actually strengthens the result further. \n\nThe authors ended the discussion on thm 1 on page 7 (just above Sec 2.3) by saying what is sufficiently close to w*.  If one goes back to (10), it is easy to see that what converges to w* when one of three things happen (assuming beta is fixed once loss L is selected). \n\n1) k goes to infinity\n2) alpha goes to 1\n3) g(w*) goes to 0 \n\nThe authors discussed how alpha is close to 1 by virtue of submodular optimization lower bounds there for what is close to w*.  In fact this proof shows the situation is much better than that.  \n\nIf we are really concerned about making what converge to w*, and if we are willing to tolerate the increasing computational complexity associated solving submodular problems with larger k, we can schedule k to increase over time which guarantees that both alpha goes to 1 and g(w*) goes to zero.  \n\nThere is also a remark that G(A) tends to be modular when lambda is small which is useful. \nFrom the algorithm, it seems clear that the authors recognized these two useful aspects of the objective and scheduled lambda to decrease exponentially and k to increase linearly. \n\nIt would be really nice to complete the analysis of Thm1 with a formal analysis of convergence speed for ||what-w*|| as lambda and k are scheduled in this fashion.  Such an analysis would help practitioners make better choices for the hyper parameters gamma and Delta."