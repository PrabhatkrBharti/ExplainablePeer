 "The paper introduces a method for learning graph representations (i.e., vector representations for graphs).  An existing node embedding method is used to learn vector representations for the nodes . The node embeddings are then projected into a 2-dimensional space by PCA.  The 2-dimensional space is binned using an imposed grid structure.  The value for a bin is the (normalized) number of nodes falling into the corresponding region.  \n\nThe idea is simple and easily explained in a few minutes . That is an advantage.  Also, the experimental results look quite promising . It seems that the methods outperforms existing methods for learning graph representations . \n\nThe problem with the approach is that it is very ad-ho c. There are several (existing) ideas of how to combine node representations into a representation for the entire graph . For instance, averaging the node embeddings is something that has shown promising results in previous work . Since the methods is so ad-hoc (node2vec -> PCA -> discretized density map -> CNN architecure) and since a theoretical understanding of why the approach works is missing , it is especially important to compare your method more thoroughly to simpler methods.  Again, pooling operations (average, max, etc.) on the learned node2vec embeddings are examples of simpler alternatives.  \n\nThe experimental results are also not explained thoroughly enough.  For instance, since two runs of node2vec will give you highly varying embeddings (depending on the initialization) , you will have to run node2vec several times to reduce the variance of your resulting discretized density maps.  How many times did you run node2vec on each graph? \n