 "This work proposed a reconfiguration of the existing state-of-the-art CNN model architectures including ResNet and DensNet.  By introducing new branching architecture, coupled ensembles, they demonstrate that the model can achieve better performance in classification tasks compared with the single branch counterpart with same parameter budget.  Additionally, they also show that the proposed ensemble method results in better performance than other ensemble methods (For example, ensemble over independently trained models)  not only in combined mode but also in individual branches. \n\nPaper Strengths:\n* The proposed coupled ensembles method truly show impressive results in classification benchmark (DenseNet-BC L = 118 k = 35 e = 3). \n* Detailed analysis on different ensemble fusion methods on both training time and testing time. \n* Simple but effective design to achieve a better result in testing time with same total parameter budget. \n\t\nPaper Weakness:\n* Some detail about different fusing method should be mentioned in the main paper instead of in the supplementary material. \n* In practice, how much more GPU memory is required to train the model with parallel branches (with same parameter budgets) because memory consumption is one of the main problems of networks with multiple branches. \n* At least one experiment should be carried out on a larger dataset such as ImageNet to further demonstrate the validity of the proposed method. \n* More analysis can be conducted on the training process of the model.  Will it converge faster?  What will be the total required training time to reach the same performance compared with single branch model with the same parameter budget?