 "The authors propose the N-Gram machine to answer questions over long documents.  The model first encodes the document via tuple extraction.  An autoencoder objective is used to produce meaningful tuples.  Then, the model generates a program, based on the extracted tuple collection and the question, to find an answer. \n\nI am very disappointed in the authors' choice of evaluation, namely bAbI - a toy, synthetic task long abandoned by the NLP community because of its lack of practicality.  If the authors would like to demonstrate question answering on long documents, they have the luxury of choosing amongst several large scale, realistic question answering datasets such as the Stanford Question answering dataset or TriviaQA. \nBeyond the problem of evaluation, the model the authors propose does not provide new ideas, and rather merges existing ones. This, in itself, is not a problem . However, the authors decline to cite many, many important prior work. For example, the tuple extraction described by the authors has significant prior work in the information retrieval community (e.g. knowledge base population, relation extraction).  The idea of generating programs to query over populated knowledge bases, again, has significant related work in semantic parsing and program synthesis.  Question answering over (much more complex) probabilistic knowledge graphs have been proposed before as well (in fact I believe Matt Gardner wrote his entire thesis on this topic).  Finally, textual question answering (on realistic datasets) has seen significant breakthroughs in the last few years.  Non of these areas, with the exception of semantic parsing, are addressed by the author.  With sufficient knowledge of related works from these areas, I find that the authors' proposed method lacks proper evaluation and sufficient novelty."