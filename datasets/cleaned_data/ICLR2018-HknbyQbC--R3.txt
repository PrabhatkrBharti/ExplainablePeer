 "The paper proposes a way of generating adversarial examples that fool classification systems. \nThey formulate it for a blackbox and a semi-blackbox setting (semi being, needed for training their own network, but not to generate new samples).\ n\nThe model is a residual gan formulation, where the generator generates an image mask M, and (Input + M) is the adversarial example.\ nThe paper is generally easy to understand and clear in their results. \nI am not awfully familiar with the literature on adversarial examples to know if other GAN variants exist . From this paper's literature survey, they dont exist.  \nSo this paper is innovative in two parts:\n- it applies GANs to adversarial example generation\ n- the method is a simple feed-forward network, so it is very fast to compute\ n\nThe experiments are pretty robust, and they show that their method is better than the proposed baselines .\nI am not sure if these are complete baselines or if the baselines need to cover other methods (again, not fully familiar with all literature here).\n"