 "This paper adds source side dependency syntax trees to an NMT model without explicit supervision.  Exploring the use of syntax in neural translation is interesting but I am not convinced that this approach actually works based on the experimental results. \n\nThe paper distinguishes between syntactic and semantic objectives (4th paragraph in section 1), attention, and heads.  Please define what semantic attention is.  You just introduce this concept without any explanation.  I believe you mean standard attention, if so, please explain why standard attention is semantic. \n\nClarity. What is shared attention exactly?  Section 3.2 says that you share attention weights from the decoder with encoder. Please explain this a bit more.  Also the example in Figure 3 is not very clear and did not help me in understanding this concept. \n\nResults. A good baseline would be to have two identical attention mechanisms to figure out if improvements come from more capacity or better model structure.  Flat attention seems to add a self-attention model and is somewhat comparable to two mechanisms.  The results show hardly any improvement over the flat attention baseline (at most 0.2 BLEU which is well within the variation of different random initializations).  It looks as if the improvement comes from adding additional capacity to the model.  \n\nEquation 3: please define H.