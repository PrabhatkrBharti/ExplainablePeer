 "Summary:\nThis paper proposes a new approach to tackle the problem of prediction under\nthe shift in design, which consists of the shift in policy (conditional\ndistribution of treatment given features) and the shift in domain (marginal \ndistribution of features). \n\nGiven labeled samples from a source domain and unlabeled samples from a target\ndomain, this paper proposes to minimize the risk on the target domain by \njointly learning the shift-invariant representation and the re-weighting \nfunction for the induced representations.  According to Lemma 1 and its finite\nsample version in Theorem 1, the risk on the target domain can be upper bounded\nby the combination of 1) the re-weighted empirical risk on the source domain;  \nand 2) the distributional discrepancy between the re-weighted source domain and\nthe target domain.  These theoretical results justify the objective function\nshown in Equation 8.  \n\nExperiments on the IHDP dataset demonstrates the advantage of the proposed\napproach compared to its competing alternatives. \n\nComments:\n1) This paper is well motivated.  For the task of prediction under the shift in\ndesign, shift-invariant representation learning (Shalit 2017) is biased even in\nthe inifite data limit.  On the other hand, although re-weighting methods are\nunbiased, they suffer from the drawbacks of high variance and unknown optimal\nweights.  The proposed approach aims to overcome these drawbacks. \n\n2) The theoretical results justify the optimization procedures presented in\nsection 5.  Experimental results on the IHDP dataset confirm the advantage of\nthe proposed approach.  \n\n3) I have some questions on the details.  In order to make sure the second \nequality in Equation 2 holds, p_mu (y|x,t) = p_pi (y|x,t) should hold as well. \nIs this a standard assumption in the literature? \n\n4) Two drawbacks of previous methods motivate this work, including the bias of\nrepresentation learning and the high variance of re-weighting.  According to\nLemma 1, the proposed method is unbiased for the optimal weights in the large\ndata limit.  However, is there any theoretical guarantee or empirical evidence\nto show the proposed method does not suffer from the drawback of high variance? \n\n5) Experiments on synthetic datasets, where both the shift in policy and the\nshift in domain are simulated and therefore can be controlled, would better \ndemonstrate how the performance of the proposed approach (and thsoe baseline \nmethods) changes as the degree of design shift varies.  \n\n6) Besides IHDP, did the authors run experiments on other real-world datasets, \nsuch as Jobs, Twins, etc?"