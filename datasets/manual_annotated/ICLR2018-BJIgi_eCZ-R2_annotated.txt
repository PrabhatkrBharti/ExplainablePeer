The primary intellectual point the authors make is that previous networks for machine comprehension are not fully attentive.  That is, they do not provide attention on all possible layers on abstraction such as the word-level and the phrase-level . The network proposed here, FusionHet, fixes problem.  Importantly, the model achieves state-of-the-art performance of the SQuAD dataset. \n\nThe paper is very well-written and easy to follow.  I found the architecture very intuitively laid out, even though this is not my area of expertise.  Moreover, I found the figures very helpful -- the authors clearly took a lot of time into clearly depicting their work!  What most impressed me, however, was the literature review.  Perhaps this is facilitated by the SQuAD leaderboard, which makes it simple to list related work.  Nevertheless, I am not used to seeing comparison to as many recent systems as are presented in Table 2.  \n\nAll in all, it is difficult not to highly recommend an architecture that achieves state-of-the-art results on such a popular dataset.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]