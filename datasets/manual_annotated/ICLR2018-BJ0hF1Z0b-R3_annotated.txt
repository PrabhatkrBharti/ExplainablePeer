This paper extends the previous results on differentially private SGD to user-level differentially private recurrent language models.  It experimentally shows that the proposed differentially private LSTM achieves comparable utility compared to the non-private model. \n\nThe idea of training differentially private neural network is interesting and very important to the machine learning + differential privacy community.  This work makes a pretty significant contribution to such topic.  It adapts techniques from some previous work to address the difficulties in training language model and providing user-level privacy.  The experiment shows good privacy and utility. \n\nThe presentation of the paper can be improved a bit.  For example, it might be better to have a preliminary section before Section2 introducing the original differentially private SGD algorithm with clipping, the original FedAvg and FedSGD, and moments accountant as well as privacy amplification; otherwise, it can be pretty difficult for readers who are not familiar with those concepts to fully understand the paper.  Such introduction can also help readers understand the difficulty of adapting the original algorithms and appreciate the contributions of this work.\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]