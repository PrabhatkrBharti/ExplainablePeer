The paper proposes a method to synthesize adversarial examples that remain robust to different 2D and 3D perturbations.  The paper shows this is effective by transferring the examples to 3D objects that are color 3D-printed and show some nice results. \n\nThe experimental results and video showing that the perturbation is effective for different camera angles, lighting conditions and background is quite impressive.  This work convincingly shows that adversarial examples are a real-world problem for production deep-learning systems rather than something that is only academically interesting. \n\nHowever, the authors claim that standard techniques require complete control and careful setups (e.g. in the camera case) is quite misleading, especially with regards to the work by Kurakin et. al.  This paper also seems to have some problems of its own (for example the turtle is at relatively the same distance from the camera in all the examples, I expect the perturbation wouldn't work well if it was far enough away that the camera could not resolve the HD texture of the turtle). \n\nOne interesting point this work raises is whether the algorithm is essentially learning universal perturbations (Moosavi-Dezfooli et. al).  If that's the case then complicated transformation sampling and 3D mapping setup would be unnecessary.  This may already be the case since the training set already consists of multiple lighting, rotation and camera type transformations so I would expect universal perturbations to already produce similar results in the real-world. \n\nMinor comments:\nSection 1.1: \"a affine\" -> \"an affine\"\nTypo in section 3.4: \"of a of a \"\nIt's interesting in figure 9 that the crossword puzzle appears in the image of the lighthouse. \n\nMoosavi-Dezfooli, S. M., Fawzi, A., Fawzi, O., & Frossard, P. Universal adversarial perturbations. CVPR 2017.[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEG],[CON-POS],[ENG-POS],[ACC-POS],[CST-POS],[NOV-NEU],[ETH-NEU]]