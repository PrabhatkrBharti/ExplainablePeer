This paper studies empirical risk in deep neural networks.  Results are provided in Section 4 for linear networks and in Section 5 for nonlinear networks. \nResults for deep linear neural networks are puzzling.  Whatever the number of layers, a deep linear NN is simply a matrix multiplication and minimizing the MSE is simply a linear regression.  So results in Section 4 are just results for linear regression and I do not understand why the number of layers come into play?  \nAlso this is never explicitly mentioned in the paper, I guess the authors make an assumption that the samples (x_i,y_i) are drawn i.i.d. from a given distribution D.  In such a case, I am sure results on the population risk minimization can be found for linear regression and should be compare to results in Section 4.\n\n[[CLA-POS],[JUS-POS],[DEP-POS],[FAI-NEU],[CON-NEU],[ENG-NEU],[ACC-NEU],[CST-NEU],[NOV-NEU],[ETH-NEU]]