 "The paper presents a method for improving the diversity of Generative Adversarial Network (GAN) by promoting the Gnet's weights to be as informative as possible.[[INT-NEU], [null]]  This is achieved by penalizing the correlation between responses of hidden nodes and promoting low entropy intra node.[[MET-NEU], [null]]  Numerical experiments that demonstrate the diversity increment on the generated samples are shown.[[EXP-NEU], [null]] \n\nConcerns.\n\nThe paper is hard do tear and it is deficit to identify the precise contribution of the authors.[[OAL-NEG], [CLA-NEG]]  Such contribution can, in my opinion, be summarized  in a potential of the form\n\nwith\n\n$$\nR_BRE = a R_ME+ b R_AC = a \\sum_k  \\sum_i s_{ki}^2   +  b \\sum_{<k,l>} \\sum_i \\{ s_{ki} s_{li} \\}   \n$$\n(Note that my version of R_ME is different to the one proposed by the authors, but it could have the same effect)\n\nWhere a and b are parameters that weight the relative contribution of each term  (maybe computed as suggested in the paper).[[MET-NEU], [EMP-NEU]] \n\nIn this formulation:\n\nThen R_ME has a high response if the node has saturated responses -1\u2019s or 1``s, as one desire such saturated responses, a should be negative.[[MET-NEU], [EMP-NEU]] \n\nThe R_AC, penalizes correlation between responses of different nodes.[[MET-NEU], [EMP-NEU]] \n\nThe point is, \n\na) The second term will introduce  low correlation in saturated vectors, then the will be informative.[[MET-NEU], [EMP-NEU]]  \n \nb) why the authors use the softsign instead the tanh:  $tahnh \\in C^2 $! Meanwhile the derivative id softsign is discontinuous.[[MET-NEU], [EMP-NEU]] \n\nc)  It is not clear is the softsign is used besides the activation function: In page 5 is said \u201cR_BRE can be applied on ant rectified layer before the nolinearity\u201d [[MET-NEU], [EMP-NEU]] . This seems tt the authors propose to add a second activation function (the softsign), why not use the one is in teh layer?[[MET-NEU], [EMP-NEU]] \n\nd) The authors found hard to regularize the gradient $\\nabla_x D(x)$, even they tray tanh and cosine based activations.[[MET-NEU], [EMP-NEU]]  It seems that effectively, the  introduce their additional softsign in the process.[[MET-NEU], [EMP-NEU]] \n\ne) En the definition of R_AC, I denoted by <k,l> the pair of nodes (k \\ne l).[[MET-NEU], [null]]  However, I think that it should be for pair in the same layer. It is not clear in the paper.[[MET-NEU], [EMP-NEU]] \n\nf) It is supposed that the L_1 regularization motes the weights to be informative, this work is doing something similar.[[MET-NEU], [EMP-NEU]]  How is it compared  the L_1 regularization vs. the proposal?[[MET-NEU], [CMP-NEU]] \n\nRecommendation\nI tried to read the paper several times and I accept that it was very hard to me.[[OAL-NEG], [CLA-NEG]]  The most difficult part is the lack of precision on the maths, it is hard to figure out what the authors contribution indeed are.[[MET-NEU], [EMP-NEG]]  I think there is some merit in the work.[[OAL-POS], [null]]  However, it is not very well organized and many points are not defined.[[OAL-NEG], [CLA-NEG,PNF-NEG]]  In my opinion, the paper is in a preliminary stage and should be refined.[[OAL-NEU], [null]]  I recommend a \u201cSOFT\u201d REJECT.[[OAL-NEG], [REC-NEG]]