 "The authors present a scalable model for questioning answering that is able to train on long documents.[[INT-NEU,PDI-NEU], [null]]  On the TriviaQA dataset, the proposed model achieves state of the art results on both domains (wikipedia and web).[[DAT-POS,RES-POS], [EMP-POS]]  The formulation of the model is straight-forward,[[OAL-POS], [EMP-POS]]  however I am skeptical about whether the results prove the premise of the paper (e.g. multi-mention reasoning is necessary).[[RES-NEG], [EMP-NEG]]  Furthermore, I am slightly unconvinced about the authors' claim of efficiency.[[RES-NEG], [EMP-NEG]]  Nevertheless, I think this work is important given its performance on the task.[[RES-POS,OAL-POS], [EMP-POS]] \n\n1. Why is this model successful?[[MET-NEU], [EMP-NEU]]  Multi-mention reasoning or more document context?[[MET-NEU], [EMP-NEU]] \nI am not convinced of the necessity of multi-mention reasoning, which the authors use as motivation, as shown in the examples in the paper.[[MET-NEG], [EMP-NEG]]  For example, in Figure 1, the answer is solely obtained using the second last passage.[[MET-NEG,TNF-NEG], [EMP-NEG]]  The other mentions provide signal, but does not provide conclusive evidence.[[ANA-NEG], [SUB-NEG]]  Perhaps I am mistaken, but it seems to me that the proposed model cannot seem to handle negation, can the authors confirm/deny this?[[MET-NEG], [EMP-NEG]]  I am also skeptical about the computation efficiency of a model that scores all spans in a document (which is O(N^2), where N is the document length).[[MET-NEG], [EMP-NEG]]  Can you show some analysis of your model results that confirm/deny this hypothesis?[[RES-NEU,ANA-NEU], [EMP-NEU]] \n\n2. Why is the computational complexity not a function of the number of spans?[[MET-NEG], [EMP-NEG]] \nIt seems like the derivations presents several equations that score a given span.[[MET-NEU], [EMP-NEU]]  Perhaps I am mistaken, but there seems to be n^2 spans in the document that one has to score.[[MET-NEU], [EMP-NEG]]  Shouldn't the computational complexity then be at least O(n^2), which makes it actually much slower than, say, SQuAD models that do greedy decoding O(2n + nm)?[[MET-NEU], [EMP-NEU]] \n\nSome minor notes\n- 3.3.1 seems like an attention computation in which the attention context over the question and span is computed using the question.[[MET-NEU], [EMP-NEU]]  Explicitly mentioning this may help the reading grasp the formulation.[[MET-NEU], [CNT]] \n- Same for 3.4, which seems like the biattention (Seo 2017) or coattention (Xiong 2017) from previous squad work.[[RWK-NEU], [CMP-NEU]] \n- The sentence \"We define ... to be the embeddings of the l words of the sentence that contains s.\" is not very clear.[[TNF-NEG], [CLA-NEG]]  Do you mean that the sentence contains l words?[[CNT], [CLA-NEG]]  It could be interpreted that the span has l words.[[TNF-NEG], [CLA-NEG]] \n- There is a typo in your 3.7 \"level 1 complexity\": there is an extra O inside the big O notation."[[MET-NEG], [CLA-NEG]]