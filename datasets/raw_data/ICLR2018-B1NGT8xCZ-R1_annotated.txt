 "This is a very well-written paper that shows how to successfully use (generative) autoencoders together with the (discriminative) domain adversarial neural network (DANN) of Ganin et al.[[RWK-POS], [CLA-POS,CMP-POS]] \nThe construction is simple but nicely backed by a probabilistic analysis of the domain adaptation problem.[[PDI-POS,ANA-POS], [EMP-POS]] \n\nThe only criticism that I have towards this analysis is that the concept of shared parameter between the discriminative and predictive model (denoted by zeta in the paper) disappear when it comes to designing the learning model.[[ANA-NEG], [EMP-NEG]]   \n\nThe authors perform numerous empirical experiments on several types of problems.[[EXP-NEU], [null]]  They successfully show that using autoencoder can help to learn a good representation for discriminative domain adaptation tasks.[[MET-POS], [EMP-POS]] [[MET-POS], [EMP-POS]]  On the downside, all these experiments concern predictive (discriminative) problems.[[EXP-NEG], [EMP-NEG]]  Given the paper title, I would have expected some experiments in a generative context.[[EXP-NEU], [SUB-NEG]]  Also, a comparison with the Generative Adversarial Networks of Goodfellow et al. (2014) would be a plus.[[RWK-NEU], [SUB-NEU,CMP-NEU]] \nI would also like to see the results obtained using DANN stacked on mSDA representations, as it is done in Ganin et al. (2016).[[RWK-NEU,RES-NEU], [SUB-NEU]] \n\nMinor comments:\n- Paragraph below Equation 6:  The meaning of $\\phi(\\psi)$ is unclear[[MET-NEG], [PNF-NEG]]  \n- Equation (7): phi and psi seems inverted[[MET-NEG], [PNF-NEG]]  \n- Section 4: The acronym MLP is used but never defined.[[MET-NEG], [PNF-NEG]] \n\n=== update ===\nI lowered my score and confidence, see my new post below."[[OAL-NEG], [REC-NEG]]