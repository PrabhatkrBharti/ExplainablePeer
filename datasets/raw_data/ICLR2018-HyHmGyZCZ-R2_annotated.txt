 "This paper proposes a ranking-based similarity metric for distributional semantic models.[[INT-NEU], [null]]  The main idea is to learn \"baseline\" word embeddings, retrofitting those and applying localized centering, to then calculate similarity using a measure called \"Ranking-based Exponential Similarity Measure\" (RESM), which is based on the recently proposed APSyn measure.[[RWK-NEU,PDI-NEU], [CMP-NEU]] \n\nI think the work has several important issues:[[OAL-NEU], [null]] \n\n1. The work is very light on references.[[RWK-NEG], [SUB-NEG]]  There is a lot of previous work on evaluating similarity in word embeddings (e.g. Hill et al, a lot of the papers in RepEval workshops, etc.); specialization for similarity of word embeddings (e.g. Kiela et al., Mrksic et al., and many others); multi-sense embeddings (e.g. from Navigli's group); and the hubness problem (e.g. Dinu et al.).[[RWK-NEU], [CMP-NEU]]  For the localized centering approach, Hara et al.'s introduced that method.[[RWK-NEU,MET-NEG], [null]]  None of this work is cited, which I find inexcusable.[[BIB-NEG], [SUB-NEG]] \u2028\n\n2. The evaluation is limited, in that the standard evaluations (e.g. SimLex would be a good one to add, as well as many others, please refer to the literature) are not used and there is no comparison to previous work.[[RWK-NEG,BIB-NEG], [SUB-NEG,PNF-NEG]]  The results are also presented in a confusing way, with the current state of the art results separate from the main results of the paper.[[RES-NEG], [PNF-NEG]]  It is unclear what exactly helps, in which case, and why.[[RES-NEG], [PNF-NEG]] \u2028\n\n3. There are technical issues with what is presented, with some seemingly factual errors.[[MET-NEG], [EMP-NEG]]  For example, \"In this case we could apply the inversion, however it is much more convinient [sic] to take the negative of distance.[[MET-NEG], [EMP-NEG]]  Number 1 in the equation stands for the normalizing, hence the similarity is defined as follows\" - the 1 does not stand for normalizing, that is the way to invert the cosine distance (put differently, cosine distance is 1-cosine similarity, which is a metric in Euclidean space due to the properties of the dot product).[[EXP-NEG,MET-NEG], [EMP-NEG]]  Another example, \"are obtained using the GloVe vector, not using PPMI\" - there are close relationships between what GloVe learns and PPMI, which the authors seem unaware of (see e.g. the GloVe paper and Omer Levy's work).[[RES-NEG], [EMP-NEG]] \u2028\n\n4. Then there is the additional question, why should we care?[[MET-NEG], [EMP-NEG]]  The paper does not really motivate why it is important to score well on these tests: these kinds of tests are often used as ways to measure the quality of word embeddings, but in this case the main contribution is the similarity metric used *on top* of the word embeddings.[[EXP-NEG], [EMP-NEG]]  In other words, what is supposed to be the take-away, and why should we care?[[MET-NEG], [EMP-NEG]] \n\nAs such, I do not recommend it for acceptance - it needs significant work before it can be accepted at a conference.[[OAL-NEG], [REC-NEG]] \n\nMinor points:\n- Typo in Eq 10\n- Typo on page 6 (/cite instead of \\cite)"[[OAL-NEG], [CLA-NEG]]