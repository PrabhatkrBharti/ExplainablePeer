 "The paper extends softmax consistency by adding in a relative entropy term to the entropy regularization and applying trust region policy optimization instead of gradient descent.[[INT-NEU,PDI-NEU,MET-NEU], [null]]   I am not an expert in this area.[[EXT-NEU], [CNT]]  It is hard to judge the significance of this extension.[[OAL-NEU], [IMP-NEU]] \n\nThe paper largely follows the work of Nachum et al 2017.[[RWK-NEU], [null]]  The differences (i.e., the claimed novelty) from that work are the relative entropy and trust region method for training.[[MET-POS], [NOV-POS]]  However, the relative entropy term added seems like a marginal modification.[[MET-NEG], [EMP-NEG]]