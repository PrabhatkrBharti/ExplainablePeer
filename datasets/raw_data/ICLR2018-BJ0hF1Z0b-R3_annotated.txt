 "This paper extends the previous results on differentially private SGD to user-level differentially private recurrent language models.[[RWK-NEU,PDI-NEU], [CMP-NEU]]  It experimentally shows that the proposed differentially private LSTM achieves comparable utility compared to the non-private model.[[RWK-NEU,EXP-NEU,RES-NEU], [CMP-NEU]] \n\nThe idea of training differentially private neural network is interesting and very important to the machine learning + differential privacy community.[[PDI-POS], [IMP-POS]]  This work makes a pretty significant contribution to such topic.[[OAL-POS], [IMP-POS]]  It adapts techniques from some previous work to address the difficulties in training language model and providing user-level privacy.[[RWK-NEU,MET-NEU], [CMP-NEU]]  The experiment shows good privacy and utility.[[EXP-POS], [EMP-POS]] \n\nThe presentation of the paper can be improved a bit.[[OAL-NEU], [PNF-NEG]]  For example, it might be better to have a preliminary section before Section2 introducing the original differentially private SGD algorithm with clipping, the original FedAvg and FedSGD, and moments accountant as well as privacy amplification; otherwise, it can be pretty difficult for readers who are not familiar with those concepts to fully understand the paper.[[MET-NEU], [PNF-NEU]]  Such introduction can also help readers understand the difficulty of adapting the original algorithms and appreciate the contributions of this work.\n"[[OAL-NEU], [PNF-NEU]]