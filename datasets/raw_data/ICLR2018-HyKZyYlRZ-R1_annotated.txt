 "The paper presents a multi-task, multi-domain model based on deep neural networks.[[INT-NEU], [null]]  The proposed model is able to take inputs from various domains (image, text, speech) and solves multiple tasks, such as image captioning, machine translation or speech recognition.[[PDI-NEU], [null]]  The proposed model is composed of several features learning blocks (one for each input type) and of an encoder and an auto-regressive decoder, which are domain-agnostic.[[INT-NEU,PDI-NEU], [null]]  The model is evaluated on 8 different tasks and is compared with a model trained separately on each task, showing improvements on each task.[[MET-NEU,RES-POS], [EMP-POS]] \n\nThe paper is well written and easy to follow.[[OAL-POS], [CLA-POS,PNF-POS]] \n\nThe contributions of the paper are novel and significant.[[OAL-POS], [NOV-POS,IMP-POS]]  The approach of having one model able to perform well on completely different tasks and type of input is very interesting and inspiring.[[MET-POS], [EMP-POS]]  The experiments clearly show the viability of the approach and give interesting insights.[[EXP-POS,MET-POS], [EMP-POS]]  This is surely an important step towards more general deep learning models.[[RES-POS], [EMP-POS]]  \n\nComments:\n\n* In the introduction where the 8 databases are presented, the tasks should also be explained clearly, as several domains are involved and the reader might not be familiar with the task linked to each database.[[DAT-NEU,MET-NEU], [EMP-NEU]]  Moreover, some databases could be used for different tasks, such as WSJ or ImageNet.[[DAT-NEU], [CNT]] \n\n* The training procedure of the model is not explained in the paper.[[MET-NEU], [SUB-NEU]]  What is the cost function and what is the strategy to train on multiple tasks ?[[EXP-NEU,ANA-NEU], [EMP-NEU]]  The paper should at least outline the strategy.[[MET-NEU], [SUB-NEU]] \n\n* The experiments are sufficient to demonstrate the viability of the approach,[[EXP-POS], [SUB-POS]]  but the experimental setup is not clear.[[EXP-NEG], [EMP-NEG]]  Specifically, there is an issue about the speech recognition part of the experiment.[[EXP-NEG], [EMP-NEG]]  It is not clear what the task exactly is: continuous speech recognition, isolated word recognition ?[[EXP-NEG,MET-NEG], [EMP-NEG]]  The metrics used in Table 1 are also not clear, they should be explained in the text.[[TNF-NEG], [PNF-NEG]]  Also, if the task is continuous speech recognition, the WER (word error rate) metric should be used.[[MET-NEU], [EMP-NEU]]  Information about the detailed setup is also lacking, specifically which test and development sets are used (the WSJ corpus has several sets).[[DAT-NEG,EXP-NEG,MET-NEG], [SUB-NEG]] \n\n* Using raw waveforms as audio modality is very interesting,[[EXP-POS,MET-POS], [EMP-POS]]  but this approach is not standard for speech recognition,[[MET-NEG], [EMP-NEG]]  some references should be provided, such as:\nP. Golik, Z. Tuske, R. Schluter, H. Ney, Convolutional Neural Networks for Acoustic Modeling of Raw Time Signal in LVCSR, in: Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015, pp. 26\u201330.[[BIB-NEU], [SUB-NEU]] \nD. Palaz, M. Magimai Doss and R. Collobert, (2015, April). Convolutional neural networks-based continuous speech recognition using raw speech signal.[[BIB-NEU], [SUB-NEU]]  In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on (pp. 4295-4299). IEEE.[[BIB-NEU], [SUB-NEU]] \nT. N. Sainath, R. J. Weiss, A. Senior, K. W. Wilson, and O. Vinyals.[[BIB-NEU], [SUB-NEU]]  Learning the Speech Front-end With Raw Waveform CLDNNs.[[BIB-NEU], [SUB-NEU]]  Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015.[[BIB-NEU], [SUB-NEU]] \n\nRevised Review:\nThe main idea of the paper is very interesting and the work presented is impressive.[[PDI-POS], [EMP-POS]]  However, I tend to agree with Reviewer2, as a more comprehensive analysis should be presented to show that the network is not simply multiplexing tasks.[[ANA-NEU], [SUB-NEU]]  The experiments are interesting,[[EXP-POS], [EMP-POS]]  except for the WSJ speech task, which is almost meaningless.[[EXP-NEG], [EMP-NEG]]  Indeed, it is not clear what the network has learned given the metrics presented, as the WER on WSJ should be around 5% for speech recognition.[[MET-NEG,RES-NEG], [EMP-NEG]] \nI thus suggest to either drop the speech experiment, or the modify the network to do continuous speech recognition.[[EXP-NEU], [EMP-NEU]]  A simpler speech task such as Keyword Spotting could also be investigated.\n"[[MET-NEU], [EMP-NEU]]