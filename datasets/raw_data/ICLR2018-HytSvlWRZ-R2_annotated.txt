 "The authors propose a DNN, called subspace network, for nonlinear multi-task censored regression problem.[[INT-NEU,PDI-NEU], [null]]  The topic is important. Experiments on real data show improvements compared to several traditional approaches.[[RWK-POS,DAT-POS,EXP-POS], [CMP-POS,EMP-POS]] \n\nMy major concerns are as follows.[[OAL-NEU], [null]] \n\n1. The paper is not self-contained.[[OAL-NEG], [CNT]]  The authors claim that they establish both asymptotic and non-asymptotic convergence properties for Algorithm 1.[[MET-NEU], [null]]  However, for some key steps in the proof, they refer to other references.[[RWK-NEU,MET-NEU], [CMP-NEU]]  If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix.[[MET-NEG], [SUB-NEG,PNF-NEG]] \n\n2. The experiments are unconvincing.[[EXP-NEG], [EMp-NEG]]  They compare the proposed SN with other traditional approaches on a very small data  set with 670 samples and 138 features.[[DAT-NEG,MET-NEG], [SUB-NEG,CMP-NEG]]  A major merit of DNN is that it can automatically extract useful features.[[MET-NEG], [EMP-NEG]]  However, in this experiment, the features are handcrafted before they are fed into the models.[[EXP-NEG], [EMP-NEG]]  Thus, I would like to see a comparison between SN with vanilla DNN. "[[MET-NEU], [CMP-NEU]]