 "This paper focuses on imitation learning with intentions sampled \nfrom a multi-modal distribution.[[INT-NEU,PDI-NEU,EXP-NEU,MET-NEU], [EMP-NEU]]  The papers encode the mode as a hidden \nvariable in a stochastic neural network and suggest stepping around posterior \ninference over this hidden variable (which is generally required to \ndo efficient maximum likelihood) with a biased importance \nsampling estimator. [[PDI-NEU,EXP-NEU,MET-NEU], [null]] Lastly, they incorporate attention for large visual inputs.[[PDI-NEU,DAT-NEU,EXP-NEU], [null]]  \n\nThe unimodal claim for distribution without randomness is weak.[[RWK-NEG,PDI-NEG], [SUB-NEG,IMP-NEG,EMP-NEG]]  The distribution \ncould be replaced with a normalizing flow.[[RWK-NEU,PDI-NEU], [null]]  The use of a latent variable \nin this setting makes intuitive sense, but I don't think multimodality motivates it.[[RWK-NEG,PDI-NEG], [EMP-NEG]] \n\nMoreover, it really felt like the biased importance sampling approach should be \ncompared to a formal inference scheme. [[RWK-NEU,DAT-NEU,EXP-NEU,MET-NEU], [CMP-NEU,EMP-NEU]] I can see how it adds value over sampling \nfrom the prior, but it's unclear if it has value over a modern approximate inference \nscheme like a black box variational inference algorithm or stochastic gradient MCMC.[[RWK-NEU,PDI-NEU,EXP-NEU,MET-NEU], [CLA-NEG]] \n\nHow important is using the pretrained weights from the deterministic RNN?[[RWK-NEU,MET-NEU], [null]] \n\nFinally, I'd also be curious about how much added value you get from having \naccess to extra rollouts.[[RWK-NEU], [EMP-NEU]]