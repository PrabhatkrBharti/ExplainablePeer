 "This paper studies empirical risk in deep neural networks.[[INT-NEU,PDI-NEU], [null]]  Results are provided in Section 4 for linear networks and in Section 5 for nonlinear networks.[[RES-NEU], [null]] \nResults for deep linear neural networks are puzzling.[[RES-NEG], [EMP-NEG]]  Whatever the number of layers, a deep linear NN is simply a matrix multiplication and minimizing the MSE is simply a linear regression.[[MET-NEU], [null]]  So results in Section 4 are just results for linear regression and I do not understand why the number of layers come into play?[[MET-NEU,RES-NEU], [EMP-NEU]]  \nAlso this is never explicitly mentioned in the paper, I guess the authors make an assumption that the samples (x_i,y_i) are drawn i.i.d. from a given distribution D.[[MET-NEG], [PNF-NEG,EMP-NEG]]  In such a case, I am sure results on the population risk minimization can be found for linear regression and should be compare to results in Section 4.\n\n"[[RES-NEU], [CMP-NEU]]