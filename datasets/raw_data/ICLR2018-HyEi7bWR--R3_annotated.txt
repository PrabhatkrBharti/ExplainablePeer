 "The paper is clearly written, with a good coverage of previous relevant literature.[[RWK-POS,OAL-POS], [CLA-POS,CMP-POS]]  \nThe contribution itself is slightly incremental, as several different parameterization of orthogonal or almost-orthogonal weight matrices for RNN have been introduced.[[MET-POS,RES-POS], [EMP-POS]] \nTherefore, the paper must show that this new method performs better in some way compared with previous methods.[[RWK-POS,MET-POS], [CMP-POS,EMP-POS]]  They show that the proposed method is competitive on several datasets and a clear winner on one task: MSE on TIMIT.[[DAT-POS,MET-POS], [CMP-POS,EMP-POS]] \n\nPros:\n1. New, relatively simple method for learning orthogonal weight matrices for RNN[[MET-POS], [EMP-POS]] \n\n2. Clearly written\[[OAL-POS], [CLA-POS]] n\n3. Quite good results on several relevant tasks.[[RES-POS], [CMP-POS,EMP-POS]] \n\nCons:\n1. Technical novelty is somewhat limited[[MET-NEG,OAL-NEG], [NOV-NEG]] \n\n2. Experiments do not evaluate run time, memory use, computational complexity, or stability.[[EXP-NEG], [SUB-NEG]]  Therefore it is more difficult to make comparisons: perhaps restricted-capacity uRNN is 10 times faster than the proposed method?"[[MET-NEU], [EMP-NEU]]