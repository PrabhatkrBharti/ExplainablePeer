 "Interesting ideas that extend LSTM to produce probabilistic forecasts for univariate time series, experiments are okay.[[PDI-POS,EXP-NEU], [EMP-NEU]]  Unclear if this would work at all in higher-dimensional time series.[[FWK-NEU], [IMP-NEU]]  It is also unclear to me what are the sources of the uncertainties captured.\[[OAL-NEU], [CNT]] n\n\nThe author proposed to incorporate 2 different discretisation techniques into LSTM, in order to produce probabilistic forecasts of univariate time series.[[MET-NEU,RES-NEU], [null]]  The proposed approach deviates from the Bayesian framework where there are well-defined priors on the model, and the parameter uncertainties are subsequently updated to incorporate information from the observed data, and propagated to the forecasts.[[DAT-NEU,EXP-NEU,MET-NEU], [null]]  Instead, the conditional density p(y_t|y_{1:t-1|, \\theta}) was discretised by 1 of the 2 proposed schemes and parameterised by a LSTM.[[EXP-NEU], [null]]  The LSTM was trained using discretised data and cross-entropy loss with regularisations to account for ordering of the discretised labels.[[EXP-NEU], [null]]  Therefore, the uncertainties produced by the model appear to be a black-box.[[RES-NEG], [EMP-NEG]]  It is probably unlikely that the discretisation method can be generalised to high-dimensional setting?[[MET-NEU], [EMP-NEU]] \n\nQuality: The experiments with synthetic data sufficiently showed that the model can produce good forecasts and predictive standard deviations that agree with the ground truth. [[EXP-POS,RES-POS], [EMP-POS]] In the experiments with real data, it's unclear how good the uncertainties produced by the model are.[[DAT-NEG,EXP-NEG,RES-NEU], [EMP-NEG]]  It may be useful to compare to the uncertainty produced by a GP with suitable kernels.[[RES-NEU], [CMP-NEU]]  In Fig 6c, the 95pct CI looks more or less constant over time. Is there an explanation for that?[[RES-NEG,TNF-NEG], [SUB-NEG]] \n\nClarity: The paper is well-written.[[OAL-POS], [CLA-POS]]  The presentations of the ideas are pretty clear.[[OAL-POS], [PNF-POS]] \n\nOriginality: Above average.[[PDI-POS,OAL-POS], [NOV-POS]]  I think the regularisation techniques proposed to preserve the ordering of the discretised class label are quite clever.[[MET-POS], [EMP-POS]] \n\nSignificance: Average. [[OAL-POS], [IMP-POS]] It would be excellent if the authors can extend this to higher dimensional time series.[[FWK-NEU], [SUB-NEU,IMP-NEU]] \n\nI'm unsure about the correctness of Algorithm 1 as I don't have knowledge in SMC."[[EXT-NEU], [null]]