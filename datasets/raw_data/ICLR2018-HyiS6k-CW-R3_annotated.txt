 "This paper investigates identity space learning with well-controlled variations using an artistic portraits dataset.[[INT-NEU,PDI-NEU], [null]]  Especially, the authors propose a visual Turing test to evaluate the synthesize quality of three generative models: WGAN-GP, DFC-VAE, and Pixel VAE.[[INT-NEU,PDI-NEU], [null]] \n\nThe submission has following PROS:\n\n+ The proposed visual Turing test provides a novel solution to evaluate the generation quality.[[RES-POS], [NOV-POS]]  The test not only distinguishes real from synthesized faces but also evaluates the observer ability by determining whether the observer is a human.[[MET-POS], [EMP-POS]]  This is a merit compared with existing protocols used in generation evaluation.[[RWK-POS,MET-POS], [NOV-POS]]  \n\n+ The generated face images are very impressive, especially the improved 512x512-pixel outputs.[[RES-POS], [EMP-POS]] \n\n+ The paper presents a promising application in police composite sketching, which can significantly improve human-in-the-loop search in face modeling.[[RES-POS,FWK-POS], [IMP-POS]]  \n\nHowever, the submission also suffers from multiple CONS:\n\n- The novelty of this paper is limited.[[OAL-NEG], [NOV-NEG]]  The only novelty I can pinpoint is the proposed visual Turing test.[[MET-NEU], [SUB-NEG]]  The dataset, as well as all investigated models/approaches, are existing work.[[DAT-NEU,MET-NEU], [NOV-NEU]]  The visual Turing test is interesting but not concrete enough to support an ICLR publication.[[MET-NEG], [APR-NEG,REC-NEG]] \n\n- A very small dataset (3,300 subjects and 3,353 images) is used in the whole investigation.[[DAT-NEG], [SUB-NEG]]  It is doubtful that the conclusion or results obtained in this small dataset could be scaled up to real-world applications or datasets (millions of subjects and images).[[DAT-NEG,RES-NEG], [SUB-NEG]]  It would be favorable to empirically prove this by designing additional experiments.[[EXP-NEU], [SUB-NEU]] \n\n- Missing details.[[ANA-NEG], [SUB-NEG]]  \n(a)In section 4, how to use formal method (Ledig et al., 2016) to enlarge the portrait from 64x64 to 512x512 is unclear.[[RWK-NEU,MET-NEG], [CMP-NEG]] \n(b) Lacking details of the model setups and training strategies.[[EXP-NEG,ANA-NEG], [SUB-NEG]]  The generation models are usually highly sensitive to details settings.[[MET-NEG], [EMP-NEG]]  The readers can hardly reproduce the results or evaluate possible performance by reading the paper.[[RES-NEG], [EMP-NEG]]  \n(c) If the paper length is limited, a supplementary material about those details would be preferred.[[ANA-NEU], [SUB-NEU]] \n\n- Typos.\n(a) Page 7, \"Figure 8 shows the seeds and example images for 10 rounds...\"[[TNF-NEG], [CLA-NEG,PNF-NEG]]  \n----> Figure 8 should be Figure 10\n(b) Page 4, \"yet is is unclear how many pixels are required...\"\n----> yet is is"[[TNF-NEG], [CLA-NEG,PNF-NEG]]