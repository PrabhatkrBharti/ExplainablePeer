 "In this paper, the authors study the relationship between training GANs and primal-dual subgradient methods for convex optimization.[[INT-NEU,PDI-NEU], [null]]  Their technique can be applied on top of existing GANs and can address issues such as mode collapse.[[MET-NEU], [null]]  The authors also derive a GAN variant similar to WGAN which is called the Approximate WGAN.[[MET-NEU], [null]]  Experiments on synthetic datasets demonstrate that the proposed formulation can avoid mode collapse.[[EXP-NEU], [null]]  This is a strong contribution[[EXP-POS,MET-POS], [EMP-POS]] \n\nIn Table 2 the difference between inception scores for DCGAN and this approach seems significant to ignore.[[TNF-NEG,MET-NEG], [SUB-NEG]]  The authors should explain more possibly.[[MET-NEG], [SUB-NEG]] \nThere is a typo in Page 2 \u2013 For all these varaints, -variants.\n"[[CNT], [CLA-NEG]]