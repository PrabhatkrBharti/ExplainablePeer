 "\n-----UPDATE------\n\nHaving read the responses from the authors, and the other reviews, I am happy with my rating and maintain that this paper should be accepted.[[EXT-POS], [REC-POS]] \n\n----------------------\n\n\n\nIn this paper, the authors trains a large number of MNIST classifier networks with differing attributes (batch-size, activation function, no. layers etc.) and then utilises the inputs and outputs of these networks to predict said attributes successfully.[[INT-NEU], [null]]  They then show that they are able to use the methods developed to predict the family of Imagenet-trained networks and use this information to improve adversarial attack[[MET-NEU], [NULL]] .\n\nI enjoyed reading this paper.[[OAL-POS], [CLA-POS]]  It is a very interesting set up, and a novel idea.[[MET-POS], [NOV-POS]] \n\nA few comments:\n\nThe paper is easy to read, and largely written well[[OAL-POS], [CLA-POS]] . The article is missing from the nouns quite often though so this is something that should be amended. There are a few spelling slip ups (\"to a certain extend\" --> \"to a certain extent\", \"as will see\" --> \"as we will see\")][[OAL-NEG], [CLA-NEG]] \n\nIt appears that the output for kennen-o is a discrete probability vector for each attribute, where each entry corresponds to a possibility (for example, for \"batch-size\" it is a length 3 vector where the first entry corresponds to 64, the second 128, and the third 256)[[DAT-NEU,RES-NEU], [SUB-NEU]] . What happens if you instead treat it as a regression task, would it then be able to hint at intermediates (a batch size of 96) or extremes (say, 512).\[[EXP-NEU], [EMP-NEU]] n\nA flaw of this paper is that kennen-i and io appear to require gradients from the network being probed (you do mention this in passing), which realistically you would never have access to. (Please do correct me if I have misunderstood this)[[MET-NEG], [EMP-NEG]] \n\nIt would be helpful if Section 4 had a paragraph as to your thoughts regarding why certain attributes are easier/harder to predict[[MET-NEU], [CLA-NEU]] . Also, the caption for Table 2 could contain more information regarding the network outputs.[[TNF-NEU], [CLA-NEU]] \n\nYou have jumped from predicting 12 attributes on MNIST to 1 attribute on Imagenet[[MET-NEU], [EMP-NEU]] . It could be beneficial to do an intermediate experiment (a handful of attributes on a middling task)[[EXP-NEU], [SUB-NEU]] .\n\nI think this paper should be accepted as it is interesting and novel[[OAL-POS], [NOV-POS,REC-POS]] .\n\nPros\n------\n- Interesting idea[[PDI-POS], [null]] \n- Reads well[[OAL-POS], [CLA-POS]] \n- Fairly good experimental results[[RES-POS], [null]] \n\nCons\n------\n- kennen-i seems like it couldn't be realistically deployed\n- lack of an intermediate difficulty task\n[[MET-NEG], [EMP-NEG]]