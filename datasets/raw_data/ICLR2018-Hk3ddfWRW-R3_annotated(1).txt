 "This paper focuses on imitation learning with intentions sampled \nfrom a multi-modal distribution.[[INT-NEU,EXP-NEU,MET-NEU], [null]]  The papers encode the mode as a hidden \nvariable in a stochastic neural network and suggest stepping around posterior \ninference over this hidden variable (which is generally required to \ndo efficient maximum likelihood) with a biased importance \nsampling estimator.[[RWK-NEU], [EMP-NEU]]  Lastly, they incorporate attention for large visual inputs.[[RWK-NEU,MET-NEU], [null]]  \n\nThe unimodal claim for distribution without randomness is weak.[[RWK-NEU,MET-NEG], [IMP-NEG,EMP-NEG]]  The distribution \ncould be replaced with a normalizing flow. [[RWK-NEU,EXP-NEG], [EMP-NEG]] The use of a latent variable \nin this setting makes intuitive sense, but I don't think multimodality motivates it.[[RWK-NEU,PDI-NEU,MET-NEG], [EMP-NEG]] \n\nMoreover, it really felt like the biased importance sampling approach should be \ncompared to a formal inference scheme.[[EXP-NEG,MET-NEG,OAL-NEG], [IMP-NEG,EMP-NEG]]  I can see how it adds value over sampling \nfrom the prior, but it's unclear if it has value over a modern approximate inference \nscheme like a black box variational inference algorithm or stochastic gradient MCMC.[[RWK-NEU,PDI-NEG,EXP-NEU,MET-NEU], [EMP-NEG]] \n\nHow important is using the pretrained weights from the deterministic RNN?[[PDI-NEU,MET-NEU], [null]] \n\nFinally, I'd also be curious about how much added value you get from having \naccess to extra rollouts.[[PDI-NEU], [null]]