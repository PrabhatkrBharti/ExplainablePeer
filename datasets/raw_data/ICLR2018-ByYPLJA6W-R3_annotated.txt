 "This is an intriguing paper on running regressions on probability distributions: i.e. a target distribution is expressed as a function of input distributions. [[INT-NEU], [null]] A well-written manuscript,;[[OAL-POS], [CLA-POS]]  though the introduction could have motivated the problem a little better (i.e. why would we want to do this).[[INT-NEU], [null]]  The novelty in the paper is implementing such a regression in a layered network.[[MET-NEU], [NOV-NEU]]  The paper shows how the densities at each nodes are computed (and normalised).[[MET-NEU], [null]]  Optimisation by back propagation and discretization of the densities to carry out numerical integration are well explained and easy to follow.[[MET-POS], [EMP-POS]]  The paper uses three problems to illustrate the idea -- a synthetic dataset, a mean reverting stochastic process and a prediction problem on stock indices. [[PDI-NEU,DAT-NEU,MET-NEU], [null]]  \nMy only two reservations of this paper is the illustration on the stock index data -- it seems to me, returns on individual constituent stocks of an index are used as samples of the return on the index itself.[[DAT-NEU,EXP-NEU], [EMP-NEU]]   But this cannot be true when the index is a weighted sum of the constituent assets.  [[MET-NEU], [EMP-NEG]] Secondly, it is not clear to me why one would force a kernel density estimate on the asset returns and then bin the density into 100 bins for numerical reasons;[[MET-NEU], [EMP-NEU]]  -- does the smoothing that results from this give any advantage over a histogram of the returns in 100 bins?[[MET-NEU,RES-NEU], [EMP-NEU]]