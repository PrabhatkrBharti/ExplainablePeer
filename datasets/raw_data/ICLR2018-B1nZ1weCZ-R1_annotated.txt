 "The paper present online algorithms for learning multiple sequential problems.[[INT-NEU], [null]]  The main contribution is to introduce active learning principles for sampling the sequential tasks in an online algorithm.[[PDI-NEU], [null]]  The contributions are interesting and experimental results seem promising.[[EXP-POS,RES-POS], [EMP-POS]]  But the paper is difficult to read due to many different ideas and because some algorithms and many important explanations must be found in the Appendix (ten sections in the Appendix and 28 pages).[[MET-NEG], [PNF-NEG]]  Also, most of the paper is devoted to the study of algorithms for which the expected target scores are known.[[MET-NEG], [SUB-NEG]]  This is a very strong assumption.[[MET-NEU], [null]]  In my opinion, the authors should have put the focus on the DU4AC algorithm which get rids of this assumption.[[MET-NEG], [EMP-NEG]]  Therefore, I am not convinced that the paper is ready for publication at ICLR'18.[[OAL-NEG], [REC-NEG]] \n* Differences between BA3C and other algorithms are said to be a consequence of the probability distribution over tasks.[[MET-NEU], [EMP-NEU]]  The gap is so large that I am not convinced on the fairness of the comparison[[MET-NEG], [CMP-NEG]] . For instance, BA3C (Algorithm 2 in Appendix C) does not have the knowledge of the target scores while others heavily rely on this knowledge.[[MET-NEG], [CMP-NEG]] \n* I do not see how the single output layer is defined.[[MET-NEG], [EMP-NEG]] \n* As said in the general comments, in my opinion Section 6 should be developped and more experiments should be done with the DUA4C algorithm.[[EXP-NEG,MET-NEG], [SUB-NEG]] \n* Section 7.1. It is not clear why degradation does not happen. [[MET-NEG], [EMP-NEG]] It seems to be only an experimental fact."[[EXP-NEG], [EMP-NEG]]