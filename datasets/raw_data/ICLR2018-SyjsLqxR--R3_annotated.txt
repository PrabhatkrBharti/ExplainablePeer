 "This paper investigates the effect of adversarial training.[[MET-NEU], [null]]  Based on experiments using CIFAR10, the authors show that adversarial training is effective in protecting against \"shared\" adversarial perturbation, in particular against universal perturbation.[[DAT-NEU,EXP-NEU], [null]]  In contrast, it is less effective to protect against singular perturbations.[[MET-NEU], [null]]  Then they show that singular perturbation are less robust to image transformation, meaning after image transformation those perturbations are no longer effective.[[MET-NEU,RES-NEU], [null]]  Finally, they show that singular perturbations can be easily detected.[[MET-NEU], [EMP-NEU]] \n\nI like the message conveyed in this paper.[[OAL-POS], [CNT]]  However, as the statements are mostly backed by experiments, then I think it makes sense to ask how statistically significant the present results are.[[DAT-NEU,EXP-NEU,RES-NEU], [EMP-NEU]]  Moreover, is CIFAR 10 experiments conclusive enough. "[[DAT-NEU], [EMP-NEU]]