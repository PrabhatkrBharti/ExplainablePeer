 "The authors propose a probabilistic framework for semi-supervised learning and domain adaptation.[[INT-NEU,PDI-NEU], [null]]  By varying the prior distribution, the framework can incorporate both generative and discriminative modeling.[[PDI-NEU], [null]]   The authors emphasize on one particular form of constraint on the prior distribution, that is weight (parameter) sharing, and come up with a concrete model named Dauto for domain adaptation.[[MET-NEU], [null]]  A domain confusion loss is added to learn domain-invariant feature representations.[[MET-NEU], [null]]  The authors compared Dauto with several baseline methods on several datasets and showed improvement.[[RWK-NEG,DAT-POS,MET-POS], [CMP-POS,EMP-POS]] \n\nThe paper is well-organized and easy to follow.[[OAL-POS], [CLA-POS]]  The probabilistic framework itself is quite straight-forward.[[MET-POS], [EMP-POS]]  The paper will be more interesting if the authors are able to extend the discussion on different forms of prior instead of the simple parameter sharing scheme.[[MET-NEU], [SUB-NEU]]  \n\nThe proposed DAuto is essentially DANN+autoencoder.[[MET-NEU], [null]]   The minimax loss employed in DANN and DAuto is known to be prone to degenerated gradient for the generator.[[MET-NEU], [null]]  It would be interesting to see if the additional auto-encoder part help address the issue.[[MET-NEU], [SUB-NEU]]  \n\nThe experiments miss some of the more recent baseline in domain adaptation, such as Adversarial Discriminative Domain Adaptation (Tzeng, Eric, et al. 2017).[[RWK-NEG,EXP-NEG], [SUB-NEG]]  \n\nIt could be more meaningful to organize the pairs in table by target domain instead of source, for example, grouping 9->9, 8->9, 7->9 and 3->9 in the same block.[[EXP-NEG], [PNF-NEG]]  DAuto does seem to offer more boost in domain pairs that are less similar. "[[MET-NEU], [EMP-NEU]]