 "This paper proposes a method to learn networks invariant to translation and equivariant to rotation and scale of arbitrary precision.[[INT-NEU,MET-NEU], [null]]  The idea is to jointly train[[PDI-NEU], [null]] \n- a network predicting a polar origin,[[EXP-NEU,MET-NEU], [null]] \n- a module transforming the image into a log-polar representation according to the predicted origin,[[EXP-NEU,MET-NEU], [null]] \n- a final classifier performing the desired classification task.[[EXP-NEU,MET-NEU], [null]] \nRotation and scale from the polar origin result in translation of the log-polar representation.[[EXP-NEU,MET-NEU], [null]]  Rotation and scale can have arbitrary precision, which is novel to the best of my knowledge.[[EXP-POS,MET-POS], [NOV-POS]] \n\n(+) In my opinion, this is a simple, attractive approach to rotation and scale equivariant CNNs.[[MET-POS], [EMP-POS]] \n\n(-) The evaluation, however, is quite limited.[[MET-NEG], [SUB-NEG]]  The approach is evaluated on:\n 1) several variants of MNIST.[[DAT-NEU,MET-NEU], [null]]  The authors introduce a new variant (SIM2MNIST), which is created by applying random similitudes to the images from MNIST.[[DAT-POS,MET-POS], [NOV-POS]]  This variant is of course very well suited to the proposed method, and a bit artificial.[[DAT-POS,MET-POS], [EMP-POS]]  \n 2) 3d voxel occupancy grids with a small resolution.[[MET-NEU], [EMP-NEU]]   The objects can be rotated around the z-axis, and the method is used to be equivariant to this rotation.[[MET-NEU], [EMP-NEU]]   \n\n(-) Since the method starts by predicting the polar origin, wouldn't it be possible to also predict rotation and scale?[[MET-NEU], [EMP-NEU]]    Then the input image could be rectified to a canonical orientation and scale, without needing equivariance.[[MET-NEU], [EMP-NEU]]    My intuition is that this simpler approach would work better.[[MET-POS], [EMP-POS]]