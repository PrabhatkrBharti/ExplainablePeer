 "The authors proposed to compress word embeddings by approximate matrix factorization, and to solve the problem with the Gumbel-soft trick.[[INT-NEU,PDI-NEU], [null]]  The proposed method achieved compression rate 98% in a sentiment analysis task, and compression rate over 94% in machine translation tasks, without a performance loss.[[MET-POS,RES-POS], [EMP-POS]]  \n\nThis paper is well-written and easy to follow.[[OAL-POS], [CLA-POS]]   The motivation is clear and the idea is simple and effective.\[[PDI-POS], [IMP-POS]] n\nIt would be better to provide deeper analysis in Subsection 6.1.[[ANA-NEU], [SUB-NEU]]  The current analysis is too simple. [[ANA-NEG], [SUB-NEG]] It may be interesting to explain the meanings of individual components.[[ANA-NEU], [SUB-NEU]]  Does each component is related to a certain topic?[[ANA-NEU], [EMP-NEU]]  Is it meaningful to perform ADD or SUBSTRACT on the leaned code?[[MET-NEU], [EMP-NEU]]  \n\nIt may also be interesting to provide suitable theoretical analysis, e.g., relationships with the SVD of the embedding matrix.\n"[[ANA-NEU], [EMP-NEU]]