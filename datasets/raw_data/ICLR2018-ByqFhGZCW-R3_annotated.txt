 "The authors describe a mechanism for defending against adversarial learning attacks on classifiers.[[INT-NEU], [null]]  They first consider the dynamics generated by the following procedure.[[MET-NEU], [null]]  They begin by training a classifier, generating attack samples using FGSM, then hardening the classifier by retraining with adversarial samples, generating new attack samples for the retrained classifier, and repeating.[[DAT-NEU,MET-NEU], [null]]   \n\nThey next observe that since FGSM is given by a simple perturbation of the sample point by the gradient of the loss, that the fixed point of the above dynamics can be optimized for directly using gradient descent.[[MET-NEU,ANA-NEU], [EMP-NEU]]  They call this approach Sens FGSM, and evaluate it empirically against the various iterates of the above approach.[[MET-NEU], [EMP-NEU]]  \n\nThey then generalize this approach to an arbitrary attacker strategy given by some parameter vector (e.g. a neural net for generating adversarial samples).[[MET-NEU], [EMP-NEU]]  In this case, the attacker and defender are playing a minimax game, and the authors propose finding the minimax (or maximin) parameters using an algorithm which alternates between maximization and minimization gradient steps.[[MET-NEU], [EMP-NEU]]  They conclude with empirical observations about the performance of this algorithm.[[EXP-NEU,MET-NEU,ANA-NEU], [EMP-NEU]] \n\nThe paper is well-written and easy to follow.[[OAL-POS], [CLA-POS]]  However, I found the empirical results to be a little underwhelming.[[RES-NEU], [EMP-NEU]]  Sens-FGSM outperforms the adversarial training defenses tuned for the \u201cwrong\u201d iteration, but it does not appear to perform particularly well with error rates well above 20%.[[EXP-NEU], [EMP-NEG]]  How does it stack up against other defense approaches (e.g. https://arxiv.org/pdf/1705.09064.pdf)?[[EXP-NEU], [null]]  Furthermore, what is the significance of FGSM-curr (FGSM-81) for Sens-FGSM? [[MET-NEU], [IMP-NEU]] It is my understanding that Sens-FGSM is not trained to a particular iteration of the \u201ccat-and-mouse\u201d game.[[MET-NEU], [EMP-NEU]]  Why, then, does Sens-FGSM provide a consistently better defense against FGSM-81?[[MET-NEU], [EMP-NEU]]  With regards to the second part of the paper, using gradient methods to solve a minimax problem is not especially novel (i.e. Goodfellow et al.),;[[RWK-NEU,MET-NEU], [NOV-NEG]]  thus I would liked to see more thorough experiments here as well.[[EXP-NEU], [SUB-NEU]]  For example, it\u2019s unlikely that the defender would ever know the attack network utilized by an attacker.[[EXP-NEG], [EMP-NEG]]  How robust is the defense against samples generated by a different attack network?[[DAT-NEU,EXP-NEU], [EMP-NEU]]  The authors seem to address this in section 5 by stating that the minimax solution is not meaningful for other network classes. However, this is a bit unsatisfying.[[MET-NEU,ANA-NEU], [EMP-NEU]]  Any defense can be *evaluated* against samples generated by any attacker strategy.[[MET-NEU], [EMP-NEU]]  Is it the case that the defenses fall flat against samples generated by different architectures? [[MET-NEU], [EMP-NEU]] \n\n\nMinor Comments:\nSection 3.1, First Line. \u201df(ul(g(x),y))\u201d appears to be a mistake.[[OAL-NEU], [CLA-NEG]]