 "I have read comments and rebuttal - i do not have the luxury of time to read in depth the revision.[[EXT-NEU], [null]] \nIt seems that the authors have made an effort to accommodate reviewers' comments.[[EXT-POS], [null]]  I upgraded the rating.[[OAL-POS], [REC-POS]] \n\n-----------------------------------------------------------------------------------------------------------------------\n\nSummary: The paper considers the use of natural gradients for learning.[[INT-NEU], [null]]  The added twist is the substitution of the KL divergence with the Wasserstein distance, as proposed in GAN training.[[RWK-NEU,MET-NEU], [null]]  The authors suggest that Wasserstein regularization improves generalization over SGD with a little extra cost.[[MET-POS], [null]] \n\nThe paper is structured as follows:\n1. KL divergence is used as a similarity measure between two distributions.[[MET-NEU], [null]] \n2. Regularizing the objective with KL div. seems promising, but expensive.[[MET-POS], [null]] \n3. We usually approximate the KL div. with its 2nd order approximation - this introduces the Hessian of the KL divergence, known as Fisher information matrix.[[MET-NEU], [null]] \n4. However, computing and inverting the Fisher information matrix is computationally expensive.[[MET-NEU], [null]] \n5. One solution is to approximate the solution F^{-1} J using gradient descent.[[MET-NEU], [null]]  However, still we need to calculate F.[[MET-NEU], [null]]  There are options where F could be formed as the outer product of a collection gradients of individual examples ('empirical Fisher').[[MET-NEU], [EMP-NEU]] \n6. This paper does not move towards Fisher information, but towards Wasserstein distance: after a \"good\" initialization via SGD is obtained, the inner loop continues updating that point using the Wasserstein regularized objective.[[MET-NEU], [EMP-NEU]]  \n7. No large matrices need to be formed or inverted, however more passes needed per outer step.[[EXP-NEU,MET-NEU], [EMP-NEU]] \n\nImportance:\nSomewhat lack of originality and poor experiments lead to low importance.[[EXP-NEG], [NOV-NEG]] \n\nClarity:\nThe paper needs major revision w.r.t. presenting and highlighting the new main points.[[OAL-NEG], [CLA-NEG,PNF-NEG]]  E.g., one needs to get to page 5 to understand that the paper is just based on the WGAN ideas in Arjovsky et al., but with a different application (not GANS).[[RWK-NEU,PDI-NEU], [CLA-NEG,PNF-NEG]] \n\nOriginality/Novelty:\nThe paper, based on WGAN motivation, proposes Wasserstein distance regularization over KL div. regularization for training of simple models, such as neural networks.[[RWK-NEU,MET-NEU], [EMP-NEU]]  Beyond this, the paper does not provide any futher original idea.[[MET-NEU], [NOV-NEU]]  So, slight to no novelty.[[MET-NEU], [NOV-NEG]] \n\nMain comments:\n1. Would the approximation of C_0 by its second-order Taylor expansion (that also introduces a Hessian) help?[[MET-NEU], [EMP-NEU]]  This would require the combination of two Hessian matrices.[[MET-NEU], [EMP-NEU]] \n\n2. Experiments are really demotivating: it is not clear whether using plain SGD or the proposed method leads to better results.[[EXP-NEG], [EMP-NEG]]  \n\nOverall:\nRejection.[[OAL-NEG], [REC-NEG]]