 "Clarity \nThe paper is well-written and clear.[[OAL-POS], [CLA-POS]]  \n\nOriginality\nThe paper proposes a path consistency learning method with a new combination of entropy regularization and relative entropy.[[INT-NEU,MET-NEU], [null]]  The paper leverages a novel method in determining the coefficient of relative entropy.[[INT-POS,MET-POS], [NOV-POS]]   \n\nSignificance\n- Trust-PCL achieves overall competitive with state-of-the-art external implementations.[[MET-POS,RWK-POS], [IMP-POS,CMP-POS]] \n- Trust-PCL (off-policy) significantly outperform TRPO in terms of data efficiency and final performance.[[RES-POS], [EMP-POS]]   \n- Even though the paper claims Trust-PCL (on-policy) is close to TRPO, the initial performance of TRPO looks better in HalfCheetah, Hopper, Walker2d and Ant.[[RWK-NEG,RES-NEG], [CMP-NEG]]   \n- Some ablation studies (e.g., on entropy regularization and relative entropy) and sensitivity analysis on parameters (e.g. \\alpha and update frequency on \\phi) would be helpful.[[ANA-NEU], [SUB-NEU]]  \n\nPros:\n- The paper is well-written and clear.[[OAL-POS], [CLA-POS]]   \n- Competitive with state-of-the-art external implementations[[RWK-POS], [CMP-POS]]  \n- Significant empirical advantage over TRPO.[[MET-POS], [EMP-POS]]  \n-  Open source codes.[[MET-POS], [EMP-POS]]  \n\nCons:\n- No ablation studies. \n"[[ANA-NEG], [SUB-NEG]]