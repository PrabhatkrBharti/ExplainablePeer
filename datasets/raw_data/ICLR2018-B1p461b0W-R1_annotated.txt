 "The paper makes a bold claim, that deep neural networks are robust to arbitrary level of noise.[[INT-NEU], [null]]  It also implies that this would be true for any type of noise, and support this later claim using experiments on CIFAR and MNIST with three noise types: (1) uniform label noise (2) non-uniform but image-independent label noise, which is named \"structured noise\", and (3) Samples from out-of-dataset classes.[[PDI-NEU], [EMP-NEU]]  The experiments show robustness to these types of noise.[[EXP-NEU], [EMP-NEU]]  \n\nReview: \nThe claim made by the paper is overly general, and in my own experience incorrect when considering real-world-noise.[[EXP-NEG], [EMP-NEG]]  This is supported by the literature on \"data cleaning\" (partially by the authors), a procedure which is widely acknowledged as critical for good object recognition.[[MET-NEU], [EMP-NEU]]   While it is true that some image-independent label noise can be alleviated in some datasets, incorrect labels in real world datasets can substantially harm classification accuracy.[[DAT-NEG,RES-NEG], [EMP-NEG]] \n\nIt would be interesting to understand the source of the difference between the results in this paper and the more common results (where label noise damages recognition quality).[[RES-NEU], [EMP-NEU]]  The paper did not get a chance to test these differences, and I can only raise a few hypotheses.[[RES-NEG], [CMP-NEG]]  First, real-world noise depends on the image and classes in a more structured way. For instance, raters may confuse one bird species from a similar one, when the bird is photographed from a particular angle.[[EXT-NEU], [null]]  This could be tested experimentally, for example by adding incorrect labels for close species using the CUB data for fine-grained bird species recognition. [[EXT-NEU], [null]]   Another possible reason is that classes in MNIST and CIFAR10 are already very distinctive, so are more robust to noise.[[DAT-POS], [EMP-POS]]   Once again, it would be interesting for the paper to study why they achieve robustness to noise while the effect does not hold in general.[[ANA-NEU], [SUB-NEU]]   \n\nWithout such an analysis, I feel the paper should not be accepted to ICLR because the way it states its claim may mislead readers.[[ANA-NEG,OAL-NEG], [SUB-NEG,REC-NEG]]   \n\nOther specific comments: \n-- Section 3.4 the experimental setup, should clearly state details of the optimization, architecture and hyper parameter search.[[EXP-NEU], [EMP-NEU]]   For example, for Conv4, how many channels at each layer?[[MET-NEU], [EMP-NEU]]   how was the net initialized? [[EXP-NEU], [EMP-NEU]] which hyper parameters were tuned and with which values?[[EXP-NEU], [EMP-NEU]]  were hyper parameters tuned on a separate validation set?[[MET-NEU], [EMP-NEU]]  How was the train/val/test split done, etc.[[EXP-NEU], [EMP-NEU]]  These details are useful for judging technical correctness.[[MET-NEU], [null]] \n-- Figure 8 failed to show for me.[[TNF-NEG], [PNF-NEG]]  \n-- Figure 9,10, need to specify which noise model was used.\n\n\n\n\n\n"[[TNF-NEG], [EMP-NEG]]