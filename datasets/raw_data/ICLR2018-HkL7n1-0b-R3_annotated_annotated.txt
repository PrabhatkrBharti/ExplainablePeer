 "This paper provides a reasonably comprehensive generalization to VAEs and Adversarial Auto-encoders through the lens of the Wasserstein metric.[[INT-NEU,EXP-NEU,MET-NEU], [null]]  By posing the auto-encoder design as a dual formulation of optimal transport, the proposed work supports the use of both deterministic and random decoders under a common framework.[[RWK-NEU,PDI-NEU,EXP-NEU,MET-NEU], [EMP-NEU]]  In my opinion, this is one of the crucial contributions of this paper.[[OAL-NEU], [IMP-POS]]  While the existing properties of auto-encoders are preserved, stability characteristics of W-GANs are also observed in the proposed architecture.[[RWK-NEU,MET-NEU], [EMP-NEU]]  The results from MNIST and CelebA datasets look convincing, though could include additional evaluation to compare the adversarial loss with the straightforward MMD metric and potentially discuss their pros and cons.[[MET-NEU,RES-POS,OAL-NEU], [IMP-POS,CMP-NEU]]  In some sense, given the challenges in evaluating and comparing closely related auto-encoder solutions, the authors could design demonstrative experiments for cases where Wassersterin distance helps and may be  its potential limitations.[[RWK-NEU,EXP-NEU,MET-NEU,RES-NEU], [EMP-NEU]] \n\nThe closest work to this paper is the adversarial variational bayes framework by Mescheder et.al.[[RWK-NEU,MET-NEU,BIB-NEU], [null]]  which also attempts at unifying VAEs and GANs.[[RWK-NEU,MET-NEU], [null]]  While the authors describe the conceptual differences and advantages over that approach, it will be beneficial to actually include some comparisons in the results section.[[RES-NEG,OAL-NEG], [SUB-NEG,CMP-NEG]]