 "The article \"Do GANs Learn the Distribution?[[EXT-NEU], [null]]  Some Theory and Empirics\" considers the important problem of quantifying whether the distributions obtained from generative adversarial networks come close to the actual distribution of images.[[EXT-NEU], [null]]  The authors argue that GANs in fact generate the distributions with fairly low support.[[PDI-NEU], [null]] \n\nThe proposed approach relies on so-called birthday paradox which allows to estimate the number of objects in the support by counting number of matching (or very similar) pairs in the generated sample.[[MET-NEU], [null]]  This test is expected to experimentally support the previous theoretical analysis by Arora et al. (2017).[[RWK-NEU,MET-NEU,ANA-NEU], [CMP-NEU]]  The further theoretical analysis is also performed showing that for encoder-decoder GAN architectures the distributions with low support can be very close to the optimum of the specific (BiGAN) objective.[[ANA-NEU,EXP-NEU,MET-NEU], [EMP-NEU]] \n\nThe experimental part of the paper considers the CelebA and CIFAR-10 datasets.[[DAT-NEU,EXP-NEU], [null]]  We definitely see many very similar images in fairly small sample generated.[[DAT-NEU,TNF-NEU], [null]]  So, the general claim is supported.[[MET-POS], [EMP-POS]]  However, if you look closely at some pictures, you can see that they are very different though reported as similar.[[TNF-NEU], [null]]  For example, some deer or truck pictures.[[TNF-NEU], [null]]  That's why I would recommend to reevaluate the results visually, which may lead to some change in the number of near duplicates and consequently the final support estimates.[[RES-NEU], [EMP-NEU]] \n\nTo sum up, I think that the general idea looks very natural and the results are supportive.[[RES-POS], [EMP-POS]]  On theoretical side, the results seem fair (though I didn't check the proofs) and, being partly based on the previous results of Arora et al. (2017), clearly make a step further."[[RWK-POS,RES-POS], [CMP-POS,EMP-POS]]