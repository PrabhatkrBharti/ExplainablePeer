 "This is quite an interesting paper. Thank you.[[OAL-POS], [null]]  Here are a few comments:\n\nI think this style of writing theoretical papers is pretty good, where the main text aims of preserving a coherent story while the technicalities of the proofs are sent to the appendix.[[OAL-POS], [CLA-POS,PNF-POS]]  \nHowever I would have appreciated a little bit more details about the proofs in the main text (maybe more details about the construct that is involved).[[MET-NEG], [SUB-NEG]]  I can appreciate though that this a fine line to walk.[[MET-POS], [EMP-POS]]  Also in the appendix, please restate the lemma that is being proven.[[MET-NEU], [EMP-NEU]]  Otherwise one will have to scroll up and down all the time to understand the proof.[[MET-NEG], [PNF-NEG]]  \n\nI think the paper could also discuss a bit more in detail the results provided.[[RES-NEU], [SUB-NEU]]  For example a discussion of how practical is the algorithm proposed for exact counting of linear regions would be nice.[[MET-NEU], [SUB-NEU]]  Though regardless, I think the findings speak for themselves and this seems an important step forward in understanding neural nets.[[RES-POS,OAL-POS], [IMP-POS]]  \n\n****************\nI had reduced my score based on the observation made by Reviewer 1 regarding the talk Montufar at SampTA.[[EXT-NEG,OAL-NEU], [REC-NEG]]  Could the authors prioritize clarification to that point ![[RWK-NEU], [SUB-NEU]]  \n - Thanks for the clarification and adding this citation. "[[BIB-POS,OAL-POS], [SUB-POS]]