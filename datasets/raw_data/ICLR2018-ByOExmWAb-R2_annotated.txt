 "Quality: The work focuses on a novel problem of generating text sample using GAN and a novel in-filling mechanism of words.[[PDI-POS], [NOV-POS]]  Using GAN to generate samples in adversarial setup in texts has been limited due to the mode collapse and training instability issues.[[MET-NEU], [EMP-NEU]]  As a remedy to these problems an in-filling-task conditioning on the surrounding text has been proposed.[[MET-NEU], [null]]  But, the use of the rewards at every time step (RL mechanism) to employ the actor-critic training procedure could be challenging computationally challenging.[[MET-NEU], [EMP-NEU]] \n\nClarity: The mechanism of generating the text samples using the proposed methodology has been described clearly.[[MET-POS], [EMP-POS]]  However the description of the reinforcement learning step could have been made a bit more clear.[[MET-NEU], [EMP-NEU]] \n\nOriginality: The work indeed use a novel mechanism of in-filling via a conditioning approach to overcome the difficulties of GAN training in text settings. [[MET-POS], [NOV-POS]] There has been some work using GAN to generate adversarial examples in textual context too to check the robustness of classifiers.[[EXP-NEU,MET-NEU], [EMP-NEU]]  How this current work compares with the existing such literature?[[RWK-NEU,MET-NEU], [CMP-NEU]] \n\nSignificance: The research problem is indeed significant since the use of GAN in generating adversarial examples in image analysis has been more prevalent compared to text settings.[[PDI-POS,MET-POS], [IMP-POS]]  Also, the proposed actor-critic training procedure via RL methodology is indeed significant from its application in natural language processing.[[EXP-POS,MET-POS], [IMP-POS]] \n\npros:\n(a) Human evaluations applications to several datasets show the usefulness of MaskGen over the maximum likelihood trained model in generating more realistic text samples.[[DAT-NEU,EXP-POS,MET-POS], [EMP-POS]] \n(b) Using a novel in-filling procedure to overcome the complexities in GAN training.[[EXP-NEU,MET-POS], [NOV-POS]] \n(c) generation of high quality samples even with higher perplexity on ground truth set.[[DAT-POS,EXP-POS], [EMP-POS]] \n\ncons:\n(a) Use of rewards at every time step to the actor-critic training procure could be computationally expensive.[[MET-NEU], [EMP-NEG]] \n(b) How to overcome the situation where in-filling might introduce implausible text sequences with respect to the surrounding words?[[MET-NEU], [EMP-NEU]] \n(c) Depending on the Mask quality GAN can produce low quality samples.[[DAT-NEG,EXP-NEU], [EMP-NEG]]  Any practical way of choosing the mask?[[MET-NEU], [null]]