 "Strengths:\n* Very simple approach, amounting to coupled training of \"e\" identical copies  of a chosen net architecture, whose predictions are fused during training. [[PDI-POS,EXP-POS,OAL-POS], [IMP-POS,EMP-POS]] This forces the different model instances to become more complementary.[[RWK-NEU,MET-POS], [IMP-POS,EMP-POS]] \n* Perhaps counterintuitively, experiments also show that coupled ensembling leads to individual nets that perform better than those produced by separate training.[[EXP-POS,RES-POS], [CMP-POS]] \n* The practical advantages of the proposed approach are twofold:\n1. Given a fixed parameter budget, coupled ensembling leads to better accuracy than a single net or an ensemble of disjointly-trained nets.[[RWK-NEU,PDI-POS,EXP-NEU,RES-POS], [CMP-NEU]] \n2. For the same accuracy, coupled ensembling yields significant parameter savings.[[RWK-NEU,PDI-NEU,EXP-NEU,RES-NEU], [IMP-NEU]] \n\nWeaknesses:\n* Although results are very strong, the proposed models do not outperform the state-of-the-art, except for the models reported in Table 4, which however were obtained by *traditional* ensembling of coupled ensembles. [[PDI-NEG,RES-POS,TNF-NEU,OAL-NEG], [NOV-NEG,EMP-NEG]] \n* Coupled ensembling requires joint training of all nets in the ensemble and thus is limited by the size of the model that can be fit in memory. [[RWK-NEG], [SUB-NEG,EMP-NEG]] Conversely, traditional ensembling involves separate training of the different instances and this enables the learning of an arbitrary number of individual nets.[[RWK-NEG,PDI-NEG,EXP-NEU,MET-NEG], [SUB-NEG,EMP-NEG]]  \n* I am surprised by the results in Table 2, which suggest that the optimal number of nets in the ensemble is remarkably low (only 3!).[[RWK-NEG,TNF-NEG], [EMP-NEG]]  It'd be valuable to understand whether this kind of result holds for other network architectures or whether it is specific to this choice of net.[[RWK-NEG,RES-NEU], [null]] \n* Strictly speaking it is correct to refer to the individual nets in the ensembles as \"branches\" and \"basic blocks.[[EXP-NEU,MET-NEU], [null]] \" Nevertheless, I find the use of these terms confusing in the context of the proposed approach, since they are commonly used to denote concepts different from those represented here. [[RWK-NEG,PDI-NEG], [PNF-NEG]]  I would recommend refraining from using these terms here.[[EXT-NEU], [null]] \n\nOverall, the paper provides limited technical novelty.[[OAL-NEU], [NOV-NEU]]  Yet, it reveals some interesting empirical findings about the benefits of coordinated training of models in an ensemble.[[RWK-POS,MET-POS], [EMP-POS]]