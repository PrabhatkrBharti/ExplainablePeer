 "Summary:\nThis paper investigated the problem of attribute-conditioned image generation using generative adversarial networks.[[INT-NEU,PDI-NEU], [null]]  More specifically, the paper proposed to generate images from attribute and latent code as high-level representation.[[PDI-NEU], [null]]  To learn the mapping from image to high-level representations, an auxiliary encoder was introduced.[[MET-NEU], [null]]  The model was trained using a combination of reconstruction (auto-encoding) and adversarial loss.[[MET-NEU], [null]]  To further encourage effective disentangling (against trivial solution), an annihilating operation was proposed together with the proposed training pipeline.[[MET-NEU], [null]]   Experimental evaluations were conducted on standard face image databases such as Multi-PIE and CelebA.[[DAT-NEU,EXP-NEU], [null]]  \n\n== Novelty and Significance ==\nMulti-attribute image generation is an interesting task but has been explored to some extent.[[PDI-NEG], [NOV-NEG,IMP-NEG]]  The integration of generative adversarial networks with auto-encoding loss is not really a novel contribution.[[PDI-NEG], [NOV-NEG]]  \n-- Autoencoding beyond pixels using a learned similarity metric. Larsen et al., In ICML 2016.[[RWK-NEU,MET-NEU], [CMP-NEU]] \n\n== Technical Quality == \nFirst, it is not clear how was the proposed annihilating operation used in the experiments (there is no explanation in the experimental section).[[EXP-NEG,MET-NEG], [EMP-NEG]]  Based on my understanding, additional loss was added to encourage effective disentangling (prevent trivial solution).[[MET-NEU], [EMP-NEU]]  I would appreciate the authors to elaborate this a bit.[[EXP-NEU], [SUB-NEU]] \n\nSecond, the iterative training (section 3.4) is not a novel contribution since it was explored in the literature before (e.g., Inverse Graphics network).[[RWK-NEU,MET-NEG], [CMP-NEG]]  The proof developed in the paper provides some theoretical analysis but cannot be considered as a significant contribution.[[ANA-NEG], [EMP-NEG]] \n\nThird, it seems that the proposed multi-attribute generation pipeline works for binary attribute only.[[MET-NEG], [SUB-NEG]]  However, such assumption limits the generality of the work.[[MET-NEG], [EMP-NEG]]  Since the title is quite general, I would assume to see the results (1) on datasets with real-valued attributes, mixture attributes or even relative attributes[[INT-NEU,DAT-NEU,RES-NEU], [EMP-NEU]]  and (2) not specific to face images.[[RES-NEU], [EMP-NEU]] \n-- Learning to generate chairs with convolutional neural networks. Dosovitskiy et al., In CVPR 2015.\n-- Deep Convolutional Inverse Graphics Network. Kulkarni et al., In NIPS 2015.\n-- Attribute2Image: Conditional Image Generation from Visual Attributes. Yan et al., In ECCV 2016.[[RWK-NEU,BIB-NEU], [CMP-NEU]] \n-- InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets. Chen et al., In NIPS 2016.Yan et al., In ECCV 2016.[[RWK-NEU,BIB-NEU], [CMP-NEU]] \n\nAdditionally, considering the generation quality, the CelebA samples in the paper are not the state-of-the-art.[[RWK-NEG], [CMP-NEG]]  I suspect the proposed method only works in a more constrained setting (such as Multi-PIE where the images are all well aligned).[[MET-NEG], [EMP-NEG]] \n\nOverall, I feel that the submitted version is not ready for publication in the current form.\n" [[OAL-NEG], [REC-NEG]]