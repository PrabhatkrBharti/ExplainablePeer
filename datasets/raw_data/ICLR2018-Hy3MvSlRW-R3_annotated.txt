 "The main idea of this paper is to automate the construction of adversarial reading comprehension problems in the spirit of Jia and Liang, EMNLP 2017.[[RWK-NEU,PDI-NEU], [null]]   In that work a \"distractor sentence\" is manually added to a passage to superficially, but not logically, support an incorrect answer.[[PDI-NEU], [null]]   It was shown that these distractor sentences largely fool existing reading comprehension systems although they do not fool human readers.[[PDI-NEU], [null]]  \n\nThis paper replaces the manual addition of a distractor sentence with a single word replacement where a \"narrator\" is trained adversarially to select a replacement to fool the question answering system.[[PDI-NEU,MET-NEU], [null]]    This idea seems interesting but very difficult to evaluate.[[MET-NEG], [EMP-NEG]]    An adversarial word replacement my in fact destroy the factual information needed to answer the question and there is no control for this.[[MET-NEG], [EMP-NEG]]    The performance of the question answering system in the presence of this adversarial narrator is of unclear significance and the empirical results in the paper are very difficult to interpret.[[MET-NEG,RES-NEG], [EMP-NEG]]    No comparisons with previous work are given (and perhaps cannot be given).[[RWK-NEG], [CMP-NEG]]  \n\nA better model would be the addition of a distractor sentence as this preserves the information in the original passage.[[MET-NEG], [EMP-NEG]]    A language model could probably be used to generate a compelling distractor.[[MET-NEU], [EMP-NEU]]    But we want that the corrupted passage has the same correct answer as the uncorrupted passage and this difficult to guarantee.[[MET-NEG], [EMP-NEG]]    A trained \"narrator\" could learn to actually change the correct answer."[[EXP-NEU], [EMP-NEU]]