 "This paper proposes an iterative inference scheme for latent variable models that use inference networks.[[INT-NEU,PDI-NEU], [null]]  Instead of using a fixed-form inference network, the paper proposes to use the learning to learn approach of Andrychowicz et. al.[[RWK-NEU,MET-NEU], [null]]  The parameter of the inference network is still a fixed quantity but the function mapping is based on a deep network (e.g. it could be RNN but the experiments uses a feed-forward network).[[MET-NEU], [null]] \n\nMy main issue with the paper is that it does not do a good job justifying the main advantages of the proposed approach.[[MET-NEG], [EMP-NEG]]  It appears that the iterative method should result in \"direct improvement with additional samples and inference iterations\".[[MET-NEG], [EMP-NEG]]  I am supposing this is at the test time. [[MET-NEU], [EMP-NEU]] It is not clear exactly when this will be useful. [[RWK-NEU,MET-NEG], [EMP-NEG]] \n\nI believe an iterative approach is also possible to perform with the standard VAE, e.g., by bootstrapping over the input data and then using the iterative scheme of Rezende et. al.[[MET-NEU], [SUB-NEG]]  2014 (they used this method to perform data imputation).[[RWK-NEU,DAT-NEU], [null]] \n\nThe paper should also discuss the additional difficulty that arises when training the proposed model and compare them to training of standard inference networks in VAE.[[EXP-NEG,ANA-NEG], [SUB-NEG]] \n\nIn summary, the paper needs to do a better job in justifying the advantages obtained by the proposed method. "[[MET-NEG], [EMP-NEG]]