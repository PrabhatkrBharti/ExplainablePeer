 "SUMMARY.\n\nThe paper presents a variational autoencoder for generating entity pairs given a relation in a medical setting.[[INT-NEU,PDI-NEU], [null]] \nThe model strictly follows the standard VAE architecture with an encoder that takes as input an entity pair and a relation between the entities.[[EXP-NEU,MET-NEU], [null]] \nThe encoder maps the input to a probabilistic latent space.[[EXP-NEU,MET-NEU], [null]] \nFinally, a generator is used to generate entity pairs give a relation.[[MET-NEU], [null]] \n\n----------\n\nOVERALL JUDGMENT\nThe paper presents a clever use of VAEs for generating entity pairs conditioning on relations.[[MET-POS], [EMP-POS]] \nMy main concern about the paper is that it seems that the authors have tuned the hyperparameters and tested on the same validation set.[[DAT-NEG,MET-NEG], [EMP-NEG]] \nIf this is the case, all the analysis and results obtained are almost meaningless.[[RES-NEG,ANA-NEG], [EMP-NEG]] \nI suggest the authors make clear if they used the split training, validation, test.[[EXP-NEG,MET-NEG], [EMP-NEG]] \nUntil then it is not possible to draw any conclusion from this work.[[OAL-NEG], [EMP-NEG]] \n\nAssuming the experimental setting is correct, it is not clear to me the reason of having the representation of r (one-hot-vector of the relation) also in the decoding/generation part.[[EXP-NEG], [EMP-NEG]] \nThe hidden representation obtained by the encoder should already capture information about the relation.[[EXP-NEU], [EMP-NEU]] \nIs there a specific reason for doing so?\n\n"[[EXP-NEU], [EMP-NEU]]