 "This paper applies the boosting trick to deep learning.[[INT-NEU], [null]]  The idea is quite straightforward, and the paper is relatively easy to follow.[[PDI-POS], [EMP-POS]]  The proposed algorithm is validated on several image classification datasets.[[DAT-NEU,MET-NEU], [null]] \n\nThe paper is its current form has the following issues:\n1. There is hardly any baseline compared in the paper.[[RWK-NEG], [SUB-NEG,CMP-NEG]]  The proposed algorithm is essentially an ensemble algorithm, there exist several works on deep model ensemble (e.g., Boosted convolutional neural networks, and Snapshot Ensemble) should be compared against.[[MET-NEG], [SUB-NEG,CMP-NEG]] \n2. I did not carefully check all the proofs, but seems most of the proof can be moved to supplementary to keep the paper more concise.[[MET-NEU], [EMP-NEU]] \n3. In Eq. (3), \\tilde{D} is not defined.[[MET-NEG], [EMP-NEG]] \n4. Under the assumption $\\epsilon_t(l) > \\frac{1}{2\\lambda}$, the definition of $\\beta_t$ in Eq.8 does not satisfy $0 < \\beta_t < 1$.[[MET-NEU], [EMP-NEU]]   \n5. How many layers is the DenseNet-BC used in this paper?[[MET-NEU], [EMP-NEU]]  Why the error rate reported here is higher than that in the original paper?[[RWK-NEG,RES-NEG], [CMP-NEG]] \nTypo: \nIn Session 3 Line 7, there is a missing reference.[[RWK-NEG], [SUB-NEG]] \nIn Session 3 Line 10, \u201c1,00 object classes\u201d should be \u201c100 object classes\u201d.[[CNT], [CLA-NEG]] \nIn Line 3 of the paragraph below Equation 5, \u201cclasse\u201d should be \u201cclass\u201d.\n"[[CNT], [CLA-NEG]]