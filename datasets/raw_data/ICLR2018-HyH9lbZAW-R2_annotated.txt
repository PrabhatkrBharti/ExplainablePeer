 "This paper presents a variational inference algorithm for models that contain\ndeep neural network components and probabilistic graphical model (PGM)\ncomponents.[[MET-NEU], [null]] \nThe algorithm implements natural-gradient message-passing where the messages\nautomatically reduce to stochastic gradients for the non-conjugate neural\nnetwork components.[[MET-NEU], [null]]  The authors demonstrate the algorithm on a Gaussian mixture\nmodel and linear dynamical system where they show that the proposed algorithm\noutperforms previous algorithms.[[RWk-NEU,MET-NEU], [null]]  Overall, I think that the paper proposes some\ninteresting ideas,[[PDI-POS], [EMP-POS]]  however, in its current form I do not think that the novelty\nof the contributions are clearly presented and that they are not thoroughly\nevaluated in the experiments.[[MET-NEG,EXP-NEG], [NOV-NEG,EMP-NEG]] \n\nThe authors propose a new variational inference algorithm that handles models\nwith deep neural networks and PGM components.[[MET-NEU], [NOV-NEU]]  However, it appears that the\nauthors rely heavily on the work of (Khan & Lin, 2017) that actually provides\nthe algorithm.[[RWK-NEU,MET-NEU], [NOV-NEU]]  As far as I can tell this paper fits inference networks into\nthe algorithm proposed in (Khan & Lin, 2017) which boils down to i) using an\ninference network to generate potentials for a conditionally-conjugate\ndistribution[[RWK-NEU,MET-NEU], [CMP-NEU]]  and ii) introducing new PGM parameters to decouple the inference\nnetwork from the model parameters.[[RWK-NEU,MET-NEU], [CMP-NEU]]  These ideas are a clever solution to work\ninference networks into the message-passing algorithm of (Khan & Lin, 2017),[[RWK-POS,PDI-POS], [CMP-NEU,EMP-POS]] \nbut I think the authors may be overselling these ideas as a brand new algorithm.[[RWK-NEG,MET-NEG], [NOV-NEG]] \nI think if the authors sold the paper as an alternative to (Johnson, et al., 2016)\nthat doesn't suffer from the implicit gradient problem the paper would fit into\nthe existing literature better.[[RWK-NEU], [CMP-NEU]] \n\nAnother concern that I have is that there are a lot of conditiona-conjugacy\nassumptions baked into the algorithm that the authors only mention at the end\nof the presentation of their algorithm.[[MET-NEG], [SUB-NEG]]  Additionally, the authors briefly state\nthat they can handle non-conjugate distributions in the model by just using\nconjugate distributions in the variational approximation.[[MET-NEU], [null]]  Though one could do\nthis, the authors do not adequately show that one should, or that one can do this\nwithout suffering a lot of error in the posterior approximation.[[MET-NEG], [EMP-NEG]]  I think that\nwithout an experiment the small section on non-conjugacy should be removed.[[EXP-NEU], [EMP-NEU]] \n\nFinally, I found the experimental evaluation to not thoroughly demonstrate the\nadvantages and disadvantages of the proposed algorithm.[[EXP-NEG,MET-NEG], [EMP-NEG]]  The algorithm was applied\nto the two models originally considered in (Johnson, et al., 2016) and the\nproposed algorithm was shown to attain lower mean-square errors for the two\nmodels.[[RWK-NEU,MET-NEU], [CMP-NEU]]  The experiments do not however demonstrate why the algorithm is\nperforming better.[[EXP-NEG,MET-NEG], [SUB-NEG,EMP-NEG]]  For instance, is the (Johnson, et al., 2016) algorithm\nsuffering from the implicit gradient? [[RWK-NEU,MET-NEU], [null]] It also would have been great to have\nconsidered a model that the (Johnson, et. al., 2016) algorithm would not work\nwell on or could not be applied to show the added applicability of the proposed\nalgorithm.[[RWK-NEU,MET-NEU], [CMP-NEU]] \n\nI also have some minor comments on the paper:\n- There are a lot of typos.[[OAL-NEG], [CLA-NEG]] \n- The first two sentences of the abstract do not really contribute anything to the paper.[[ABS-NEG], [CNT]]  What is a powerful model?[[MET-NEU], [CNT]]  What is a powerful algorithm?[[MET-NEU], [CNT]] \n- DNN was used in Section 2 without being defined.[[MET-NEU], [EMP-NEG]] \n- Using p() as an approximate distribution in Section 3 is confusing notation[[MET-NEG], [PNF-NEG]] \n  because p() was used for the distributions in the model.[[MET-NEG], [PNF-NEG]]