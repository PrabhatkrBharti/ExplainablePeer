 "This paper introduces a smooth surrogate loss function for the top-k SVM, for the purpose of plugging the SVM to the deep neural networks.[[RWK-NEU,EXP-NEU,MET-NEU], [null]]  The idea is to replace the order statistics, which is not smooth and has a lot of zero partial derivatives, to the exponential of averages, which is smooth and is a good approximation of the order statistics by a good selection of the \"temperature parameter\". [[RWK-NEU,PDI-NEU,EXP-NEG], [EMP-NEG]] The paper is well organized and clearly written.[[OAL-POS], [CLA-POS,PNF-POS]]  The idea deserves a publication.[[OAL-POS], [IMP-POS,REC-POS]] \n\nOn the other hand, there might be better and more direct solutions to reduce the combinatorial complexity.[[RWK-NEU,EXP-NEG], [EMP-NEG]]  When the temperature parameter is small enough, both of the original top-k SVM surrogate loss (6) and the smooth loss (9) can be computed precisely by sorting the vector s first, and take a good care of the boundary around s_{[k]}.[[RWK-NEU,EXP-NEU,MET-NEU], [EMP-NEU]]