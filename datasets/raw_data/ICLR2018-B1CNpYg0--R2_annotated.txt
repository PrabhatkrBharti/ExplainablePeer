 "\nThis paper illustrates a method to compute produce word embeddings on the fly for rare words, using a pragmatic combination of existing ideas:[[INT-NEU,RWK-NEU,PDI-NEU], [null]] \n\n* Backing off to a separate decoder for rare words a la Luong and Manning (https://arxiv.org/pdf/1604.00788.pdf, should be cited, though the idea might be older).[[RWK-NEU,BIB-NEU], [null]] \n\n* Using character-level models a la Ling et al.[[RWK-NEU,BIB-NEU], [null]] \n\n* Using dictionary embeddings a la Hill et al.[[RWK-NEU,BIB-NEU], [null]] \n\nNone of these ideas are new before but I haven\u2019t seen them combined in this way before.[[RWK-NEG], [NOV-NEG]]  This is a very practical idea, well-explained with a thorough set of experiments across three different tasks.[[PDI-POS,EXP-POS], [EMP-POS]]  The paper is not surprising[[OAL-NEG], [NOV-NEG]]  but this seems like an effective technique for people who want to build effective systems with whatever data they\u2019ve got. \n"[[MET-POS], [EMP-POS]]