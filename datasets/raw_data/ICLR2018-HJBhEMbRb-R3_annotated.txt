 "This paper studies the generalization properties of 2-layer neural networks based on Fourier analysis.[[INT-NEU,MET-NEU], [null]]  Studying the generalization property of neural network is an important problem and Fourier-based analysis is a promising direction, as shown in (Lee et al., 2017).[[RWK-NEU,MET-NEU,BIB-NEU], [null]]  However, I am not satisfied with the results in the current version.[[RES-NEG,OAL-NEG], [IMP-NEG]] \n\n1) The main theoretical results are on the sin activation functions instead of commonly used ReLU functions. [[RWK-NEU,MET-NEU,RES-NEU], [null]] \n\n2) Even if for sin activation functions, the analysis is NOT complete. [[RWK-NEU,MET-NEG,ANA-NEG], [SUB-NEG,EMP-NEG]] The authors claimed in the abstract that gradient-based methods will converge to generalizable local minima.[[RWK-NEU,EXP-NEU,MET-NEU], [null]]  However, Corollary 3 is only a concentration bound on the gradient.[[RWK-NEU], [null]]  There is a gap that how this corollary implies generalization.[[RWK-NEU], [null]]  The paragraph below this corollary is only a high level intuition. [[RWK-NEU], [EMP-NEU]]