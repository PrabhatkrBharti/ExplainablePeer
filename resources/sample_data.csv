,Index,Text,Clarity of Review,Justification of Scores,Depth of Analysis,Fairness and Objectivity,Constructiveness of Feedback,Engagement with Related Work,Accuracy in Understanding,Consistency of Evaluation,Identification of Novelty,Ethical Considerations and Responsibility
0,B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",1,1,1,1,-1,1,1,1,-1,0
1,B11bwYgfM-R2,"This paper proposes a method for multitask and few-shot learning by completing a performance matrix (which measures how well the classifier for task i performs on task j). \n\nThe matrix completion approach is based on robust PCA.  When used for multitask learning (MTL) with N tasks, the method has to first train one classifier for each task (and so train a total of N classifiers), and then evaluate the performance of each classifier on each and every task (and so involves N^2 testing rounds).  This can be computationally demanding. \n\nThe key assumption in the paper is that task classifier i that performs well on task j means tasks i and j belong to the same cluster, and if task classifier i does not perform well on task j, then tasks i and j belong to different cluster. The proposed algorithm then uses these performance values to perform task clustering.  However, in MTL, we usually assume that there are not enough samples to learn each task, and so this performance matrix may not be reliable. \n\nThere have been a number of MTL methods based on task clustering.  For example,\n[1] A convex formulation for learning task relationships in multi-task learning (UAI) \n[2] A dirty model for multi-task learning (NIPS) \n[3] Clustered multi-task learning: A convex formulation (NIPS) \n[4] Convex multitask learning with flexible task clusters (ICML) \n[5] Integrating low-rank and group-sparse structures for robust multi-task learning (KDD)\n[6] Learning incoherent sparse and low-rank patterns from multiple tasks (KDD)\nIn particular, [5] assumes that the combined weight matrix (for all the tasks) follows the robust PCA model.  This is thus very similar to the proposed method (which assumes that the performance matrix follows the robust PCA model).  However, a disadvantage of the proposed method is that it is a two-step approach (first perform task clustering, then re-learn the cluster weights), while [5] is not. \n\nFor few-shot learning, the authors mentioned that the \\alpha's are adaptable parameters but did not mention how they are adapted. \n\nExperimental results are not convincing. \n- Comparison with existing clustered MTL methods mentioned above are missing. \n- As mentioned above, the proposed method can be computationally expensive (when used for MTL), but no timing results are reported. \n- As the authors mentioned in section 4.2, most of the tasks have a significant amount of training data (and single-task baselines achieve good results), and so this is not a good benchmark dataset for MTL.",1,1,1,1,1,1,1,1,-1,0
