Index,Text,CLA,JUS,DEP,FAI,CON,ENG,ACC,CST,NOV,ETH
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-POS,ETH-POS
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-NEG,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-POS,ETH-POS
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-NEG,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-NEG,ENG-POS,ACC-POS,CST-POS,NOV-POS,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-POS,ETH-POS
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-NEG,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-NEG,ENG-POS,ACC-POS,CST-POS,NOV-POS,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-NEG,JUS-NEG,DEP-NEG,FAI-NEG,CON-NEG,ENG-NEG,ACC-NEG,CST-NEG,NOV-NEG,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-POS,ETH-POS
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-POS,ENG-POS,ACC-POS,CST-POS,NOV-NEG,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-NEG,ENG-POS,ACC-POS,CST-POS,NOV-POS,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-NEG,JUS-NEG,DEP-NEG,FAI-NEG,CON-NEG,ENG-NEG,ACC-NEG,CST-NEG,NOV-NEG,ETH-NEG
B11bwYgfM-R1,"The idea of using cross-task transfer performance to do task clustering is not new.  Please refer to the paper \u201cDiscovering structure in multiple learning tasks: The TC algorithm\u201d published in ICML 1996.  One issue of the use of cross-task transfer performance to measure task relations is that it ignores the negative correlations between tasks, which is useful for learning from multiple tasks.  For example, in binary classification tasks, a very small S_{ij} indicates that by changing the sign of the classification function these two tasks are useful to each other.  So the use of cross-task transfer performance and the task clustering approach can only capture positive correlations between tasks but ignore the negative task relations which are also important to the sharing among tasks in multi-task learning. \n\nProblem (2) is identical to robust PCA and Theorem 3.1 is common in matrix completion literature.  I don\u2019t see much novelty.  Appendix A seems obvious but it cannot prove the validity of the assumption made in problem (2).  Based on previous works such as \u201cMulti-task Sparse Structure Learning with Gaussian Copula Models\u201d and \u201cLearning Sparse Task Relations in Multi-Task Learning\u201d, when the number of tasks is large, the task relation exhibits the sparse structure.  I don\u2019t know whether the low-rank structure does exist in the cross-task transfer performance or not. \n\nThe two parts in this paper are not new.  The combination of the two parts seems a bit incremental and does not bring much novelty.",CLA-POS,JUS-POS,DEP-POS,FAI-POS,CON-NEG,ENG-POS,ACC-POS,CST-POS,NOV-NEG,ETH-NEU
